@article{Christophides2019,
    author = {Christophides, Vassilis and Efthymiou, Vasilis and Palpanas, Themis and Papadakis, George and Stefanidis, Kostas},
    doi = {10.1145/3418896},
    issn = {15577341},
    journal = {ACM Computing Surveys},
    keywords = {Entity blocking and matching,batch and incremental entity resolution workflows,block processing,crowdsourcing,deep learning,strongly and nearly similar entities},
    number = {6},
    title = {An Overview of End-to-End Entity Resolution for Big Data},
    volume = {53},
    year = {2021}
}

@article{martin2011inspire,
  title={INSPIRE: Managing metadata in a global digital library for high-energy physics},
  author={Martin Montull, Javier},
  journal={Research Conference on Metadata and Semantic Research},
  pages={269--274},
  year={2011},
  organization={Springer}
}

@book{Papadakis2021,
  title={The Four Generations of Entity Resolution},
  author={Papadakis, George and Ioannou, Ekaterini and Thanos, Emanouil and Palpanas, Themis},
  pages={1--170},
  year={2021},
  publisher={Morgan \& Claypool Publishers},
  address={}
}


@article{ishwaran2001gibbs,
  title={Gibbs sampling methods for stick-breaking priors},
  author={Ishwaran, H. and James, L.~F.},
  journal={Journal of the American Statistical Association},
  volume={96},
  number={453},
  pages = {161--173},
  year={2001}
}

@article{perman1992size,
  title={Size-biased sampling of {P}oisson point processes and excursions},
  author={Perman, M. and Pitman, J. and Yor, M.},
  journal={Probability Theory and Related Fields},
  volume={92},
  number={1},
  pages={21--39},
  year={1992},
  publisher={Springer}
}

@article{pitman1997two,
  title={The two-parameter {P}oisson-{D}irichlet distribution derived from a stable subordinator},
  author={Pitman, J. and Yor, M.},
  journal={The Annals of Probability},
  volume = {25},
  number = {2},
    pages={855--900},
  year={1997},
  publisher={JSTOR}
}

@article{pitman1995exchangeable,
  title={Exchangeable and partially exchangeable random partitions},
  author={Pitman, Jim},
  journal={Probability theory and related fields},
  volume={102},
  number={2},
  pages={145--158},
  year={1995},
  publisher={Springer}
}


@book{pitman_2006,
  title={Combinatorial stochastic processes},
  author={Pitman, Jim},
  volume={32},
  year={2006},
  publisher={Springer Science \& Business Media}
}

@article{blei_2003_latent,
  title={Latent {D}irichlet allocation},
  author={Blei, D.~M. and Ng, A.~Y. and Jordan, M.~I.},
  journal={Journal of Machine Learning Research},
  volume={3},
  pages={993--1022},
  year={2003},
  publisher={JMLR.org}
}

@article{antoniak1974mixtures,
  title={Mixtures of {D}irichlet processes with applications to {B}ayesian nonparametric problems},
  author={Antoniak, C.~E.},
  journal={The Annals of Statistics},
  pages={1152--1174},
  volume = {2},
  number = {6},
  year={1974},
  publisher={JSTOR}
}

@article{maceachern1994estimating,
  title={Estimating normal means with a conjugate style {D}irichlet process prior},
  author={MacEachern, S.~N.},
  journal={Communications in Statistics-Simulation and Computation},
  volume={23},
  number={3},
  pages={727--741},
  year={1994},
  publisher={Taylor \& Francis}
}

@incollection{maceachern1998computational,
  title={Computational methods for mixture of {D}irichlet process models},
  author={MacEachern, S.~N.},
  booktitle={Practical nonparametric and semiparametric Bayesian statistics},
  pages={23--43},
  year={1998},
  publisher={Springer}
}

@article{kingman_1978_representation,
  title={The representation of partition structures},
  author={Kingman, J.~F.~C.},
  journal={Journal of the London Mathematical Society},
  volume={2},
  number={2},
  pages={374--380},
  year={1978},
  publisher={Oxford University Press}
}



@article{asher2020introduction,
  title={An introduction to probabilistic record linkage with a focus on linkage processing for WTC registries},
  author={Asher, Jana and Resnick, Dean and Brite, Jennifer and Brackbill, Robert and Cone, James},
  journal={International journal of environmental research and public health},
  volume={17},
  number={18},
  pages={6937},
  year={2020},
}



@incollection{ball2000salvadoran,
    author = {Ball, Patrick},
    booktitle = {Making the Case: Investigating Large Scale Human Rights Violations Using Information Systems and Data Analysis},
    editor = {Ball, Patrick and Spirer, Herbert F. and Spirer, Louise},
    pages = {15--24},
    publisher = {American Association for the Advancement of Science},
    title = {The {S}alvadoran Human Rights Commission: Data Processing, Data Representation, and Generating Analytical Reports},
    year = {2000}
}

@article{zhang2018name,
  title={Name Disambiguation in AMiner: Clustering, Maintenance, and Human in the Loop.},
  author={Zhang, Yutao and Zhang, Fanjin and Yao, Peiran and Tang, Jie},
  journal={Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  pages={1002--1011},
  year={2018}
}

@article{louppe2016ethnicity,
  title={Ethnicity sensitive author disambiguation using semi-supervised learning},
  author={Louppe, Gilles and Al-Natsheh, Hussein T and Susik, Mateusz and Maguire, Eamonn James},
  journal={international conference on knowledge engineering and the semantic web},
  pages={272--287},
  year={2016},
  organization={Springer}
}

@article{fan2011graph,
  title={On graph-based name disambiguation},
  author={Fan, Xiaoming and Wang, Jianyong and Pu, Xu and Zhou, Lizhu and Lv, Bing},
  journal={Journal of Data and Information Quality (JDIQ)},
  volume={2},
  number={2},
  pages={1--23},
  year={2011},
  publisher={ACM New York, NY, USA}
}

@inbook{zhang2017name,
  title={Name disambiguation in anonymized graphs using network embedding},
  author={Zhang, Baichuan and Al Hasan, Mohammad},
  booktitle={Proceedings of the 2017 ACM on Conference on Information and Knowledge Management},
  pages={1239--1248},
  year={2017}
}

@article{Tang:12TKDE,
    author = {Jie Tang and Alvis C.M. Fong and Bo Wang and Jing Zhang},
    title = {A Unified Probabilistic Framework for Name Disambiguation in Digital Library},
    journal ={IEEE Transactions on Knowledge and Data Engineering},
    volume = {24},
    number = {6},
    year = {2012},
}

@article{muller2017data,
  title={Data sets for author name disambiguation: an empirical analysis and a new resource},
  author={M{\"u}ller, Mark-Christoph and Reitz, Florian and Roy, Nicolas},
  journal={Scientometrics},
  volume={111},
  number={3},
  pages={1467--1500},
  year={2017},
  publisher={Springer}
}

@data{illinoisdatabankIDB-4222651,
doi = {10.13012/B2IDB-4222651_V1},
url = {https://doi.org/10.13012/B2IDB-4222651_V1},
author = {Torvik, Vetle I. and Smalheiser, Neil R.},
publisher = {University of Illinois at Urbana-Champaign},
title = {Author-ity 2009 - PubMed author name disambiguated dataset},
year = {2018}
}

 
@inbook{ wang:adana:,
AUTHOR = "Xuezhi Wang and Jie Tang and Hong Cheng and Philip S. Yu",
TITLE = "ADANA: Active Name Disambiguation",
BOOKTITLE = "ICDM'11",
PAGES = {794-803},
YEAR = {2011}, 
}  

@inbook{tran2014author,
  title={Author name disambiguation by using deep neural network},
  author={Tran, Hung Nghiep and Huynh, Tin and Do, Tien},
  booktitle={Asian Conference on Intelligent Information and Database Systems},
  pages={123--132},
  year={2014},
  organization={Springer}
}

@article{subramanian2021s2and,
  title={S2AND: A Benchmark and Evaluation System for Author Name Disambiguation},
  author={Subramanian, Shivashankar and King, Daniel and Downey, Doug and Feldman, Sergey},
  journal={arXiv e-prints},
  year={2021},
  note={{arXiv:2103.07534}}
}

@article{xu2019incorporating,
  title={Incorporating conditional dependence in latent class models for probabilistic record linkage: Does it matter?},
  author={Xu, Huiping and Li, Xiaochun and Shen, Changyu and Hui, Siu L and Grannis, Shaun and others},
  journal={The Annals of Applied Statistics},
  volume={13},
  number={3},
  pages={1753--1790},
  year={2019},
  publisher={Institute of Mathematical Statistics}
}

@article{howland2008rescate,
  title={How {El} {R}escate, a Small Nongovernmental Organization, Contributed to the Transformation of the Human Rights Situation in {El} {S}alvador},
  author={Howland, Todd},
  journal={Human Rights Quarterly},
  pages={703--757},
  year={2008},
  volume = {30},
  number={3},
}


@article{wortman2018simultaneous,
	Author = {Wortman, Joan Heck and Reiter, Jerome P},
	Journal = {Statistics in Medicine},
	Publisher = {Wiley Online Library},
	Title = {Simultaneous record linkage and causal inference with propensity score subclassification},
	Year = {2018}}
	
@techreport{betancur1993madness,
    author = {Betancur, Belisario and Planchart, Reinaldo Figueredo and Buergenthal, Thomas},
    booktitle = {Report on The Commission on the Truth for El Salvador},
    institution = {UN Security Council},
    number = {S/25500, Annex},
    title = {From Madness to Hope: {T}he 12-year war in {E}l {S}alvador},
    year = {1993}
}
	
@phdthesis{wortman2019record,
	Author = {Wortman, Joan Pearson Heck},
	School = {Duke University},
	Title = {Record Linkage Methods with Applications to Causal Inference and Election Voting Data},
	Year = 2019,
	Bdsk-Url-1 = {https://hdl.handle.net/10161/18657}
}	


@article{tancredi2018unified,
  title={A Unified Framework for De-Duplication and Population Size Estimation (with Discussion)},
  author={Tancredi, Andrea and Steorts, Rebecca and Liseo, Brunero},
  journal={Bayesian Analysis},
  year={2020},
  volume = {15}, 
  number={2},
  pages={33–682},
  publisher={International Society for Bayesian Analysis}
}

@article{sadinle2020discussion,
  title={A Unified Framework for De-Duplication and Population Size Estimation (Invited Discussion)},
  author={Sadinle, Maurico},
  journal={Bayesian Analysis},
  year={2020},
  volume = {15}, 
  number={2},
  pages={659–663},
  publisher={International Society for Bayesian Analysis}
}

@article{murray2020discussion,
  title={A Unified Framework for De-Duplication and Population Size Estimation (Invited Discussion)},
  author={Murray, Jared},
  journal={Bayesian Analysis},
  year={2020},
  volume = {15}, 
  number={2},
  pages={664–669},
  publisher={International Society for Bayesian Analysis}
}

@article{ju2020discussion,
  title={A Unified Framework for De-Duplication and Population Size Estimation (Contributed Discussion)},
  author={Nianqiao, Ju and Biswas, Niloy and Jacob, Pierre and Mena, Gonzalo and O'Leary, John and Pompe, Emilia},
  journal={Bayesian Analysis},
  year={2020},
  volume = {15}, 
  number={2},
  pages={670–672},
  publisher={International Society for Bayesian Analysis}
}

@article{tancredi2020rejoinder,
  title={A Unified Framework for De-Duplication and Population Size Estimation (Rejoiner)},
  author={Tancredi, Andrea and Steorts, Rebecca and Liseo, Brunero},
  journal={Bayesian Analysis},
  year={2020},
  volume = {15}, 
  number={2},
  pages={675–682},
  publisher={International Society for Bayesian Analysis}
}


@article{bohannon2005cost,
  title={A Cost-Based Model and Effective Heuristic for Repairing Constraints by Value Modification},
  author={Bohannon, Philip and Fan, Wenfei and Flaster, Michael and Rastogi, Rajeev},
  journal={Proceedings of the 2005 ACM SIGMOD International Conference on Management of Data},
  pages={143--154},
  year={2005}
}

@article{korn200721,
  title={IL-21 initiates an alternative pathway to induce proinflammatory TH 17 cells},
  author={Korn, Thomas and Bettelli, Estelle and Gao, Wenda and Awasthi, Amit and J{\"a}ger, Anneli and Strom, Terry B and Oukka, Mohamed and Kuchroo, Vijay K},
  journal={Nature},
  volume={448},
  number={7152},
  pages={484--487},
  year={2007},
  publisher={Nature Publishing Group}
}

@article{yan1999conflict,
  title={Conflict Tolerant Queries in AURORA},
  author={Yan, Ling Ling and Ozsu, M Tamer},
  journal={Proceedings Fourth IFCIS International Conference on Cooperative Information Systems},
  pages={279--290},
  year={1999},
  organization={IEEE}
}

@article{cohen2005incremental,
    author = {Cohen, Sara and Sagiv, Yehoshua},
    title = {An Incremental Algorithm for Computing Ranked Full Disjunctions},
    year = {2005},
    isbn = {1595930620},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    journal = {Proceedings of the Twenty-Fourth ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems},
    pages = {98–107},
    numpages = {10},
    location = {Baltimore, Maryland},
}
  

@article{culotta2007canonicalization,
    author = {Culotta, Aron and Wick, Michael and Hall, Robert and Marzilli, Matthew and McCallum, Andrew},
    title = {Canonicalization of Database Records Using Adaptive Similarity Measures},
    year = {2007},
    isbn = {9781595936097},
    publisher = {Association for Computing Machinery},
    address = {New York, NY},
    journal = {Proceedings of the 13th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
    pages = {201–209},
    numpages = {9},
    keywords = {data mining, information extraction, data cleaning},
    location = {San Jose, California, USA},
}
  

	
@article{bleiholder2009data,
  title={Data Fusion},
  author={Bleiholder, Jens and Naumann, Felix},
  journal={ACM Computing Surveys},
  volume={41},
  number={1},
  pages={1--41},
  year={2009},
  publisher={ACM New York, NY, USA}
}	
	
@article{kaplan2020,
  title={Entity Resolution and the Downstream Task: A Case Study of North Carolina Voter Registration Records},
  author={Andee Kaplan and Brenda Betancourt and Rebecca C. Steorts},
  journal={Submitted},
  year={2020}
}
	
@misc{ncsbe,
	Author = {North Carolina State Board of Elections},
	Note = {Accessed: 2019-12-24},
	Title = {North Carolina State Board of Elections},
	Year = {2019}
}	

@article{cohen2003comparison,
    author = {Cohen, William W. and Ravikumar, Pradeep and Fienberg, Stephen E.},
    title = {A Comparison of String Distance Metrics for Name-Matching Tasks},
    year = {2003},
    publisher = {AAAI Press},
    journal = {Proceedings of the 2003 International Conference on Information Integration on the Web},
    pages = {73–78},
    numpages = {6},
    location = {Acapulco, Mexico},
}



@article{frisoli2019novel,
  title={A Novel Record Linkage Interface That Incorporates Group Structure to Rapidly Collect Richer Labels},
  author={Frisoli, Kayla and LeRoy, Benjamin and Nugent, Rebecca},
  journal={IEEE International Conference on Data Science and Advanced Analytics},
  pages={580--589},
  year={2019}
}

@article{Frisoli2018ExploringTE,
  title={Exploring the Effect of Household Structure in Historical Record Linkage of Early 1900s Ireland Census Records},
  author={Kayla Frisoli and Rebecca Nugent},
  journal={2018 IEEE International Conference on Data Mining Workshops (ICDMW)},
  year={2018},
  pages={502-509}
}

@article{hogan2013quality,
  title={Quality and the 2010 Census},
  author={Hogan, Howard and Cantwell, Patrick J and Devine, Jason and Mule, Vincent T and Velkoff, Victoria},
  journal={Population Research and Policy Review},
  volume={32},
  number={5},
  pages={637--662},
  year={2013},
  publisher={Springer}
}

@article{broderick_2013_feature,
  title={Feature allocations, probability functions, and paintboxes},
  author={Broderick, T. and Pitman, J. and Jordan, M.~I.},
  journal={Bayesian Analysis},
  volume={8},
  number={4},
  pages={801--836},
  year={2013},
  publisher={International Society for Bayesian Analysis}
}


@article{teh_2006_hierarchical,
  title={Hierarchical {D}irichlet processes},
  author={Teh, Y.~W. and Jordan, M.~I. and Beal, M.~J. and Blei, D.~M.},
  journal={Journal of the American Statistical Association},
  volume={101},
  number={476},
  pages = {1566--1581},
  year={2006}
}


@article{marchant_distributed_2019,
  title={d-blink: Distributed End-to-End {B}ayesian Entity Resolution},
  author={Marchant, Neil G and Steorts, Rebecca C and Kaplan, Andee and Rubinstein, Benjamin I P and Elazar, Daniel N},
  journal={arXiv e-prints},
  note={{arxiv:1909.06039}},
  year={2019}
}

@article{johndrow2017theoretical,
    author = {Johndrow, J E and Lum, K and Dunson, D B},
    title = "{Theoretical limits of microclustering for record linkage}",
    journal = {Biometrika},
    volume = {105},
    number = {2},
    pages = {431-446},
    year = {2018},
    issn = {0006-3444},
    doi = {10.1093/biomet/asy003},
}


@misc{Sariyar2016,
	Author = {Sariyar, Murat and Andreas Borg},
	Date-Modified = {2017-06-18 19:55:51 +0000},
	Howpublished = {\url{http://cran.r-project.org/package=RecordLinkage}},
	Title = {Record Linkage in R. R package. Version 0.4-10},
	Year = {2016}}


@ARTICLE{gutman_2013,
  AUTHOR =       {Roee Gutman and Christopher C. Afendulis and Alan M. Zaslavsky},
  TITLE =        {A {B}ayesian Procedure for File Linking to Analyze End-of-Life Medical Costs},
  JOURNAL =      {Journal of the American Statistical Association },
  YEAR =         {2013},
  NUMBER = 	 {501},
  VOLUME =	 {108},
  PAGES =	 {34--47},
}

@article{shan2020bayesian,
  title={A {B}ayesian Multi-Layered Record Linkage Procedure to Analyze Functional Status of Medicare Patients with Traumatic Brain Injury},
  author={Shan, Mingyang and Thomas, Kali and Gutman, Roee},
  journal={arXiv e-prints},
  year={2020},
  note={{arxiv:2005.08549}}
}


@article{lahiri_2005,
	Author = {Lahiri, P. and Larsen, M.},
	Journal = {Journal of the American Statistical Association},
	Number = {469},
	Pages = {222-230},
	Title = {Regression Analysis With Linked Data},
	Volume = {100},
	Year = {2005}
}


@article{broderick_variational_2014,
	title = {Variational {Bayes} for {Merging} {Noisy} {Databases}},
	abstract = {{B}ayesian entity resolution merges together multiple, noisy databases and returns the minimal collection of unique individuals represented, together with their true, latent record values. Bayesian methods allow flexible generative models that share power across databases as well as principled quantification of uncertainty for queries of the final, resolved database. However, existing Bayesian methods for entity resolution use Markov monte Carlo method (MCMC) approximations and are too slow to run on modern databases containing millions or billions of records. Instead, we propose applying variational approximations to allow scalable Bayesian inference in these models. We derive a coordinate-ascent approximation for mean-field variational Bayes, qualitatively compare our algorithm to existing methods, note unique challenges for inference that arise from the expected distribution of cluster sizes in entity resolution, and discuss directions for future work in this domain.},
	urldate = {2016-03-30},
	journal = {arXiv e-prints},
	author = {Broderick, Tamara and Steorts, Rebecca C.},
	year = {2014},
	note = {{arxiv:1410.4792}},
	keywords = {Statistics - Machine Learning, Statistics - Methodology},
	annote = {Comment: 12 pages}
}

@article{christen2019data,
  title={Data linkage: The big picture},
  author={Christen, Peter},
  journal={Harvard Data Science Review},
  year={2019}
}

@article{SIPP,
	Author = {{{U. S. Census Bureau}}},
	Date-Added = {2020-02-02 16:35:20 -0500},
	Date-Modified = {2020-02-02 16:45:32 -0500},
	Doi = {10.3886/ICPSR04517.v1},
	Publisher = {Inter-university Consortium for Political and Social Research {$[$}distributor{$]$}},
	Title = {Survey of Income and Program Participation (SIPP) 2004 Panel},
	Ty = {DATA},
	Year = {2009}
}

@article{spahn2017before,
    author = {Spahn, Bradley},
    pages = {1--38},
    title = {Before The American Voter},
    year = {2019},
    note={Available at SSRN: \url{https://ssrn.com/abstract=3478473}}
}


@article{mcveigh2017practical,
  title={Practical {B}ayesian Inference for Record Linkage},
  author={McVeigh, Brendan S and Murray, Jared S},
  journal={arXiv e-prints},
  note={{arxiv:1710.10558}},
  year={2017}
}

@article{mcveigh2019scaling,
  title={Scaling {B}ayesian Probabilistic Record Linkage with Post-Hoc Blocking: an Application to the California Great Registers},
  author={McVeigh, Brendan S and Spahn, Bradley T and Murray, Jared S},
  journal={arXiv e-prints},
  note={{arxiv:1905.05337}},
  year={2019}
}


@article{tancredi2011hierarchical,
  title={A Hierarchical {B}ayesian Approach to Record Linkage and Population Size Problems},
  author={Tancredi, Andrea and Liseo, Brunero and others},
  journal={The Annals of Applied Statistics},
  volume={5},
  number={2B},
  pages={1553--1585},
  year={2011},
  publisher={Institute of Mathematical Statistics}
}

@article{kim12,
	Acmid = {2206477},
	Address = {Amsterdam, The Netherlands, The Netherlands},
	Author = {Kim, Gunky and Chambers, Raymond},
	Issn = {0167-9473},
	Issue_Date = {September, 2012},
	Journal = {Computational Statistics and Data Analalysis},
	Number = {9},
	Numpages = {15},
	Pages = {2756--2770},
	Publisher = {Elsevier Science Publishers B. V.},
	Title = {Regression Analysis Under Incomplete Linkage},
	Volume = {56},
	Year = {2012}}
	
@article{goldstein12,
	Author = {Goldstein, Harvey and Harron, Katie and Wade, Angie},
	Journal = {Statistics in Medicine},
	Number = {28},
	Pages = {3481--3493},
	Publisher = {Wiley Online Library},
	Title = {The Analysis of Record-Linked Data Using Multiple Imputation With Data Value Priors},
	Volume = {31},
	Year = {2012}}	

@article{larsen:lahiri,
	Author = {P Lahiri and Michael D Larsen},
	Journal = {Journal of the American Statistical Association},
	Number = {469},
	Pages = {222-230},
	Publisher = {Taylor & Francis},
	Title = {Regression Analysis With Linked Data},
	Volume = {100},
	Year = {2005}}

@article{kaplan2018posterior,
  title={Posterior Prototyping: Bridging the Gap between {B}ayesian Record Linkage and Regression},
  author={Kaplan, Andee and Betancourt, Brenda and Steorts, Rebecca C},
  journal={arXiv e-prints},
  note={{arxiv:1810.01538}},
  year={2018}
}


@article{steorts_bayesian_2016,
	title = {A {B}ayesian Approach to Graphical Record Linkage and Deduplication},
	volume = {111},
	issn = {0162-1459},
	doi = {10.1080/01621459.2015.1105807},
	language = {en},
	number = {516},
	urldate = {2017-06-08},
	journal = {Journal of the American Statistical Association},
	author = {Steorts, Rebecca C. and Hall, Rob and Fienberg, Stephen E.},
	year = {2016},
	pages = {1660--1672}
}

@article{enamorado2019using,
  title={Using a Probabilistic Model to Assist Merging of Large-Scale Administrative Records},
  author={Ted Enamorado and Benjamin Fifield and Kosuke Imai},
  journal={American Political Science Review},
  year={2019},
  volume={113},
  pages={353-371}
}

@phdthesis{hoover2011repertoires,
	Author = {{Hoover Green}, Amelia},
	School = {Yale University, Department of Political Science},
	Title = {Repertoires of Violence Against Noncombatants: The Role of Armed Group Institutions and Ideology},
	Year = 2011,
}	


@article{green2019civilian,
  title={Civilian Killings and Disappearances During Civil War in {El} {S}alvador (1980--1992)},
  author={Green, Amelia Hoover and Ball, Patrick},
  journal={Demographic Research},
  volume={41},
  pages={781--814},
  year={2019},
  publisher={JSTOR}
}

@article{sadinle2018bayesian,
  title={{B}ayesian Propagation of Record Linkage Uncertainty Into Population Size Estimation of Human Rights Violations},
  author={Sadinle, Mauricio},
  journal={The Annals of Applied Statistics},
  volume={12},
  number={2},
  pages={1013--1038},
  year={2018},
  publisher={Institute of Mathematical Statistics}
}

@article{sadinle_generalized_2013,
	title = {A {Generalized} {Fellegi}-{Sunter} {Framework} for {Multiple} {Record} {Linkage} {With} {Application} to {Homicide} {Record} {Systems}},
	volume = {108},
	issn = {0162-1459},
	doi = {10.1080/01621459.2012.757231},
	language = {en},
	number = {502},
	urldate = {2017-07-06},
	journal = {Journal of the American Statistical Association},
	author = {Sadinle, Mauricio and Fienberg, Stephen E.},
	year = {2013},
	keywords = {EM algorithm, data matching, mixture model, Bell number, Census undercount, Data linkage, Multiple systems estimation, Partially ordered set},
	pages = {385--397}
}

@article{jain_split-merge_2004,
	title = {A {Split}-{Merge} {Markov} chain {Monte} {Carlo} {Procedure} for the {Dirichlet} {Process} {Mixture} {Model}},
	volume = {13},
	issn = {1061-8600, 1537-2715},
	doi = {10.1198/1061860043001},
	language = {en},
	number = {1},
	urldate = {2017-08-14},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Jain, Sonia and Neal, Radford M.},
	year = {2004},
	pages = {158--182}
}

@article{fritsch_improved_2009,
	title = {Improved criteria for clustering based on the posterior similarity matrix},
	volume = {4},
	issn = {1936-0975, 1931-6690},
	doi = {10.1214/09-BA414},
	abstract = {In this paper we address the problem of obtaining a single clustering estimate c{\textasciicircum}c{\textasciicircum}{\textbackslash}hat\{c\} based on an MCMC sample of clusterings c(1),c(2)…,c(M)c(1),c(2)…,c(M)c{\textasciicircum}\{(1)\},c{\textasciicircum}\{(2)\}{\textbackslash}ldots,c{\textasciicircum}\{(M)\} from the posterior distribution of a Bayesian cluster model. Methods to derive c{\textasciicircum}c{\textasciicircum}{\textbackslash}hat\{c\} when the number of groups KKK varies between the clusterings are reviewed and discussed. These include the maximum a posteriori (MAP) estimate and methods based on the posterior similarity matrix, a matrix containing the posterior probabilities that the observations iii and jjj are in the same cluster. The posterior similarity matrix is related to a commonly used loss function by Binder (1978). Minimization of the loss is shown to be equivalent to maximizing the Rand index between estimated and true clustering. We propose new criteria for estimating a clustering, which are based on the posterior expected adjusted Rand index. The criteria are shown to possess a shrinkage property and outperform Binder's loss in a simulation study and in an application to gene expression data. They also perform favorably compared to other clustering procedures.},
	language = {EN},
	number = {2},
	urldate = {2017-09-27},
	journal = {Bayesian Analysis},
	author = {Fritsch, Arno and Ickstadt, Katja},
	year = {2009},
	mrnumber = {MR2507368},
	zmnumber = {1330.62249},
	keywords = {Markov chain Monte Carlo, Dirichlet process mixture model, adjusted Rand index, cluster analysis},
	pages = {367--391}
}

@article{newman_distributed_2009,
	title = {Distributed algorithms for topic models},
	volume = {10},
	abstract = {We describe distributed algorithms for two widely-used topic models, namely the Latent Dirichlet Allocation (LDA) model, and the Hierarchical Dirichet Process (HDP) model. In our distributed algorithms the data is partitioned across separate processors and inference is done in a parallel, distributed fashion. We propose two distributed algorithms for LDA. The first algorithm is a straightforward mapping of LDA to a distributed processor setting. In this algorithm processors concurrently perform Gibbs sampling over local data followed by a global update of topic counts. The algorithm is simple to implement and can be viewed as an approximation to Gibbs-sampled LDA. The second version is a model that uses a hierarchical Bayesian extension of LDA to directly account for distributed data. This model has a theoretical guarantee of convergence but is more complex to implement than the first algorithm. Our distributed algorithm for HDP takes the straightforward mapping approach, and merges newly-created topics either by matching or by topic-id. Using five real-world text corpora we show that distributed learning works well in practice. For both LDA and HDP, we show that the converged test-data log probability for distributed learning is indistinguishable from that obtained with single-processor learning. Our extensive experimental results include learning topic models for two multi-million document collections using a 1024-processor parallel computer.},
	number = {Aug},
	journal = {Journal of Machine Learning Research},
	author = {Newman, David and Asuncion, Arthur and Smyth, Padhraic and Welling, Max},
	editor = {McCallum, Andrew},
	year = {2009},
	pages = {1801--1828}
}

@article{lovell_clustercluster:_2013,
	title = {{ClusterCluster}: {Parallel} {Markov} {Chain} {Monte} {Carlo} for {Dirichlet} {Process} {Mixtures}},
	shorttitle = {{ClusterCluster}},
	abstract = {The Dirichlet process (DP) is a fundamental mathematical tool for Bayesian nonparametric modeling, and is widely used in tasks such as density estimation, natural language processing, and time series modeling. Although MCMC inference methods for the DP often provide a gold standard in terms asymptotic accuracy, they can be computationally expensive and are not obviously parallelizable. We propose a reparameterization of the Dirichlet process that induces conditional independencies between the atoms that form the random measure. This conditional independence enables many of the Markov chain transition operators for DP inference to be simulated in parallel across multiple cores. Applied to mixture modeling, our approach enables the Dirichlet process to simultaneously learn clusters that describe the data and superclusters that define the granularity of parallelization. Unlike previous approaches, our technique does not require alteration of the model and leaves the true posterior distribution invariant. It also naturally lends itself to a distributed software implementation in terms of Map-Reduce, which we test in cluster configurations of over 50 machines and 100 cores. We present experiments exploring the parallel efficiency and convergence properties of our approach on both synthetic and real-world data, including runs on 1MM data vectors in 256 dimensions.},
	urldate = {2018-01-11},
	journal = {arXiv e-prints},
	author = {Lovell, Dan and Malmaud, Jonathan and Adams, Ryan P. and Mansinghka, Vikash K.},
	year = {2013},
	note = {{arxiv:1304.2302}},
	keywords = {Computer Science - Learning, Statistics - Machine Learning, Computer Science - Distributed, Parallel, and Cluster Computing},
	annote = {Comment: 12 pages, 10 figures. Submitted to ICML 2013 during third submission cycle}
}

@inbook{liang_permutation-augmented_2007,
	address = {New York, NY, USA},
	series = {{ICML} '07},
	title = {A {Permutation}-augmented {Sampler} for {DP} {Mixture} {Models}},
	isbn = {978-1-59593-793-3},
	doi = {10.1145/1273496.1273565},
	abstract = {We introduce a new inference algorithm for Dirichlet process mixture models. While Gibbs sampling and variational methods focus on local moves, the new algorithm makes more global moves. This is done by introducing a permutation of the data points as an auxiliary variable. The algorithm is a blocked sampler which alternates between sampling the clustering and sampling the permutation. The key to the efficiency of this approach is that it is possible to use dynamic programming to consider all exponentially many clusterings consistent with a given permutation. We also show that random projections can be used to effectively sample the permutation. The result is a stochastic hill-climbing algorithm that yields burn-in times significantly smaller than those of collapsed Gibbs sampling.},
	urldate = {2018-03-23},
	booktitle = {Proceedings of the 24th {International} {Conference} on {Machine} {Learning}},
	publisher = {ACM},
	author = {Liang, Percy and Jordan, Michael I. and Taskar, Ben},
	year = {2007},
	pages = {545--552}
}

@techreport{haramoto_efficient_2006,
	title = {Efficient jump ahead for {F}2-linear random number generators},
	abstract = {The fastest long-period random number generators currently available are based on linear re-currences modulo 2. So far, software that provides multiple disjoint streams and substreams has not been available for these generators because of the lack of efficient jump-ahead fa-cilities. In principle, it suffices to multiply the state (a k-bit vector) by an appropriate k × k binary matrix to find the new state far ahead in the sequence. However, when k is large (e.g., for a generator such as the popular Mersenne twister, for which k = 19937), this matrix-vector multiplication is slow and a large amount of memory is required to store the k × k matrix. In this paper, we provide a faster algorithm to jump ahead by a large number of steps in a linear recurrence modulo 2. The method uses much less than the k 2 bits of memory required by the matrix method. It is based on polynomial calculus modulo the characteristic polynomial of the recurrence and uses a sliding window algorithm for the multiplication. Key words: simulation; random number generation; jumping ahead; multiple streams 1.},
	author = {Haramoto, Hiroshi and Matsumoto, Makoto and Nishimura, Takuji and Panneton, François},
	year = {2006}
}

@article{yujian_normalized_2007,
	title = {A {Normalized} {Levenshtein} {Distance} {Metric}},
	volume = {29},
	issn = {0162-8828},
	doi = {10.1109/TPAMI.2007.1078},
	abstract = {Although a number of normalized edit distances presented so far may offer good performance in some applications, none of them can be regarded as a genuine metric between strings because they do not satisfy the triangle inequality. Given two strings X and Y over a finite alphabet, this paper defines a new normalized edit distance between X and Y as a simple function of their lengths ({\textbar}X{\textbar} and {\textbar}Y{\textbar}) and the Generalized Levenshtein Distance (GLD) between them. The new distance can be easily computed through GLD with a complexity of O({\textbar}X{\textbar} cdot {\textbar}Y{\textbar}) and it is a metric valued in [0, 1] under the condition that the weight function is a metric over the set of elementary edit operations with all costs of insertions/deletions having the same weight. Experiments using the AESA algorithm in handwritten digit recognition show that the new distance can generally provide similar results to some other normalized edit distances and may perform slightly better if the triangle inequality is violated in a particular data set.},
	number = {6},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Yujian, Li and Bo, Liu},
	year = {2007},
	keywords = {Algorithms, Artificial Intelligence, Information Storage and Retrieval, Models, Statistical, Pattern Recognition, Automated, Signal processing algorithms, AESA., Biomedical signal processing, Computational biology, Cost function, Error correction, Handwriting recognition, Image Enhancement, Image Interpretation, Computer-Assisted, Image recognition, Imaging, Three-Dimensional, Information retrieval, Levenshtein distance, metric, normalized edit distance, Pattern recognition, Sequence comparison, Sequences},
	pages = {1091--1095}
}

@inbook{ge_distributed_2015,
	address = {Lille, France},
	series = {Proceedings of {Machine} {Learning} {Research}},
	title = {Distributed {Inference} for {Dirichlet} {Process} {Mixture} {Models}},
	volume = {37},
	abstract = {Bayesian nonparametric mixture models based on the Dirichlet process (DP) have been widely used for solving problems like clustering, density estimation and topic modelling. These models make weak assumptions about the underlying process that generated the observed data. Thus, when more data are collected, the complexity of these models can change accordingly. These theoretical properties often lead to superior predictive performance when compared to traditional finite mixture models. However, despite the increasing amount of data available, the application of Bayesian nonparametric mixture models is so far limited to relatively small data sets. In this paper, we propose an efficient distributed inference algorithm for the DP and the HDP mixture model. The proposed method is based on a variant of the slice sampler for DPs. Since this sampler does not involve a pre-determined truncation, the stationary distribution of the sampling algorithm is unbiased. We provide both local thread-level and distributed machine-level parallel implementations and study the performance of this sampler through an extensive set of experiments on image and text data. When compared to existing inference algorithms, the proposed method exhibits state-of-the-art accuracy and strong scalability with up to 512 cores.},
	booktitle = {Proceedings of the 32nd {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Ge, Hong and Chen, Yutian and Wan, Moquan and Ghahramani, Zoubin},
	editor = {Bach, Francis and Blei, David},
	year = {2015},
	pages = {2276--2284}
}

@inbook{chang_parallel_2013,
	address = {NY, USA},
	series = {{NIPS}'13},
	title = {Parallel {Sampling} of {DP} {Mixture} {Models} {Using} {Sub}-clusters {Splits}},
	volume = {1},
	booktitle = {Proceedings of the 26th {International} {Conference} on {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates Inc.},
	author = {Chang, Jason and Fisher, III, John W.},
	year = {2013},
	pages = {620--628}
}

@inbook{williamson_parallel_2013,
	address = {Atlanta, Georgia, USA},
	series = {Proceedings of {Machine} {Learning} {Research}},
	title = {Parallel {Markov} {Chain} {Monte} {Carlo} for {Nonparametric} {Mixture} {Models}},
	volume = {28},
	abstract = {Nonparametric mixture models based on the Dirichlet process are an elegant alternative to finite models when the number of underlying components is unknown, but inference in such models can be slow. Existing attempts to parallelize inference in such models have relied on introducing approximations, which can lead to inaccuracies in the posterior estimate. In this paper, we describe auxiliary variable representations for the Dirichlet process and the hierarchical Dirichlet process that allow us to perform MCMC using the correct equilibrium distribution, in a distributed manner. We show that our approach allows scalable inference without the deterioration in estimate quality that accompanies existing methods.},
	booktitle = {Proceedings of the 30th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Williamson, Sinead and Dubey, Avinava and Xing, Eric},
	editor = {Dasgupta, Sanjoy and McAllester, David},
	year = {2013},
	pages = {98--106}
}

@article{zanella_flexible_2016,
	address = {NY, USA},
	series = {{NIPS}'16},
	title = {Flexible Models for Microclustering with Application to Entity Resolution},
	isbn = {978-1-5108-3881-9},
	journal = {Proceedings of the 30th {International} {Conference} on {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates Inc.},
	author = {Zanella, Giacomo and Betancourt, Brenda and Wallach, Hanna and Miller, Jeffrey and Zaidi, Abbas and Steorts, Rebecca C.},
	year = {2016},
	pages = {1425--1433}
}

@article{steorts_performance_2017,
	address = {Fort Lauderdale, FL, USA},
	series = {Proceedings of {Machine} {Learning} {Research}},
	title = {Performance Bounds for Graphical Record Linkage},
	volume = {54},
	journal = {Proceedings of the 20th {International} {Conference} on {Artificial} {Intelligence} and {Statistics}},
	publisher = {PMLR},
	author = {Steorts, Rebecca C. and Barnes, Mattew and Neiswanger, Willie},
	editor = {Singh, Aarti and Zhu, Jerry},
	year = {2017},
	pages = {298--306}
}

@article{vinh_information_2010,
	title = {Information theoretic measures for clusterings comparison: {Variants}, properties, normalization and correction for chance},
	volume = {11},
	shorttitle = {Information theoretic measures for clusterings comparison},
	number = {Oct},
	journal = {Journal of Machine Learning Research},
	author = {Vinh, Nguyen Xuan and Epps, Julien and Bailey, James},
	year = {2010},
	pages = {2837--2854}
}

@article{tierney_markov_1994,
	title = {Markov {Chains} for {Exploring} {Posterior} {Distributions}},
	volume = {22},
	issn = {0090-5364, 2168-8966},
	doi = {10.1214/aos/1176325750},
	abstract = {Several Markov chain methods are available for sampling from a posterior distribution. Two important examples are the Gibbs sampler and the Metropolis algorithm. In addition, several strategies are available for constructing hybrid algorithms. This paper outlines some of the basic methods and strategies and discusses some related theoretical and practical issues. On the theoretical side, results from the theory of general state space Markov chains can be used to obtain convergence rates, laws of large numbers and central limit theorems for estimates obtained from Markov chain methods. These theoretical results can be used to guide the construction of more efficient algorithms. For the practical use of Markov chain methods, standard simulation methodology provides several variance reduction techniques and also give guidance on the choice of sample size and allocation.},
	language = {EN},
	number = {4},
	journal = {The Annals of Statistics},
	author = {Tierney, Luke},
	year = {1994},
	mrnumber = {MR1329166},
	zmnumber = {0829.62080},
	keywords = {62-04, Gibbs sampler, Metropolis-Hastings algorithm, Monte Carlo, variance reduction},
	pages = {1701--1728}
}

@inbook{wallach_alternative_2010,
	address = {Chia Laguna Resort, Sardinia, Italy},
	series = {Proceedings of {Machine} {Learning} {Research}},
	title = {An Alternative Prior Process for Nonparametric {B}ayesian Clustering},
	volume = {9},
	abstract = {Prior distributions play a crucial role in Bayesian approaches to clustering. Two commonly-used prior distributions are the Dirichlet and Pitman-Yor processes. In this paper, we investigate the predictive probabilities that underlie these processes, and the implicit “rich-get-richer” characteristic of the resulting partitions. We explore an alternative prior for nonparametric Bayesian clustering, the uniform process, for applications where the “rich-get-richer” property is undesirable. We also explore the cost of this new process: partitions are no longer exchangeable with respect to the ordering of variables. We present new asymptotic and simulation-based results for the clustering characteristics of the uniform process and compare these with known results for the Dirichlet and Pitman-Yor processes. Finally, we compare performance on a real document clustering task, demonstrating the practical advantage of the uniform process despite its lack of exchangeability over orderings.},
	booktitle = {Proceedings of the {Thirteenth} {International} {Conference} on {Artificial} {Intelligence} and {Statistics}},
	publisher = {PMLR},
	author = {Wallach, Hanna and Jensen, Shane and Dicker, Lee and Heller, Katherine},
	editor = {Teh, Yee Whye and Titterington, Mike},
	year = {2010},
	pages = {892--899}
}

@article{gnedin_exchangeable_2006,
	title = {Exchangeable {Gibbs} partitions and {Stirling} triangles},
	volume = {138},
	issn = {1072-3374, 1573-8795},
	doi = {10.1007/s10958-006-0335-z},
	abstract = {For two collections of nonnegative and suitably normalized weights W = (Wj) and V = (Vn,k), a probability distribution on the set of partitions of the set \{1, …, n\} is defined by assigning to a generic partition \{Aj, j ≤ k\} the probability Vn,k Vn,kW{\textbar}A1{\textbar}⋯W{\textbar}Ak{\textbar}Vn,kW{\textbar}A1{\textbar}⋯W{\textbar}Ak{\textbar}V\_\{n,k\} W\_\{{\textbackslash}left{\textbar} \{A\_1 \} {\textbackslash}right{\textbar}\} {\textbackslash}cdots W\_\{{\textbackslash}left{\textbar} \{A\_k \} {\textbackslash}right{\textbar}\} , where {\textbar}Aj{\textbar} is the number of elements of Aj. We impose constraints on the weights by assuming that the resulting random partitions Π n of [n] are consistent as n varies, meaning that they define an exchangeable partition of the set of all natural numbers. This implies that the weights W must be of a very special form depending on a single parameter α ∈ [− ∞, 1]. The case α = 1 is trivial, and for each value of α ≠ = 1 the set of possible V-weights is an infinite-dimensional simplex. We identify the extreme points of the simplex by solving the boundary problem for a generalized Stirling triangle. In particular, we show that the boundary is discrete for − ∞ ≤ α {\textless} 0 and continuous for 0 ≤ α {\textless} 1. For α ≤ 0 the extremes correspond to the members of the Ewens-Pitman family of random partitions indexed by (α,θ), while for 0 {\textless} α {\textless} 1 the extremes are obtained by conditioning an (α,θ)-partition on the asymptotics of the number of blocks of Πn as n tends to infinity. Bibliography: 29 titles.},
	language = {en},
	number = {3},
	journal = {Journal of Mathematical Sciences},
	author = {Gnedin, Alexander and Pitman, Jim},
	year = {2006},
	pages = {5674--5685}
}

@article{buntine_bayesian_2010,
	title = {A {Bayesian} View of the {Poisson}-{Dirichlet} Process},
	abstract = {The two parameter Poisson-Dirichlet Process (PDP), a generalisation of the Dirichlet Process, is increasingly being used for probabilistic modelling in discrete areas such as language technology, bioinformatics, and image analysis. There is a rich literature about the PDP and its derivative distributions such as the Chinese Restaurant Process (CRP). This article reviews some of the basic theory and then the major results needed for Bayesian modelling of discrete problems including details of priors, posteriors and computation. The PDP allows one to build distributions over countable partitions. The PDP has two other remarkable properties: first it is partially conjugate to itself, which allows one to build hierarchies of PDPs, and second using a marginalised relative the CRP, one gets fragmentation and clustering properties that lets one layer partitions to build trees. This article presents the basic theory for understanding the notion of partitions and distributions over them, the PDP and the CRP, and the important properties of conjugacy, fragmentation and clustering, as well as some key related properties such as consistency and convergence. This article also presents a Bayesian interpretation of the Poisson-Dirichlet process based on an improper and infinite dimensional Dirichlet distribution. This means we can understand the process as just another Dirichlet and thus all its sampling properties emerge naturally. The theory of PDPs is usually presented for continuous distributions (more generally referred to as non-atomic distributions), however, when applied to discrete distributions its remarkable conjugacy property emerges. This context and basic results are also presented, as well as techniques for computing the second order Stirling numbers that occur in the posteriors for discrete distributions.},
	urldate = {2018-06-07},
	journal = {arXiv e-prints},
	author = {Buntine, Wray and Hutter, Marcus},
	year = {2010},
	note = {{arxiv:1007.0296}},
	keywords = {Computer Science - Learning, Mathematics - Statistics Theory, Mathematics - Probability},
	annote = {Comment: 50 LaTeX pages, 10 figures, 3 tables, 1 algorithm}
}

@article{marzal_computation_1993,
	title = {Computation of normalized edit distance and applications},
	volume = {15},
	issn = {0162-8828},
	doi = {10.1109/34.232078},
	abstract = {Given two strings X and Y over a finite alphabet, the normalized edit distance between X and Y, d(X,Y) is defined as the minimum of W(P)/L(P), where P is an editing path between X and Y, W(P) is the sum of the weights of the elementary edit operations of P, and L(P) is the number of these operations (length of P). It is shown that in general, d(X ,Y) cannot be computed by first obtaining the conventional (unnormalized) edit distance between X and Y and then normalizing this value by the length of the corresponding editing path. In order to compute normalized edit distances, an algorithm that can be implemented to work in O(m×n2) time and O( n2) memory space is proposed, where m and n are the lengths of the strings under consideration, and m ⩾n. Experiments in hand-written digit recognition are presented, revealing that the normalized edit distance consistently provides better results than both unnormalized or post-normalized classical edit distances},
	number = {9},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Marzal, Andrés and Vidal, Enrique},
	year = {1993},
	keywords = {Error correction, normalized edit distance, Pattern recognition, Character recognition, character strings, computational complexity, finite alphabet, hand-written digit recognition, Optical character recognition software, pattern recognition, Speech recognition, words},
	pages = {926--932}
}

@article{zanella_informed_2017,
	title = {Informed proposals for local {MCMC} in discrete spaces},
	abstract = {There is a lack of methodological results to design efficient Markov chain Monte Carlo (MCMC) algorithms for statistical models with discrete-valued high-dimensional parameters. Motivated by this consideration, we propose a simple framework for the design of informed MCMC proposals (i.e. Metropolis-Hastings proposal distributions that appropriately incorporate local information about the target) which is naturally applicable to both discrete and continuous spaces. We explicitly characterize the class of optimal proposal distributions under this framework, which we refer to as locally-balanced proposals, and prove their Peskun-optimality in high-dimensional regimes. The resulting algorithms are straightforward to implement in discrete spaces and provide orders of magnitude improvements in efficiency compared to alternative MCMC schemes, including discrete versions of Hamiltonian Monte Carlo. Simulations are performed with both simulated and real datasets, including a detailed application to Bayesian record linkage. A direct connection with gradient-based MCMC suggests that locally-balanced proposals may be seen as a natural way to extend the latter to discrete spaces.},
	urldate = {2018-06-07},
	journal = {arxiv e-prints},
	author = {Zanella, Giacomo},
	year = {2017},
	note = {{arxiv:1711.07424}},
	keywords = {Statistics - Computation, Mathematics - Probability},
	annote = {Comment: 20 pages + 14 pages of supplementary, 10 figures}
}

@article{dyk_partially_2008,
	title = {Partially {Collapsed} {Gibbs} {Samplers}},
	volume = {103},
	issn = {0162-1459},
	doi = {10.1198/016214508000000409},
	abstract = {Ever-increasing computational power, along with ever–more sophisticated statistical computing techniques, is making it possible to fit ever–more complex statistical models. Among the more computationally intensive methods, the Gibbs sampler is popular because of its simplicity and power to effectively generate samples from a high-dimensional probability distribution. Despite its simple implementation and description, however, the Gibbs sampler is criticized for its sometimes slow convergence, especially when it is used to fit highly structured complex models. Here we present partially collapsed Gibbs sampling strategies that improve the convergence by capitalizing on a set of functionally incompatible conditional distributions. Such incompatibility generally is avoided in the construction of a Gibbs sampler, because the resulting convergence properties are not well understood. We introduce three basic tools (marginalization, permutation, and trimming) that allow us to transform a Gibbs sampler into a partially collapsed Gibbs sampler with known stationary distribution and faster convergence.},
	number = {482},
	urldate = {2018-06-07},
	journal = {Journal of the American Statistical Association},
	author = {Dyk, David A. van and Park, Taeyoung},
	year = {2008},
	keywords = {Gibbs sampler, Blocking, Incompatible Gibbs sampler, Marginal data augmentation, Rate of convergence},
	pages = {790--796}
}

@article{vose_linear_1991,
	title = {A linear algorithm for generating random numbers with a given distribution},
	volume = {17},
	issn = {0098-5589},
	doi = {10.1109/32.92917},
	abstract = {Let ξ be a random variable over a finite set with an arbitrary probability distribution. Improvements to a fast method of generating sample values for ξ in constant time are suggested. The proposed modification reduces the time required for initialization to O( n). For a simple genetic algorithm, this improvement changes an O(g n 1n n) algorithm into an O(g n) algorithm (where g is the number of generations, and n is the population size)},
	number = {9},
	journal = {IEEE Transactions on Software Engineering},
	author = {Vose, Michael D.},
	year = {1991},
	keywords = {Computational modeling, Computer science, Genetic algorithms, Probability distribution, probability, arbitrary probability distribution, finite set, genetic algorithms, linear algorithm, random number generation, Random number generation, random numbers, random variable, Random variables, Roundoff errors, simple genetic algorithm},
	pages = {972--975}
}

@article{lecuyer_good_1999,
	title = {Good {Parameters} and {Implementations} for {Combined} {Multiple} {Recursive} {Random} {Number} {Generators}},
	volume = {47},
	issn = {0030-364X},
	doi = {10.1287/opre.47.1.159},
	abstract = {Combining parallel multiple recursive sequences provides an efficient way of implementing random number generators with long periods and good structural properties. Such generators are statistically more robust than simple linear congruential generators that fit into a computer word. We made extensive computer searches for good parameter sets, with respect to the spectral test, for combined multiple recursive generators of different sizes. We also compare different implementations and give a specific code in C that is faster than previous implementations of similar generators.},
	number = {1},
	urldate = {2018-06-07},
	journal = {Operations Research},
	author = {L'Ecuyer, Pierre},
	year = {1999},
	pages = {159--164}
}

@inbook{lomeli_hybrid_2015,
	address = {Cambridge, MA, USA},
	series = {{NIPS}'15},
	title = {A {Hybrid} {Sampler} for {Poisson}-{Kingman} {Mixture} {Models}},
	volume = {2},
	abstract = {This paper concerns the introduction of a new Markov Chain Monte Carlo scheme for posterior sampling in Bayesian nonparametric mixture models with priors that belong to the general Poisson-Kingman class. We present a novel compact way of representing the infinite dimensional component of the model such that while explicitly representing this infinite component it has less memory and storage requirements than previous MCMC schemes. We describe comparative simulation results demonstrating the efficacy of the proposed MCMC algorithm against existing marginal and conditional MCMC samplers.},
	urldate = {2018-06-07},
	booktitle = {Proceedings of the 28th {International} {Conference} on {Neural} {Information} {Processing} {Systems}},
	publisher = {MIT Press},
	author = {Lomelí, María and Favaro, Stefano and Teh, Yee Whye},
	year = {2015},
	pages = {2161--2169}
}

@article{steorts_entity_2015,
	title = {Entity {Resolution} with {Empirically} {Motivated} {Priors}},
	volume = {10},
	issn = {1936-0975, 1931-6690},
	doi = {10.1214/15-BA965SI},
	abstract = {Databases often contain corrupted, degraded, and noisy data with duplicate entries across and within each database. Such problems arise in citations, medical databases, genetics, human rights databases, and a variety of other applied settings. The target of statistical inference can be viewed as an unsupervised problem of determining the edges of a bipartite graph that links the observed records to unobserved latent entities. Bayesian approaches provide attractive benefits, naturally providing uncertainty quantification via posterior probabilities. We propose a novel record linkage approach based on empirical Bayesian principles. Specifically, the empirical Bayesian-type step consists of taking the empirical distribution function of the data as the prior for the latent entities. This approach improves on the earlier HB approach not only by avoiding the prior specification problem but also by allowing both categorical and string-valued variables. Our extension to string-valued variables also involves the proposal of a new probabilistic mechanism by which observed record values for string fields can deviate from the values of their associated latent entities. Categorical fields that deviate from their corresponding true value are simply drawn from the empirical distribution function. We apply our proposed methodology to a simulated data set of German names and an Italian household survey on income and wealth, showing our method performs favorably compared to several standard methods in the literature. We also consider the robustness of our methods to changes in the hyper-parameters.},
	language = {EN},
	number = {4},
	journal = {Bayesian Analysis},
	author = {Steorts, Rebecca C.},
	year = {2015},
	mrnumber = {MR3432242},
	zmnumber = {1335.62023},
	pages = {849--875}
}

@incollection{bhattacharya_latent_2006,
	series = {Proceedings},
	title = {A {Latent} {Dirichlet} {Model} for {Unsupervised} {Entity} {Resolution}},
	isbn = {978-0-89871-611-5},
	abstract = {Entity resolution has received considerable attention in recent years. Given many references to underlying entities, the goal is to predict which references correspond to the same entity. We show how to extend the Latent Dirichlet Allocation model for this task and propose a probabilistic model for collective entity resolution for relational domains where references are connected to each other. Our approach differs from other recently proposed entity resolution approaches in that it is a) generative, b) does not make pair-wise decisions and c) captures relations between entities through a hidden group variable. We propose a novel sampling algorithm for collective entity resolution which is unsupervised and also takes entity relations into account. Additionally, we do not assume the domain of entities to be known and show how to infer the number of entities from the data. We demonstrate the utility and practicality of our relational entity resolution approach for author resolution in two real-world bibliographic datasets. In addition, we present preliminary results on characterizing conditions under which relational information is useful.},
	urldate = {2018-06-13},
	booktitle = {Proceedings of the 2006 {SIAM} {International} {Conference} on {Data} {Mining}},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Bhattacharya, Indrajit and Getoor, Lise},
	year = {2006},
	doi = {10.1137/1.9781611972764.5},
	pages = {47--58}
}



@techreport{CCES:17ajps,
	Author = {Ansolabehere, Stephen and Schaffner, Brian and Luks, Sam},
	Date-Modified = {2018-07-15 20:43:52 +0000},
	Institution = {Harvard University},
	Note = {Data Release No. 2},
	Title = {Guide to the 2016 Cooperative Congressional Election Survey},
	Url = {\url{https://dataverse.harvard.edu/file.xhtml?persistentId=doi:10.7910/DVN/GDF6Z0/RK0ONG&version=4.0}},
	Year = {2017},
	Bdsk-Url-1 = {https://dataverse.harvard.edu/file.xhtml?persistentId=doi:10.7910/DVN/GDF6Z0/RK0ONG&version=4.0}}
	
@techreport{anes16meth,
	Address = {Ann Arbor, MI and Palo Alto, CA},
	Author = {Matthew DeBell and Michelle Amsbary and Vanessa Meldener and Shelly Brock and Natalya Maisel},
	Date-Added = {2018-03-02 06:18:07 +0000},
	Date-Modified = {2018-07-15 20:48:13 +0000},
	Institution = {Stanford University and the University of Michigan.},
	Title = {Methodology Report for the ANES 2016 Time Series Study.},
	Year = {2016}
	}
	

@misc{bilenko2006riddle,
  title={Riddle: Repository of Information on Duplicate Detection, Record Linkage, and Identity Uncertainty},
  author={Bilenko, Misha and Mooney, R},
  year={2006},
  note={Online; retrieved July 29, 2020; \url{http://www.cs.utexas.edu/users/ml/riddle/}},
  url={http://www.cs.utexas.edu/users/ml/riddle/}
}

@article{sadinle_bayesian_2017,
	title = {Bayesian Estimation of Bipartite Matchings for Record Linkage},
	volume = {112},
	issn = {0162-1459},
	doi = {10.1080/01621459.2016.1148612},
	abstract = {The bipartite record linkage task consists of merging two disparate datafiles containing information on two overlapping sets of entities. This is nontrivial in the absence of unique identifiers and it is important for a wide variety of applications given that it needs to be solved whenever we have to combine information from different sources. Most statistical techniques currently used for record linkage are derived from a seminal article by Fellegi and Sunter in 1969. These techniques usually assume independence in the matching statuses of record pairs to derive estimation procedures and optimal point estimators. We argue that this independence assumption is unreasonable and instead target a bipartite matching between the two datafiles as our parameter of interest. Bayesian implementations allow us to quantify uncertainty on the matching decisions and derive a variety of point estimators using different loss functions. We propose partial Bayes estimates that allow uncertain parts of the bipartite matching to be left unresolved. We evaluate our approach to record linkage using a variety of challenging scenarios and show that it outperforms the traditional methodology. We illustrate the advantages of our methods merging two datafiles on casualties from the civil war of El Salvador. Supplementary materials for this article are available online.},
	number = {518},
	urldate = {2018-06-13},
	journal = {Journal of the American Statistical Association},
	author = {Sadinle, Mauricio},
	year = {2017},
	keywords = {Assignment problem, Bayes estimate, Data matching, Fellegi–Sunter decision rule, Mixture model, Reject option},
	pages = {600--612}
}

@article{gutman_bayesian_2013,
	title = {A {Bayesian} Procedure for File Linking to Analyze End-of-Life Medical Costs},
	volume = {108},
	issn = {0162-1459},
	doi = {10.1080/01621459.2012.726889},
	abstract = {End-of-life medical expenses are a significant proportion of all health care expenditures. These costs were studied using costs of services from Medicare claims and cause of death (CoD) from death certificates. In the absence of a unique identifier linking the two datasets, common variables identified unique matches for only 33\% of deaths. The remaining cases formed cells with multiple cases (32\% in cells with an equal number of cases from each file and 35\% in cells with an unequal number). We sampled from the joint posterior distribution of model parameters and the permutations that link cases from the two files within each cell. The linking models included the regression of location of death on CoD and other parameters, and the regression of cost measures with a monotone missing data pattern on CoD and other demographic characteristics. Permutations were sampled by enumerating the exact distribution for small cells and by the Metropolis algorithm for large cells. Sparse matrix data structures enabled efficient calculations despite the large dataset (≈1.7 million cases). The procedure generates m datasets in which the matches between the two files are imputed. The m datasets can be analyzed independently and results can be combined using Rubin’s multiple imputation rules. Our approach can be applied in other file-linking applications. Supplementary materials for this article are available online.},
	number = {501},
	urldate = {2018-06-13},
	journal = {Journal of the American Statistical Association},
	author = {Gutman, Roee and Afendulis, Christopher C. and Zaslavsky, Alan M.},
	year = {2013},
	pmid = {23645944},
	keywords = {Administrative data, Bayesian analysis, Missing data, Record linkage, Statistical matching},
	pages = {34--47}
}

@article{farley2020bayesian,
  title={A {B}ayesian Approach to Linking Data Without Unique Identifiers},
  author={Farley, Edwin and Gutman, Roee},
  journal={arXiv e-prints},
  year={2020},
  note={{arxiv:2012.00601}}
}


@article{bentley_multidimensional_1975,
	title = {Multidimensional {Binary} {Search} {Trees} {Used} for {Associative} {Searching}},
	volume = {18},
	issn = {0001-0782},
	doi = {10.1145/361002.361007},
	abstract = {This paper develops the multidimensional binary search tree (or k-d tree, where k is the dimensionality of the search space) as a data structure for storage of information to be retrieved by associative searches. The k-d tree is defined and examples are given. It is shown to be quite efficient in its storage requirements. A significant advantage of this structure is that a single data structure can handle many types of queries very efficiently. Various utility algorithms are developed; their proven average running times in an n record file are: insertion, O(log n); deletion of the root, O(n(k-1)/k); deletion of a random node, O(log n); and optimization (guarantees logarithmic performance of searches), O(n log n). Search algorithms are given for partial match queries with t keys specified [proven maximum running time of O(n(k-t)/k)] and for nearest neighbor queries [empirically observed average running time of O(log n).] These performances far surpass the best currently known algorithms for these tasks. An algorithm is presented to handle any general intersection query. The main focus of this paper is theoretical. It is felt, however, that k-d trees could be quite useful in many applications, and examples of potential uses are given.},
	number = {9},
	urldate = {2018-06-21},
	journal = {Commun. ACM},
	author = {Bentley, Jon Louis},
	year = {1975},
	keywords = {associative retrieval, attribute, binary search trees, binary tree insertion, information retrieval system, intersection queries, key, nearest neighbor queries, partial match queries},
	pages = {509--517}
}

@article{friedman_algorithm_1977,
	title = {An {Algorithm} for {Finding} {Best} {Matches} in {Logarithmic} {Expected} {Time}},
	volume = {3},
	issn = {0098-3500},
	doi = {10.1145/355744.355745},
	number = {3},
	urldate = {2018-06-21},
	journal = {ACM Trans. Math. Softw.},
	author = {Friedman, Jerome H. and Bentley, Jon Louis and Finkel, Raphael Ari},
	year = {1977},
	pages = {209--226}
}

@misc{liseo_2013,
	Author = {Liseo, Brunero and Tancredi, Andrea},
	Date-Modified = {2013-05-30 04:51:43 +0000},
	Title = {Some advances on {B}ayesian record linkage and inference for linked data},
	Url = {http://www.ine.es/e/essnetdi_ws2011/ppts/Liseo_Tancredi.pdf},
	Year = 2013,
	Bdsk-Url-1 = {http://www.ine.es/e/essnetdi_ws2011/ppts/Liseo_Tancredi.pdf}}
	

@ARTICLE{Fortinietal01,
  AUTHOR =       {Fortini, M. and Liseo, B. and Nuccitelli, A. and Scanu, M.},
  TITLE =        {On {B}ayesian Record Linkage},
  JOURNAL =      {Research in Official Statistics},
  YEAR =         {2001},
  NUMBER = 	 {1},
  VOLUME =	 {4},
  PAGES =	 {185--198},
}

@MISC{Larsen12,
  AUTHOR =       {Michael D. Larsen},
  TITLE =        {An Experiment with Hierarchical {B}ayesian Record Linkage},
  HOWPUBLISHED =      {arXiv e-prints},
  YEAR =         {2012},
  note={{arxiv:1212.5203}}
}

@PHDTHESIS{Matsakis10,
  AUTHOR =       {Nicholas Elias Matsakis},
  TITLE =        {Active Duplicate Detection with {B}ayesian Nonparametric Models},
  SCHOOL =      {Massachusetts Institute of Technology},
  YEAR =         {2010},
}

	
@article{christen_2012,
  title={A survey of indexing techniques for scalable record linkage and deduplication},
  author={Christen, Peter},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  volume={24},
  number={9},
  pages={1537--1555},
  year={2012},
  publisher={IEEE}
}
	

@book{Herzog_2007,
	Address = {New York, NY},
	Author = {Herzog, T.N. and Scheuren, F.J. and Winkler, W.E.},
	Publisher = {Springer},
	Title = {Data Quality and Record Linkage Techniques},
	Year = {2007}
}

@article{belin_1995,
	title = {A Method for Calibrating False-Match Rates in Record Linkage},
	volume = {90},
	issn = {0162-1459},
	doi = {10.2307/2291082},
	number = {430},
	journal = {Journal of the American Statistical Association},
	author = {Belin, Thomas R. and Rubin, Donald B.},
	year = {1995},
	pages = {694--707}
}

@article{larsen_2001,
	title = {Iterative {Automated} {Record} {Linkage} {Using} {Mixture} {Models}},
	volume = {96},
	issn = {0162-1459},
	doi = {10.1198/016214501750332956},
	abstract = {The goal of record linkage is to link quickly and accurately records that correspond to the same person or entity. Whereas certain patterns of agreements and disagreements on variables are more likely among records pertaining to a single person than among records for different people, the observed patterns for pairs of records can be viewed as arising from a mixture of matches and nonmatches. Mixture model estimates can be used to partition record pairs into two or more groups that can be labeled as probable matches (links) and probable nonmatches (nonlinks). A method is proposed and illustrated that uses marginal information in the database to select mixture models, identifies sets of records for clerks to review based on the models and marginal information, incorporates clerically reviewed data, as they become available, into estimates of model parameters, and classifies pairs as links, nonlinks, or in need of further clerical review. The procedure is illustrated with five datasets from the U.S. Bureau of the Census. It appears to be robust to variations in record-linkage sites. The clerical review corrects classifications of some pairs directly and leads to changes in classification of others through reestimation of mixture models.},
	number = {453},
	urldate = {2018-07-19},
	journal = {Journal of the American Statistical Association},
	author = {Larsen, Michael D. and Rubin, Donald B.},
	year = {2001},
	pages = {32--41}
}

@inbook{domingos_2004,
  title={Multi-relational record linkage},
  author={Domingos, Parag and Domingos, Pedro},
  booktitle={Proceedings of the KDD-2004 Workshop on Multi-Relational Data Mining},
  year={2004},
  organization={ACM}
}

	
@inbook{Larsen02,
  AUTHOR =       {Larsen, Michael D.},
  TITLE =        {Comments on Hierarchical {B}ayesian Record Linkage},
  BOOKTITLE =    {Proceedings of the Joint Statistical Meetings, Section on Survey Research Methods},
  YEAR =         {2002},
  ORGANIZATION = {The American Statistical Association},
  PAGES =	 {1995--2000},
} 


@inbook{Larsen05,
  AUTHOR =       {Larsen, Michael D.},
  TITLE =        {Advances in Record Linkage Theory: {H}ierarchical {B}ayesian Record Linkage Theory},
  BOOKTITLE =    {Proceedings of the Joint Statistical Meetings, Section on Survey Research Methods},
  YEAR =         {2005},
  ORGANIZATION = {The American Statistical Association},
  PAGES =	 {3277--3284}
} 

@article{murray2016probabilistic,
  title={Probabilistic Record Linkage and Deduplication after Indexing, Blocking, and Filtering},
  author={Murray, Jared S.},
  journal={Journal of Privacy and Confidentiality},
  volume={7},
  number={1},
  pages={3--24},
  year={2016}
}	

@Article{steorts14smered,
  author =       {Steorts, Rebecca C. and Hall, Rob and Fienberg, Stephen E.},
  title =        {{SMERED}: A {B}ayesian Approach to Graphical Record Linkage and De-duplication},
  journal =      {Journal of Machine Learning Research},
  year =         {2014},
  OPTkey =       {},
  volume =       {33},
  OPTnumber =    {},
  pages =        {922--930}
}


@techreport{winkler_overview_2006,
	title = {Overview of record linkage and current research directions},
	abstract = {This paper provides background on record linkage methods that can be used in combining data from a variety of sources such as person lists business lists. It also gives some areas of current research.},
	number = {Statistics \#2006-2},
	institution = {U.S. Bureau of the Census},
	author = {Winkler, William E.},
	year = {2006}
}

@techreport{winkler_state_1999,
	title = {The {State} of {Record} {Linkage} and {Current} {Research} {Problems}},
	abstract = {This paper provides an overview of methods and systems developed for record linkage. Modern record linkage begins with the pioneering work of Newcombe and is especially based on the formal mathematical model of Fellegi and Sunter. In their seminal work, Fellegi and Sunter introduced many powerful ideas for estimating record linkage parameters and other ideas that still influence record linkage today. Record linkage research is characterized by its synergism of statistics, computer science, and operations research. Many difficult algorithms have been developed and put in software systems. Record linkage practice is still very limited. Some limits are due to existing software. Other limits are due to the difficulty in automatically estimating matching parameters and error rates, with current research highlighted by the work of Larsen and Rubin.},
	institution = {Statistical Research Division, U.S. Bureau of the Census},
	author = {Winkler, William E.},
	year = {1999}
}

@article{sadinle_detecting_2014,
	title = {Detecting Duplicates in a Homicide Registry Using a {Bayesian} Partitioning Approach},
	volume = {8},
	issn = {1932-6157, 1941-7330},
	doi = {10.1214/14-AOAS779},
	language = {EN},
	number = {4},
	urldate = {2018-06-26},
	journal = {The Annals of Applied Statistics},
	author = {Sadinle, Mauricio},
	year = {2014},
	mrnumber = {MR3292503},
	zmnumber = {06408784},
	keywords = {Deduplication, distribution on partitions, duplicate detection, entity resolution, Hispanic names, homicide records, human rights, record linkage, string similarity, United Nations Truth Commission for El Salvador},
	pages = {2404--2434}
}

@article{fellegi_theory_1969,
	title = {A Theory for Record Linkage},
	volume = {64},
	issn = {0162-1459},
	doi = {10.1080/01621459.1969.10501049},
	number = {328},
	urldate = {2018-06-26},
	journal = {Journal of the American Statistical Association},
	author = {Fellegi, Ivan P. and Sunter, Alan B.},
	year = {1969},
	pages = {1183--1210}
}

@article{newcombe_automatic_1959,
	title = {Automatic Linkage of Vital Records},
	volume = {130},
	number = {3381},
	urldate = {2018-06-26},
	journal = {Science},
	author = {Newcombe, H. B. and Kennedy, J. M. and Axford, S. J. and James, A. P.},
	year = {1959},
	pmid = {14426783},
	pages = {954--959}
}

@inbook{tang2020,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Bayesian Modeling for Simultaneous Regression and Record Linkage},
	urldate = {2018-06-26},
	booktitle = {Privacy in {Statistical} {Databases}},
	publisher = {Springer, Cham},
	author = {Tang, Jiurui  and Reiter, Jerome and Steorts, Rebecca C.},
	year = {2020}
}

@article{steorts_comparison_2014,
	title = {A Comparison of Blocking Methods for Record Linkage},
	isbn = {978-3-319-11256-5 978-3-319-11257-2},
	doi = {10.1007/978-3-319-11257-2_20},
	language = {en},
	urldate = {2018-06-26},
	journal = {Privacy in {Statistical} {Databases}},
	publisher = {Springer, Cham},
	author = {Steorts, Rebecca C. and Ventura, Samuel L. and Sadinle, Mauricio and Fienberg, Stephen E.},
	year = {2014},
	pages = {253--268}
}


@article{geman_stochastic_1984,
	title = {Stochastic Relaxation, Gibbs Distributions, and the {Bayesian} Restoration of Images},
	volume = {PAMI-6},
	issn = {0162-8828},
	doi = {10.1109/TPAMI.1984.4767596},
	abstract = {We make an analogy between images and statistical mechanics systems. Pixel gray levels and the presence and orientation of edges are viewed as states of atoms or molecules in a lattice-like physical system. The assignment of an energy function in the physical system determines its Gibbs distribution. Because of the Gibbs distribution, Markov random field (MRF) equivalence, this assignment also determines an MRF image model. The energy function is a more convenient and natural mechanism for embodying picture attributes than are the local characteristics of the MRF. For a range of degradation mechanisms, including blurring, nonlinear deformations, and multiplicative or additive noise, the posterior distribution is an MRF with a structure akin to the image model. By the analogy, the posterior distribution defines another (imaginary) physical system. Gradual temperature reduction in the physical system isolates low energy states (“annealing”), or what is the same thing, the most probable states under the Gibbs distribution. The analogous operation under the posterior distribution yields the maximum a posteriori (MAP) estimate of the image given the degraded observations. The result is a highly parallel “relaxation” algorithm for MAP estimation. We establish convergence properties of the algorithm and we experiment with some simple pictures, for which good restorations are obtained at low signal-to-noise ratios.},
	number = {6},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Geman, Stuart and Geman, Donald},
	year = {1984},
	keywords = {Bayesian methods, Markov random fields, Stochastic processes, Additive noise, Annealing, Deformable models, Degradation, Energy states, Gibbs distribution, image restoration, Image restoration, line process, MAP estimate, Markov random field, relaxation, scene modeling, spatial degradation, Temperature distribution},
	pages = {721--741}
}

@article{sariyar_recordlinkage_2010,
	title = {The {RecordLinkage} {Package}: {Detecting} {Errors} in {Data}},
	volume = {2},
	issn = {2073-4859},
	abstract = {Record linkage deals with detecting homonyms and mainly synonyms in data. The package RecordLinkage provides means to perform and evaluate different record linkage methods. A stochastic framework is implemented which calculates weights through an EM algorithm. The determination of the necessary thresholds in this model can be achieved by tools of extreme value theory. Furthermore, machine learning methods are utilized, including decision trees (rpart), bootstrap aggregating (bagging), ada boost (ada), neural nets (nnet) and support vector machines (svm). The generation of record pairs and comparison patterns from single data items are provided as well. Comparison patterns can be chosen to be binary or based on some string metrics. In order to reduce computation time and memory usage, blocking can be used. Future development will concentrate on additional and reﬁned methods, performance improvements and input/output facilities needed for real-world application.},
	language = {en},
	number = {2},
	journal = {The R Journal},
	author = {Sariyar, Murat and Borg, Andreas},
	year = {2010},
	pages = {61--67}
}

@book{liu_monte_2004,
  address = {New York},
  series = {Springer {Series} in {Statistics}},
  title = {Monte {Carlo} {Strategies} in {Scientific} {Computing}},
  isbn = {978-0-387-76369-9},
  abstract = {This paperback edition is a reprint of the 2001 Springer edition. This book provides a self-contained and up-to-date treatment of the Monte Carlo method and develops a common framework under which various Monte Carlo techniques can be "standardized" and compared. Given the interdisciplinary nature of the topics and a moderate prerequisite for the reader, this book should be of interest to a broad audience of quantitative researchers such as computational biologists, computer scientists, econometricians, engineers, probabilists, and statisticians. It can also be used as the textbook for a graduate-level course on Monte Carlo methods. Many problems discussed in the alter chapters can be potential thesis topics for masters’ or Ph.D. students in statistics or computer science departments. Jun Liu is Professor of Statistics at Harvard University, with a courtesy Professor appointment at Harvard Biostatistics Department. Professor Liu was the recipient of the 2002 COPSS Presidents' Award, the most prestigious one for statisticians and given annually by five leading statistical associations to one individual under age 40. He was selected as a Terman Fellow by Stanford University in 1995, as a Medallion Lecturer by the Institute of Mathematical Statistics (IMS) in 2002, and as a Bernoulli Lecturer by the International Bernoulli Society in 2004. He was elected to the IMS Fellow in 2004 and Fellow of the American Statistical Association in 2005. He and co-workers have published more than 130 research articles and book chapters on Bayesian modeling and computation, bioinformatics, genetics, signal processing, stochastic dynamic systems, Monte Carlo methods, and theoretical statistics. "An excellent survey of current Monte Carlo methods. The applications amply demonstrate the relevance of this approach to modern computing. The book is highly recommended." (Mathematical Reviews) "This book provides comprehensive coverage of Monte Carlo methods, and in the process uncovers and discusses commonalities among seemingly disparate techniques that arose in various areas of application. … The book is well organized; the flow of topics follows a logical development. … The coverage is up-to-date and comprehensive, and so the book is a good resource for people conducting research on Monte Carlo methods. … The book would be an excellent supplementary text for a course in scientific computing … ." (SIAM Review) "The strength of this book is in bringing together advanced Monte Carlo (MC) methods developed in many disciplines. … Throughout the book are examples of techniques invented, or reinvented, in different fields that may be applied elsewhere. … Those interested in using MC to solve difficult problems will find many ideas, collected from a variety of disciplines, and references for further study." (Technometrics)},
  language = {en},
  publisher = {Springer-Verlag},
  author = {Liu, Jun S.},
  year = {2004}
}


@article{vats_multivariate_2015,
	title = {Multivariate {Output} {Analysis} for {Markov} chain {Monte} {Carlo}},
	url = {http://arxiv.org/abs/1512.07713},
	abstract = {Markov chain Monte Carlo (MCMC) produces a correlated sample for estimating expectations with respect to a target distribution. A fundamental question is when should sampling stop so that we have good estimates of the desired quantities? The key to answering this question lies in assessing the Monte Carlo error through a multivariate Markov chain central limit theorem (CLT). The multivariate nature of this Monte Carlo error largely has been ignored in the MCMC literature. We present a multivariate framework for terminating simulation in MCMC. We define a multivariate effective sample size, estimating which requires strongly consistent estimators of the covariance matrix in the Markov chain CLT; a property we show for the multivariate batch means estimator. We then provide a lower bound on the number of minimum effective samples required for a desired level of precision. This lower bound depends on the problem only in the dimension of the expectation being estimated, and not on the underlying stochastic process. This result is obtained by drawing a connection between terminating simulation via effective sample size and terminating simulation using a relative standard deviation fixed-volume sequential stopping rule; which we demonstrate is an asymptotically valid procedure. The finite sample properties of the proposed method are demonstrated in a variety of examples.},
	urldate = {2018-06-29},
	journal = {arXiv e-prints},
	author = {Vats, Dootika and Flegal, James M. and Jones, Galin L.},
	year = {2015},
	note = {{arxiv: 1512.07713}},
	keywords = {Mathematics - Statistics Theory, Statistics - Computation}
}

@techreport{winkler_methods_2002,
    title = {Methods for Record Linkage and {B}ayesian Networks},
    number = {Statistics \#2002-05},
    author = {Winkler, William E.},
    year = {2002},
  	institution = {U.S. Bureau of the Census},
}


@misc{manton_nltcs_2010,
    title = {National Long-Term Care Survey: 1982, 1984, 1989, 1994, 1999 and 2004},
    author = {Manton, Kenneth G.},
    year = {2010},
    doi = {10.3886/ICPSR09681.v5},
    publisher = {{Inter-University} {Consortium} for {Political} and {Social} {Research}},
    location = {Ann Arbor, MI}
}

@techreport{christen_preparation_2014,
	title = {Preparation of a Real Temporal Voter Data Set for Record Linkage and Duplicate Detection Research},
	institution = {Australian National University},
	author = {Christen, Peter},
	year = {2014}
}

@misc{bancaitalia_2010,
  title = {Bank of Italy -- Survey on Household Income and Wealth},
  author = {{Banca d'Italia}},
  year = {n.d.},
  howpublished = {\url{http://www.bancaditalia.it/pubblicazioni/indagine-famiglie/index.html}},
  note = {Accessed: 9 March 2018}
}


@article{zaharia_apache_2016,
 author = {Zaharia, Matei and Xin, Reynold S. and Wendell, Patrick and Das, Tathagata and Armbrust, Michael and Dave, Ankur and Meng, Xiangrui and Rosen, Josh and Venkataraman, Shivaram and Franklin, Michael J. and Ghodsi, Ali and Gonzalez, Joseph and Shenker, Scott and Stoica, Ion},
 title = {Apache Spark: A Unified Engine for Big Data Processing},
 journal = {Commun. ACM},
 issue_date = {November 2016},
 volume = {59},
 number = {11},
 year = {2016},
 issn = {0001-0782},
 pages = {56--65},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2934664},
 doi = {10.1145/2934664},
 acmid = {2934664},
 publisher = {ACM},
 address = {New York, NY, USA},
}


@article{jasra_markov_2005,
	title = {Markov Chain {Monte Carlo} Methods and the Label Switching Problem in {Bayesian} Mixture Modeling},
	volume = {20},
	issn = {0883-4237, 2168-8745},
	doi = {10.1214/088342305000000016},
	abstract = {In the past ten years there has been a dramatic increase of interest in the Bayesian analysis of finite mixture models. This is primarily because of the emergence of Markov chain Monte Carlo (MCMC) methods. While MCMC provides a convenient way to draw inference from complicated statistical models, there are many, perhaps underappreciated, problems associated with the MCMC analysis of mixtures. The problems are mainly caused by the nonidentifiability of the components under symmetric priors, which leads to so-called label switching in the MCMC output. This means that ergodic averages of component specific quantities will be identical and thus useless for inference. We review the solutions to the label switching problem, such as artificial identifiability constraints, relabelling algorithms and label invariant loss functions. We also review various MCMC sampling schemes that have been suggested for mixture models and discuss posterior sensitivity to prior specification.},
	language = {en},
	number = {1},
	urldate = {2018-07-04},
	journal = {Statistical Science},
	author = {Jasra, Ajay and Holmes, Chris C. and Stephens, David A.},
	year = {2005},
	mrnumber = {MR2182987},
	zmnumber = {1100.62032},
	keywords = {Bayesian statistics, identifiability, label switching, MCMC, mixture modeling, sensitivity analysis},
	pages = {50--67}
}


@article{copas_record_1990,
	title = {Record {Linkage}: {Statistical} {Models} for {Matching} {Computer} {Records}},
	volume = {153},
	issn = {0964-1998},
	shorttitle = {Record {Linkage}},
	doi = {10.2307/2982975},
	abstract = {We wish to measure the evidence that a pair of records relates to the same, rather than different, individuals. The paper emphasizes statistical models which can be fitted to a file of record pairs known to be correctly matched, and then used to estimate likelihood ratios. A number of models are developed and applied to UK immigration statistics. The combination of likelihood ratios for possibly correlated record fields is discussed.},
	number = {3},
	urldate = {2018-07-10},
	journal = {Journal of the Royal Statistical Society. Series A (Statistics in Society)},
	author = {Copas, J. B. and Hilton, F. J.},
	year = {1990},
	pages = {287--320}
}

@inbook{narayanan2009anonymizing,
	Author = {Narayanan, Arvind and Shmatikov, Vitaly},
	Booktitle = {Security and Privacy, 2009 30th IEEE Symposium on},
	Date-Added = {2015-01-29 08:36:41 +0000},
	Date-Modified = {2015-01-29 08:36:41 +0000},
	Organization = {IEEE},
	Pages = {173--187},
	Title = {De-anonymizing social networks},
	Year = {2009}}
	
@inbook{fienberg10,
	Author = {S.E. Fienberg and A.B. Slavkovi\'c},
	Pages = {342-345},
	Publisher = {Springer-Verlag},
	Series = {International Encyclopedia of Statistical Science},
	Title = {Data Privacy and Confidentiality},
	Year = {2010}}	


@techreport{ramanayake10,
	Author = {A. Ramanayake and L. Zayatz},
	Date-Added = {2015-01-29 08:40:57 +0000},
	Date-Modified = {2015-01-29 08:40:57 +0000},
	Institution = {U.S. Census Bureau},
	Number = {2010-04},
	Title = {Balancing Disclosure Risk with Data Quality},
	Type = {Statistical Research Division Research Report Series},
	Year = {2010}}
	
@article{DMNS06,
	Author = {Cynthia Dwork and Frank McSherry and Kobbi Nissim and Adam Smith},
	journal = {Theory of Cryptography Conference},
	Date-Added = {2011-06-02 09:13:18 -0400},
	Date-Modified = {2011-06-02 09:13:18 -0400},
	Pages = {265--284},
	Printoutnum = {567},
	Publisher = {Springer},
	Title = {Calibrating noise to sensitivity in private data analysis},
	Year = {2006}}	
	
@book{hundepool2012sdc,
	Author = {Hundepool, Anco and Domingo-Ferrer, Josep and Franconi, Luisa and Giessing, Sarah and Nordholt, Eric Schulte and Spicer, Keith and De Wolf, Peter-Paul},
	Publisher = {John Wiley \& Sons},
	Title = {Statistical Disclosure Control},
	Year = {2012}}	
	
@article{rubin_1993,
  title={Multiple imputation for statistical disclosure limitation},
  author={Raghunathan, Trivellore E and Reiter, Jerome P and Rubin, Donald B},
  journal={JOURNAL OF OFFICIAL STATISTICS-STOCKHOLM-},
  volume={19},
  number={1},
  pages={1--16},
  year={2003},
  publisher={ALMQVIST \& WIKSELL INTERNATIONAL}
}

@techreport{reiter2010,
  title={Releasing multiply-imputed synthetic data generated in two stages to protect confidentiality},
  author={Reiter, Jerome P and Drechsler, J{\"o}rg},
  year={2010},
  journal={Statistica Sinica},
  volume={20},
  pages={405-421},
}

@article{abowd_2001,
  title={Disclosure limitation in longitudinal linked data},
  author={Abowd, John M and Woodcock, Simon D},
  journal={Confidentiality, Disclosure, and Data Access: Theory and Practical Applications for Statistical Agencies},
  pages={215--277},
  year={2001},
  publisher={Amsterdam: North Holland}
}

@inbook{abowd_2008,
  title={How Protective Are Synthetic Data?},
  author={Abowd, John M and Vilhuber, Lars},
  booktitle={Privacy in Statistical Databases},
  pages={239--246},
  year={2008},
  organization={Springer}
}

@article{reiter_2005,
  title={Releasing multiply imputed, synthetic public use microdata: an illustration and empirical study},
  author={Reiter, Jerome P},
  journal={Journal of the Royal Statistical Society: Series A (Statistics in Society)},
  volume={168},
  number={1},
  pages={185--205},
  year={2005},
  publisher={Wiley Online Library}
}

@article{reiter_2003,
  title={Using CART to generate partially synthetic public use microdata},
  author={Reiter, JP},
  journal={Journal of official statistics},
  volume={21},
  number={3},
  pages={441--462},
  year={2005},
  publisher={Stockholm Statistics Sweden}
}

@article{slavkovic2010synthetic,
	Author = {Slavkovi{\'c}, Aleksandra B and Lee, Juyoun},
	Date-Added = {2015-01-27 04:21:21 +0000},
	Date-Modified = {2015-01-27 04:21:21 +0000},
	Journal = {Statistical Methodology},
	Number = {3},
	Pages = {225--239},
	Publisher = {Elsevier},
	Title = {Synthetic two-way contingency tables that preserve conditional frequencies},
	Volume = {7},
	Year = {2010}}
	
@article{reiter_2010,
  title={Sampling with synthesis: A new approach for releasing public use census microdata},
  author={Drechsler, J{\"o}rg and Reiter, Jerome P},
  journal={Journal of the American Statistical Association},
  volume={105},
  number={492},
  pages={1347--1357},
  year={2010},
  publisher={Taylor \& Francis}
}	

@inbook{charest_2012,
  title={Empirical evaluation of statistical inference from differentially-private contingency tables},
  author={Charest, Anne-Sophie},
  booktitle={Privacy in Statistical Databases},
  pages={257--272},
  year={2012},
  organization={Springer}
}

@conference{SCDres2013,
	Author = {J. Soria-Cormas and J. Drechsler},
	Date-Added = {2015-01-28 21:41:15 +0000},
	Date-Modified = {2015-01-28 21:41:15 +0000},
	Journal = {In UNECE Conference of European Statisticans},
	Title = {Evaluating the potential of differential privacy mechanisms for census data},
	Year = {2013}}


@techreport{ghosh_2013b,
  title={Perturbed {G}ibbs {S}amplers for Synthetic Data Release},
  author={Yubin Park and Joydeep Ghosh},
  year={2013},
  journal={arXiv e-prints},
  note={{arxiv:.1312.537}},
}

@article{KarwaSla2015AOS,
	Author = {Karwa, Vishesh and Slavkovi{\'c}, Aleksandra},
	Date-Added = {2015-01-27 02:44:08 +0000},
	Date-Modified = {2015-01-27 02:57:19 +0000},
	Journal = {Annals of Statistics},
	Title = {Inference using noisy degrees: Differentially Private $\beta$-model and Synthetic Graphs},
	Volume = {In revision},
	Year = {2015}}

@inbook{MKAGV08,
	Author = {Ashwin Machanavajjhala and Daniel Kifer and John M. Abowd and Johannes Gehrke and Lars Vilhuber},
	Bibsource = {DBLP, http://dblp.uni-trier.de},
	Booktitle = {24th International Conference on Data Engineering (ICDE)},
	Pages = {277-286},
	Publisher = {IEEE},
	Title = {Privacy: Theory meets Practice on the Map},
	Year = {2008}}
	
@article{karwa2012differentially,
	Author = {Karwa, V. and Slavkovic, A.},
	Date-Added = {2015-01-27 02:42:33 +0000},
	Date-Modified = {2015-01-27 02:42:33 +0000},
	Journal = {arXiv e-prints},
	Title = {Differentially Private Synthetic graphs},
	Year = {2012},
	note={{arxiv:1205.4697}}}
	

@book{willenborg96,
	Address = {New York, NY},
	Author = {L. Willenborg and T. {de Waal}},
	Date-Added = {2015-01-27 02:43:26 +0000},
	Date-Modified = {2015-01-27 02:43:26 +0000},
	Publisher = {Springer},
	Title = {Statistical Disclosure Control in Practice},
	Year = {1996}}


@book{lane2014privacy,
	Author = {Lane, Julia and Stodden, Victoria and Bender, Stefan and Nissenbaum, Helen},
	Date-Added = {2015-01-29 08:34:01 +0000},
	Date-Modified = {2015-01-29 08:34:01 +0000},
	Publisher = {Cambridge University Press},
	Title = {Privacy, Big Data, and the Public Good: Frameworks for Engagement},
	Year = {2014}}


@article{getoor_entity_2012,
    author = {Getoor, Lise and Machanavajjhala, Ashwin},
    title = {Entity Resolution: Theory, Practice \& Open Challenges},
    year = {2012},
    publisher = {VLDB Endowment},
    volume = {5},
    number = {12},
    doi = {10.14778/2367502.2367564},
    journal = {Proceedings of the VLDB Endowment},
    pages = {2018–2019},
    numpages = {2}
}
  


@article{elmagarmid_duplicate_2007,
	title = {Duplicate Record Detection: {A} Survey},
	volume = {19},
	issn = {1041-4347},
	shorttitle = {Duplicate {Record} {Detection}},
	doi = {10.1109/TKDE.2007.250581},
	number = {1},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Elmagarmid, Ahmed K. and Ipeirotis, Panagiotis G. and Verykios, Vassilios S.},
	year = {2007},
	pages = {1--16}
}

@book{christen_data_2012,
	address = {Berlin Heidelberg},
	series = {Data-{Centric} {Systems} and {Applications}},
	title = {Data matching: Concepts and techniques for record linkage, entity resolution, and duplicate detection},
	shorttitle = {Data {Matching}},
	language = {en},
	publisher = {Springer-Verlag},
	author = {Christen, Peter},
	year = {2012},
	pages = {270}
}

@article{papadakis_comparative_2016,
  title={Comparative analysis of approximate blocking techniques for entity resolution},
  author={Papadakis, George and Svirsky, Jonathan and Gal, Avigdor and Palpanas, Themis},
  journal={Proceedings of the VLDB Endowment},
  volume={9},
  number={9},
  pages={684--695},
  year={2016},
  publisher={VLDB Endowment}
}


@article{Mudgal2018,
	address = {New York, NY, USA},
	series = {{SIGMOD} '18},
	title = {Deep {Learning} for {Entity} {Matching}: {A} {Design} {Space} {Exploration}},
	isbn = {978-1-4503-4703-7},
	shorttitle = {Deep {Learning} for {Entity} {Matching}},
	doi = {10.1145/3183713.3196926},
	journal = {Proceedings of the 2018 {International} {Conference} on {Management} of {Data}},
	publisher = {ACM},
	author = {Mudgal, Sidharth and Li, Han and Rekatsinas, Theodoros and Doan, AnHai and Park, Youngchoon and Krishnan, Ganesh and Deep, Rohit and Arcaute, Esteban and Raghavendra, Vijay},
	year = {2018},
	keywords = {deep learning, entity matching, entity resolution},
	pages = {19--34}
}

@inbook{galhotra_robust_2018,
	address = {New York, NY, USA},
	series = {{SIGMOD} '18},
	title = {Robust {Entity} {Resolution} {Using} {Random} {Graphs}},
	isbn = {978-1-4503-4703-7},
	doi = {10.1145/3183713.3183755},
	urldate = {2018-07-10},
	booktitle = {Proceedings of the 2018 {International} {Conference} on {Management} of {Data}},
	publisher = {ACM},
	author = {Galhotra, Sainyam and Firmani, Donatella and Saha, Barna and Srivastava, Divesh},
	year = {2018},
	keywords = {crowdsourcing, data cleaning, entity resolution, expander graphs},
	pages = {3--18}
}


@article{singh_generating_2017,
	address = {New York, NY},
	title = {Generating Concise Entity Matching Rules},
	journal = {Proceedings of the 2017 ACM International Conference on Management of Data},
    publisher = {ACM},
	author = {Singh, Rohit and Meduri, Vamsi and Elmagarmid, Ahmed and Madden, Samuel and Papotti, Paolo and Quian{\'e}-Ruiz, Jorge-Arnulfo and Solar-Lezama, Armando and Tang, Nan},
	year = {2017},
	pages = {1635--1638}
}


@incollection{neal_mcmc_2011,
	address = {New York},
	series = {Handbooks of {Modern} {Statistical} {Methods}},
	title = {{MCMC} {Using} {Hamiltonian} {Dynamics}},
	isbn = {978-1-4200-7942-5},
	abstract = {Markov chain Monte Carlo (MCMC) originated with the classic paper of Metropolis et al. (1953), where it was used to simulate the distribution of states for a system of idealized molecules. Not long after, another approach to molecular simulation was introduced (Alder and Wainwright, 1959), in which the motion of the molecules was deterministic, following Newton’s laws of motion, which have an elegant formalization as Hamiltonian dynamics. For finding the properties of bulk materials, these approaches are asymptotically equivalent, since even in a deterministic simulation, each local region of the material experiences effectively random influences from distant regions. Despite the large overlap in their application areas, the MCMC and molecular dynamics approaches have continued to coexist in the following decades (see Frenkel and Smit, 1996).},
	language = {en},
	booktitle = {Handbook of {Markov} {Chain} {Monte} {Carlo}},
	publisher = {Chapman and Hall/CRC},
	author = {Neal, Radford M.},
	editor = {Brooks, Steve and Gelman, Andrew and Jones, Galin L. and Meng, Xiao-Li},
	year = {2011},
	note = {Google-Books-ID: qfRsAIKZ4rIC},
	keywords = {Mathematics / Probability \& Statistics / General, Science / Life Sciences / Biology},
	pages = {50}
}


@article{blei_variational_2017,
	title = {Variational {Inference}: {A} {Review} for {Statisticians}},
	volume = {112},
	issn = {0162-1459},
	shorttitle = {Variational {Inference}},
	doi = {10.1080/01621459.2017.1285773},
	abstract = {One of the core problems of modern statistics is to approximate difficult-to-compute probability densities. This problem is especially important in Bayesian statistics, which frames all inference about unknown quantities as a calculation involving the posterior density. In this article, we review variational inference (VI), a method from machine learning that approximates probability densities through optimization. VI has been used in many applications and tends to be faster than classical methods, such as Markov chain Monte Carlo sampling. The idea behind VI is to first posit a family of densities and then to find a member of that family which is close to the target density. Closeness is measured by Kullback–Leibler divergence. We review the ideas behind mean-field variational inference, discuss the special case of VI applied to exponential family models, present a full example with a Bayesian mixture of Gaussians, and derive a variant that uses stochastic optimization to scale up to massive data. We discuss modern research in VI and highlight important open problems. VI is powerful, but it is not yet well understood. Our hope in writing this article is to catalyze statistical research on this class of algorithms. Supplementary materials for this article are available online.},
	number = {518},
	urldate = {2018-07-11},
	journal = {Journal of the American Statistical Association},
	author = {Blei, David M. and Kucukelbir, Alp and McAuliffe, Jon D.},
	year = {2017},
	keywords = {Algorithms, Computationally intensive methods, Statistical computing}
}


@inbook{gal_pitfalls_2014,
	address = {Beijing, China},
	series = {{ICML}'14},
	title = {Pitfalls in the {Use} of {Parallel} {Inference} for the {Dirichlet} {Process}},
	abstract = {Recent work done by Lovell, Adams, and Mansingka (2012) and Williamson, Dubey, and Xing (2013) has suggested an alternative parametrisation for the Dirichlet process in order to derive non-approximate parallel MCMC inference for it - work which has been picked-up and implemented in several different fields. In this paper we show that the approach suggested is impractical due to an extremely unbalanced distribution of the data. We characterise the requirements of efficient parallel inference for the Dirichlet process and show that the proposed inference fails most of these requirements (while approximate approaches often satisfy most of them). We present both theoretical and experimental evidence, analysing the load balance for the inference and showing that it is independent of the size of the dataset and the number of nodes available in the parallel implementation. We end with suggestions of alternative paths of research for efficient non-approximate parallel inference for the Dirichlet process.},
	urldate = {2018-07-11},
	booktitle = {Proceedings of the 31st {International} {Conference} on {International} {Conference} on {Machine} {Learning} - {Volume} 32},
	publisher = {JMLR.org},
	author = {Gal, Yarin and Ghahramani, Zoubin},
	year = {2014},
	pages = {II--208--II--216}
}


@article{smola_architecture_2010,
	title = {An {Architecture} for {Parallel} {Topic} {Models}},
	volume = {3},
	issn = {2150-8097},
	doi = {10.14778/1920841.1920931},
	abstract = {This paper describes a high performance sampling architecture for inference of latent topic models on a cluster of workstations. Our system is faster than previous work by over an order of magnitude and it is capable of dealing with hundreds of millions of documents and thousands of topics. The algorithm relies on a novel communication structure, namely the use of a distributed (key, value) storage for synchronizing the sampler state between computers. Our architecture entirely obviates the need for separate computation and synchronization phases. Instead, disk, CPU, and network are used simultaneously to achieve high performance. We show that this architecture is entirely general and that it can be extended easily to more sophisticated latent variable models such as n-grams and hierarchies.},
	number = {1-2},
	urldate = {2018-07-11},
	journal = {Proc. VLDB Endow.},
	author = {Smola, Alexander and Narayanamurthy, Shravan},
	year = {2010},
	pages = {703--710}
}


@inbook{ahn_distributed_2014,
	address = {Beijing, China},
	series = {{ICML}'14},
	title = {Distributed {Stochastic} {Gradient} {MCMC}},
	abstract = {Probabilistic inference on a big data scale is becoming increasingly relevant to both the machine learning and statistics communities. Here we introduce the first fully distributed MCMC algorithm based on stochastic gradients. We argue that stochastic gradient MCMC algorithms are particularly suited for distributed inference because individual chains can draw mini-batches from their local pool of data for a flexible amount of time before jumping to or syncing with other chains. This greatly reduces communication overhead and allows adaptive load balancing. Our experiments for LDA on Wikipedia and Pubmed show that relative to the state of the art in distributed MCMC we reduce compute time from 27 hours to half an hour in order to reach the same perplexity level.},
	urldate = {2018-07-12},
	booktitle = {Proceedings of the 31st {International} {Conference} on {International} {Conference} on {Machine} {Learning} - {Volume} 32},
	publisher = {JMLR.org},
	author = {Ahn, Sungjin and Shahbaba, Babak and Welling, Max},
	year = {2014},
	pages = {II--1044--II--1052}
}

@book{gelman_bayesian_2013,
	address = {New York},
	edition = {3rd edition},
	series = {Texts in {Statistical} {Science}},
	title = {Bayesian Data Analysis},
	isbn = {978-1-4398-9820-8},
	language = {en},
	urldate = {2018-07-13},
	publisher = {Chapman and Hall/CRC},
	author = {Gelman, Andrew and Carlin, John B. and Stern, Hal S. and Dunson, David B. and Vehtari, Aki and Rubin, Donald B.},
	year = {2013},
	doi = {10.1201/b16018}
}

@article{winkler1990string,
author = {Winkler, William E.},
journal = {Proceedings of the Section on Survey Research, American Statistical Association},
pages = {354--359},
title = {String Comparator Metrics and Enhanced Decision Rules in the {F}ellegi-{S}unter Model of Record Linkage},
year = {1990}
}


@book{dong_big_2015,
	title = {Big {Data} {Integration}},
	journal = {Synthesis Lectures on Data Management},
	author = {Dong, Xin Luna and Srivastava, Divesh},
	year = {2015},
	pages = {1--178},
	publisher={Morgan and Claypool Publishers}
}


@article{bleiholder_data_2009,
	title = {Data {Fusion}},
	volume = {41},
	number = {1},
	journal = {ACM Computing Surveys},
	author = {Bleiholder, Jens and Naumann, Felix},
	year = {2009},
	pages = {1--41}
}


@article{zhao_bayesian_2012,
	title = {A {Bayesian} Approach to Discovering Truth from Conflicting Sources for Data Integration},
	volume = {5},
	issn = {2150-8097},
	doi = {10.14778/2168651.2168656},
	abstract = {In practical data integration systems, it is common for the data sources being integrated to provide conflicting information about the same entity. Consequently, a major challenge for data integration is to derive the most complete and accurate integrated records from diverse and sometimes conflicting sources. We term this challenge the truth finding problem. We observe that some sources are generally more reliable than others, and therefore a good model of source quality is the key to solving the truth finding problem. In this work, we propose a probabilistic graphical model that can automatically infer true records and source quality without any supervision. In contrast to previous methods, our principled approach leverages a generative process of two types of errors (false positive and false negative) by modeling two different aspects of source quality. In so doing, ours is also the first approach designed to merge multi-valued attribute types. Our method is scalable, due to an efficient sampling-based inference algorithm that needs very few iterations in practice and enjoys linear time complexity, with an even faster incremental variant. Experiments on two real world datasets show that our new method outperforms existing state-of-the-art approaches to the truth finding problem.},
	number = {6},
	journal = {Proc. VLDB Endow.},
	author = {Zhao, Bo and Rubinstein, Benjamin I. P. and Gemmell, Jim and Han, Jiawei},
	year = {2012},
	pages = {550--561}
}

@article{li_survey_2016,
	title = {A {Survey} on {Truth} {Discovery}},
	volume = {17},
	issn = {1931-0145},
	doi = {10.1145/2897350.2897352},
	abstract = {Thanks to information explosion, data for the objects of interest can be collected from increasingly more sources. However, for the same object, there usually exist conflicts among the collected multi-source information. To tackle this challenge, truth discovery, which integrates multi-source noisy information by estimating the reliability of each source, has emerged as a hot topic. Several truth discovery methods have been proposed for various scenarios, and they have been successfully applied in diverse application domains. In this survey, we focus on providing a comprehensive overview of truth discovery methods, and summarizing them from different aspects. We also discuss some future directions of truth discovery research. We hope that this survey will promote a better understanding of the current progress on truth discovery, and offer some guidelines on how to apply these approaches in application domains.},
	number = {2},
	journal = {SIGKDD Explor. Newsl.},
	author = {Li, Yaliang and Gao, Jing and Meng, Chuishi and Li, Qi and Su, Lu and Zhao, Bo and Fan, Wei and Han, Jiawei},
	year = {2016},
	pages = {1--16}
}

@inbook{li_resolving_2014,
	address = {New York, NY, USA},
	series = {{SIGMOD} '14},
	title = {Resolving {Conflicts} in {Heterogeneous} {Data} by {Truth} {Discovery} and {Source} {Reliability} {Estimation}},
	isbn = {978-1-4503-2376-5},
	doi = {10.1145/2588555.2610509},
	abstract = {In many applications, one can obtain descriptions about the same objects or events from a variety of sources. As a result, this will inevitably lead to data or information conflicts. One important problem is to identify the true information (i.e., the truths) among conflicting sources of data. It is intuitive to trust reliable sources more when deriving the truths, but it is usually unknown which one is more reliable a priori. Moreover, each source possesses a variety of properties with different data types. An accurate estimation of source reliability has to be made by modeling multiple properties in a unified model. Existing conflict resolution work either does not conduct source reliability estimation, or models multiple properties separately. In this paper, we propose to resolve conflicts among multiple sources of heterogeneous data types. We model the problem using an optimization framework where truths and source reliability are defined as two sets of unknown variables. The objective is to minimize the overall weighted deviation between the truths and the multi-source observations where each source is weighted by its reliability. Different loss functions can be incorporated into this framework to recognize the characteristics of various data types, and efficient computation approaches are developed. Experiments on real-world weather, stock and flight data as well as simulated multi-source data demonstrate the necessity of jointly modeling different data types in the proposed framework.},
	booktitle = {Proceedings of the 2014 {ACM} {SIGMOD} {International} {Conference} on {Management} of {Data}},
	publisher = {ACM},
	author = {Li, Qi and Li, Yaliang and Gao, Jing and Zhao, Bo and Fan, Wei and Han, Jiawei},
	year = {2014},
	keywords = {data fusion, heterogeneous data, truth discovery},
	pages = {1187--1198}
}

@article{zheng_truth_2017,
	title = {Truth {Inference} in {Crowdsourcing}: {Is} the {Problem} {Solved}?},
	volume = {10},
	issn = {2150-8097},
	shorttitle = {Truth {Inference} in {Crowdsourcing}},
	doi = {10.14778/3055540.3055547},
	abstract = {Crowdsourcing has emerged as a novel problem-solving paradigm, which facilitates addressing problems that are hard for computers, e.g., entity resolution and sentiment analysis. However, due to the openness of crowdsourcing, workers may yield low-quality answers, and a redundancy-based method is widely employed, which first assigns each task to multiple workers and then infers the correct answer (called truth) for the task based on the answers of the assigned workers. A fundamental problem in this method is Truth Inference, which decides how to effectively infer the truth. Recently, the database community and data mining community independently study this problem and propose various algorithms. However, these algorithms are not compared extensively under the same framework and it is hard for practitioners to select appropriate algorithms. To alleviate this problem, we provide a detailed survey on 17 existing algorithms and perform a comprehensive evaluation using 5 real datasets. We make all codes and datasets public for future research. Through experiments we find that existing algorithms are not stable across different datasets and there is no algorithm that outperforms others consistently. We believe that the truth inference problem is not fully solved, and identify the limitations of existing algorithms and point out promising research directions.},
	number = {5},
	journal = {Proc. VLDB Endow.},
	author = {Zheng, Yudian and Li, Guoliang and Li, Yuanbing and Shan, Caihua and Cheng, Reynold},
	year = {2017},
	pages = {541--552}
}


@inbook{pasternack_latent_2013,
	address = {New York, NY, USA},
	series = {{WWW} '13},
	title = {Latent {Credibility} {Analysis}},
	isbn = {978-1-4503-2035-1},
	doi = {10.1145/2488388.2488476},
	abstract = {A frequent problem when dealing with data gathered from multiple sources on the web (ranging from booksellers to Wikipedia pages to stock analyst predictions) is that these sources disagree, and we must decide which of their (often mutually exclusive) claims we should accept. Current state-of-the-art information credibility algorithms known as "fact-finders" are transitive voting systems with rules specifying how votes iteratively flow from sources to claims and then back to sources. While this is quite tractable and often effective, fact-finders also suffer from substantial limitations; in particular, a lack of transparency obfuscates their credibility decisions and makes them difficult to adapt and analyze: knowing the mechanics of how votes are calculated does not readily tell us what those votes mean, and finding, for example, that a source has a score of 6 is not informative. We introduce a new approach to information credibility, Latent Credibility Analysis (LCA), constructing strongly principled, probabilistic models where the truth of each claim is a latent variable and the credibility of a source is captured by a set of model parameters. This gives LCA models clear semantics and modularity that make extending them to capture additional observed and latent credibility factors straightforward. Experiments over four real-world datasets demonstrate that LCA models can outperform the best fact-finders in both unsupervised and semi-supervised settings.},
	booktitle = {Proceedings of the 22Nd {International} {Conference} on {World} {Wide} {Web}},
	publisher = {ACM},
	author = {Pasternack, Jeff and Roth, Dan},
	year = {2013},
	keywords = {Graphical models, credibility, trust, veracity},
	pages = {1009--1020}
}


@article{lesot_similarity_2008,
	title = {Similarity measures for binary and numerical data: a survey},
	volume = {1},
	issn = {1755-3210},
	shorttitle = {Similarity measures for binary and numerical data},
	doi = {10.1504/IJKESDP.2009.021985},
	abstract = {Similarity measures aim at quantifying the extent to which objects resemble each other. Many techniques in data mining, data analysis or information retrieval require a similarity measure, and selecting an appropriate measure for a given problem is a difficult task. In this paper, the diverse forms similarity measures can take are examined, as well as their relationships and respective properties. Their semantic differences are highlighted and numerical tools to quantify these differences are proposed, considering several points of view and including global and local comparisons, order-based and value-based comparisons, and mathematical properties such as derivability. The paper studies similarity measures for two types of data: binary and numerical data, i.e., set data represented by the presence or absence of characteristics and data represented by real vectors.},
	number = {1},
	journal = {International Journal of Knowledge Engineering and Soft Data Paradigms},
	author = {Lesot, Marie-Jeanne and Rifqi, Maria and Benhadda, Hamid},
	year = {2008},
	pages = {63--84}
}


@article{turek_efficient_2016,
	title = {Efficient {Markov} chain {Monte} {Carlo} sampling for hierarchical hidden {Markov} models},
	volume = {23},
	issn = {1352-8505, 1573-3009},
	doi = {10.1007/s10651-016-0353-z},
	abstract = {Traditional Markov chain Monte Carlo (MCMC) sampling of hidden Markov models (HMMs) involves latent states underlying an imperfect observation process, and generates posterior samples for top-level parameters concurrently with nuisance latent variables. When potentially many HMMs are embedded within a hierarchical model, this can result in prohibitively long MCMC runtimes. We study combinations of existing methods, which are shown to vastly improve computational efficiency for these hierarchical models while maintaining the modeling flexibility provided by embedded HMMs. The methods include discrete filtering of the HMM likelihood to remove latent states, reduced data representations, and a novel procedure for dynamic block sampling of posterior dimensions. The first two methods have been used in isolation in existing application-specific software, but are not generally available for incorporation in arbitrary model structures. Using the NIMBLE package for R, we develop and test combined computational approaches using three examples from ecological capture–recapture, although our methods are generally applicable to any embedded discrete HMMs. These combinations provide several orders of magnitude improvement in MCMC sampling efficiency, defined as the rate of generating effectively independent posterior samples. In addition to being computationally significant for this class of hierarchical models, this result underscores the potential for vast improvements to MCMC sampling efficiency which can result from combinations of known algorithms.},
	language = {en},
	number = {4},
	journal = {Environmental and Ecological Statistics},
	author = {Turek, Daniel and Valpine, Perry de and Paciorek, Christopher J.},
	year = {2016},
	pages = {549--564}
}

@inbook{bilenko_adaptive_2003,
	address = {New York, NY, USA},
	series = {{KDD} '03},
	title = {Adaptive {Duplicate} {Detection} {Using} {Learnable} {String} {Similarity} {Measures}},
	isbn = {978-1-58113-737-8},
	doi = {10.1145/956750.956759},
	abstract = {The problem of identifying approximately duplicate records in databases is an essential step for data cleaning and data integration processes. Most existing approaches have relied on generic or manually tuned distance metrics for estimating the similarity of potential duplicates. In this paper, we present a framework for improving duplicate detection using trainable measures of textual similarity. We propose to employ learnable text distance functions for each database field, and show that such measures are capable of adapting to the specific notion of similarity that is appropriate for the field's domain. We present two learnable text similarity measures suitable for this task: an extended variant of learnable string edit distance, and a novel vector-space based measure that employs a Support Vector Machine (SVM) for training. Experimental results on a range of datasets show that our framework can improve duplicate detection accuracy over traditional techniques.},
	booktitle = {Proceedings of the {Ninth} {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {ACM},
	author = {Bilenko, Mikhail and Mooney, Raymond J.},
	year = {2003},
	keywords = {data cleaning, distance metric learning, record linkage, string edit distance, SVM applications, trained similarity measures},
	pages = {39--48}
}

@article{tancredi_2015_regression,
  title={Regression analysis with linked data: problems and possible solutions},
  author={Tancredi, Andrea and Liseo, Brunero},
  journal={Statistica},
  volume={75},
  number={1},
  pages={19--35},
  year={2015}
}

@article{konda2016magellan,
  title={Magellan: Toward building entity matching management systems},
  author={Konda, Pradap and Das, Sanjib and Suganthan GC, Paul and Doan, AnHai and Ardalan, Adel and Ballard, Jeffrey R and Li, Han and Panahi, Fatemah and Zhang, Haojun and Naughton, Jeff and others},
  journal={Proceedings of the VLDB Endowment},
  volume={9},
  number={12},
  pages={1197--1208},
  year={2016},
  publisher={VLDB Endowment}
}

@inbook{das2017falcon,
  title={Falcon: Scaling up hands-off crowdsourced entity matching to build cloud services},
  author={Das, Sanjib and GC, Paul Suganthan and Doan, AnHai and Naughton, Jeffrey F and Krishnan, Ganesh and Deep, Rohit and Arcaute, Esteban and Raghavendra, Vijay and Park, Youngchoon},
  booktitle={Proceedings of the 2017 ACM International Conference on Management of Data},
  pages={1431--1446},
  year={2017},
  organization={ACM}
}

@article{price2015documents,
  title={Documents of war: Understanding the {S}yrian conflict},
  author={Price, Megan and Gohdes, Anita and Ball, Patrick},
  journal={Significance},
  volume={12},
  number={2},
  pages={14--19},
  year={2015},
  publisher={Wiley Online Library}
}

@article{chen2018unique,
  title={Unique entity estimation with application to the {S}yrian conflict},
  author={Chen, Beidi and Shrivastava, Anshumali and Steorts, Rebecca C},
  journal={The Annals of Applied Statistics},
  volume={12},
  number={2},
  pages={1039--1067},
  year={2018},
  publisher={Institute of Mathematical Statistics} }

@article{copas1990record,
  title={Record linkage: statistical models for matching computer records},
  author={Copas, JB and Hilton, FJ},
  journal={Journal of the Royal Statistical Society. Series A (Statistics in Society)},
  pages={287--320},
  year={1990},
  publisher={JSTOR}
}

@Manual{mcmcse,
    title = {mcmcse: Monte Carlo Standard Errors for MCMC},
    author = {James M. Flegal and John Hughes and Dootika Vats and Ning Dai},
    year = {2017},
    address = {Riverside, CA, Denver, CO, Coventry, UK, and Minneapolis, MN},
    note = {R package version 1.3-2},
  }

@article{hof12,
	Author = {Hof, M. H. P. and Zwinderman, A. H.},
	Journal = {Statistics in Medicine},
	Number = {30},
	Pages = {4231--4242},
	Publisher = {Wiley Online Library},
	Title = {Methods for Analyzing Data From Probabilistic Linkage Strategies Based on Partially Identifying Variables},
	Volume = {31},
	Year = {2012}}
	
@article{DalzellReiter18,
	Author = {Nicole M. Dalzell and Jerome P. Reiter},
	Date-Added = {2018-09-02 00:37:26 +0000},
	Date-Modified = {2018-09-02 00:41:45 +0000},
	Journal = {Journal of Computational and Graphical Statistics},
	Number = {0},
	Pages = {1-11},
	Title = {Regression Modeling and File Matching Using Possibly Erroneous Matching Variables},
	Volume = {0},
	Year = {2018}}	
	
@inbook{steorts2018generalized,
	Author = {Steorts, Rebecca C and Tancredi, Andrea and Liseo, Brunero},
	Booktitle = {International Conference on Privacy in Statistical Databases},
	Organization = {Springer},
	Pages = {297--313},
	Title = {Generalized {B}ayesian Record Linkage and Regression with Exact Error Propagation},
	Year = {2018}}	


@article{gutman2013bayesian,
	Author = {Gutman, Roee and Afendulis, Christopher C and Zaslavsky, Alan M},
	Journal = {Journal of the American Statistical Association},
	Number = {501},
	Pages = {34--47},
	Publisher = {Taylor \& Francis Group},
	Title = {A {B}ayesian procedure for file linking to analyze end-of-life medical costs},
	Volume = {108},
	Year = {2013}}

@article{HofRavelliZwinderman17,
	Author = {Michel H. Hof and Anita C. Ravelli and Aeilko H. Zwinderman To},
	Date-Added = {2018-09-02 00:56:38 +0000},
	Date-Modified = {2018-09-02 01:02:12 +0000},
	Journal = {Journal of the American Statistical Association},
	Number = {520},
	Pages = {1504-1515},
	Title = {A Probabilistic Record Linkage Model for Survival Data},
	Volume = {112},
	Year = {2017}}
	
@incollection{vatsalan_2013,
  title={Sorted nearest neighborhood clustering for efficient private blocking},
  author={Vatsalan, Dinusha and Christen, Peter},
  booktitle={Advances in Knowledge Discovery and Data Mining},
  pages={341--352},
  year={2013},
  publisher={Springer}
}

@article{goldenberg_2010,
  title={A survey of statistical network models},
  author={Goldenberg, Anna and Zheng, Alice X and Fienberg, Stephen E and Airoldi, Edoardo M},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={2},
  number={2},
  pages={129--233},
  year={2010},
  publisher={Now Publishers Inc.}
}

@inbook{christen_2009,
  title={Similarity-aware indexing for real-time entity resolution},
  author={Christen, Peter and Gayler, Ross and Hawking, David},
  booktitle={Proceedings of the 18th ACM Conference on Information and Knowledge Management},
  pages={1565--1568},
  year={2009}
}

@inbook{WYP:2010,
	Author = {W.E. Winkler and  W.E. Yancey and E.H. Porter },
	Booktitle = {Proceedings of American Statistical Association Section on Survey Research Methods },
	Date-Added = {2014-05-16 14:56:15 +0000},
	Date-Modified = {2014-05-16 14:58:20 +0000},
	Title = {Fast Record Linkage of Very Large Files in Support of Decennial and Administrative Records Projects},
	Year = {2010}}

@article{Herzog:2010,
	Author = {Herzog, T.N. and Scheuren, F.J. and Winkler, W.E.},
	Date-Added = {2014-05-16 14:52:18 +0000},
	Date-Modified = {2014-05-16 14:55:13 +0000},
	Journal = {Wiley Interdisciplinary Reviews: Computational Statistics },
	Pages = {DOI: 10.1002/wics.108},
	Title = {Record Linkage},
	Volume = {2},
	Year = {2010}}

@article{BMCRF:2003,
	Author = {M. Bilenko and  R. Mooney and  W.W. Cohen and  P. Ravikumar and S.E. Fienberg },
	Date-Added = {2014-05-16 14:49:37 +0000},
	Date-Modified = {2014-05-16 14:55:52 +0000},
	Journal = {IEEE Intelligent Systems},
	Number = {5},
	Pages = {16--23},
	Title = {Adaptive Name-Matching in Information Integration },
	Volume = {18},
	Year = {2003}}


@article{Ugarte2014,
title={On fitting spatio-temporal disease mapping models using approximate {B}ayesian inference},
author= {Ugarte, Maria Dolores, and Adin, Aritz, and Goicoa, Tom\'as and Militino,  Ana F.},
journal={Statistical Methods in Medical Research},
pages={DOI: 10.1177/0962280214527528},
year= {2014}
}



@article{militino_2012,
title={Estimating the percentage of food expenditure in small areas using bias-corrected P-spline based estimators},
author= {Militino,  Ana F., and Goicoa, Tom\'as  and Ugarte, Maria Dolores},
journal={Computational Statistics and Data Analysis},
volume={53},
  pages={3616- 3629},
year= {2012}
}


@inbook{steorts_2014_louis,
  title={Conformability for {B}ayesian Estimates},
  author={Steorts, R. and Louis, T.},
  year={2014},
  organization={In preparation}
}

@article{hernandez_1995,
    author = {Hern\'{a}ndez, Mauricio A. and Stolfo, Salvatore J.},
    title = {The Merge/Purge Problem for Large Databases},
    year = {1995},
    isbn = {0897917316},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    doi = {10.1145/223784.223807},
    journal = {Proceedings of the 1995 ACM SIGMOD International Conference on Management of Data},
    pages = {127–138},
    numpages = {12},
    location = {San Jose, California, USA},
}
  


@inbook{mccallum_2000,
  title={Efficient clustering of high-dimensional data sets with application to reference matching},
  author={McCallum, Andrew and Nigam, Kamal and Ungar, Lyle H},
  booktitle={Proceedings of 6th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  pages={169--178},
  year={2000}
}


@book{lewis_1997,
  title={Elements of the Theory of Computation},
  author={Lewis, Harry R and Papadimitriou, Christos H},
  year={1997},
  publisher={Prentice Hall PTR}
}

@article{kullback_1951,
  title={On information and sufficiency},
  author={Kullback, Solomon and Leibler, Richard A},
  journal={The Annals of Mathematical Statistics},
  pages={79--86},
  year={1951} 
}

@article{pasula_2003,
  title={Identity uncertainty and citation matching},
  author={Pasula, Hanna and Marthi, Bhaskara and Milch, Brian and Russell, Stuart and Shpitser, Ilya},
  journal={Advances in Neural Information Processing Systems},
  pages={1425--1432},
  year={2003} 
}

@article{ban_2005,
  title={Clustering with Bregman Divergences},
  author={Banerjee, Arindam and Merugu, Srujana and Dhillon, Inderjit and Ghosh, Joydeep},
  journal={Journal of Machine Learning Research},
  volume={6},
  pages={1705--1749},
  year={2005},
  editor={John Lafferty}
}

@inbook{frigyik_2008,
  title={Functional Bregman Divergence and {B}ayesian
Estimation of Distributions},
  author={Bela, Frigyik and Srivastave, Santosh and Gupta, Maya},
  booktitle={IEEE TRANSACTIONS ON INFORMATION THEORY},
  volume = {54},
  pages={5130--5139},
  year={2008}
}

@inbook{vatsalan_2011,
  title={An efficient two-party protocol for approximate matching in private record linkage},
  author={Vatsalan, Dinusha and Christen, Peter and Verykios, Vassilios S},
  booktitle={Proceedings of the Ninth Australasian Data Mining Conference-Volume 121},
  pages={125--136},
  year={2011}
}

@inbook{kuzu_2011,
  title={A constraint satisfaction cryptanalysis of Bloom filters in private record linkage},
  author={Kuzu, Mehmet and Kantarcioglu, Murat and Durham, Elizabeth and Malin, Bradley},
  booktitle={Privacy Enhancing Technologies},
  pages={226--245},
  year={2011},
  organization={Springer}
}

@inbook{karakasidis_2012,
  title={Reference table based $k$-anonymous private blocking},
  author={Karakasidis, Alexandros and Verykios, Vassilios S},
  booktitle={Proceedings of the 27th Annual ACM Symposium on Applied Computing},
  pages={859--864},
  year={2012} 
}

@article{singh_1994,
  title={Time series {EBLUP}s for small areas using survey data},
  author={Singh, AC and Mantel, HJ and Thomas, BW},
  journal={Survey Methodology},
  volume={20},
  number={1},
  pages={33--43},
  year={1994}
}

@article{souza_2009,
  title={Small area population prediction via hierarchical models},
  author={Souza, Debora F and Moura, Fernando AS and Migon, Helio S},
  journal={Catalogue no. 12-001-X},
  pages={203},
  year={2009}
}

@article{pratesi_2008,
  title={Small area estimation: the EBLUP estimator based on spatially correlated random area effects},
  author={Pratesi, Monica and Salvati, Nicola},
  journal={Statistical methods and applications},
  volume={17},
  number={1},
  pages={113--141},
  year={2008},
  publisher={Springer}
}

@article{datta_1999,
  title={Hierarchical Bayes estimation of unemployment rates for the states of the US},
  author={Datta, Gauri S and Lahiri, Partha and Maiti, Tapabrata and Lu, Kim L},
  journal={Journal of the American Statistical Association},
  volume={94},
  number={448},
  pages={1074--1082},
  year={1999},
  publisher={Taylor \& Francis Group}
}

@inbook{datta_1996,
  title={Estimation of median income of four-person families: a {B}ayesian approach},
  author={Datta, GS and Ghosh, M and Nangia, Narinder and Natarajan, K},
  booktitle={{B}ayesian analysis in statistics and econometrics: essays in honor of Arnold Zellner},
  pages={129--140},
  year={1996}
}


@article{stodden_2013,
  title={“Setting the Default to Reproducible” in Computational Science Research},
  author={Stodden, Victoria and Borwein, Jonathan and Bailey, David H},
  journal={SIAM News, June},
  volume={3},
  year={2013}
}

@online{molina_2013,
  author = {Molina, Isabel and Marhenda, Yolada},
  title = {{Package sae}},
  year = 2013,
  url = {http://cran.r-project.org/web/packages/sae/sae.pdf},
  urldate = {2010-09-30}
}

@article{berend_2014,
  title={Minimum KL-divergence on complements of $ L\_1 $ balls},
  author={Berend, Daniel and Harremoes, Peter and Kontorovich, Aryeh},
  publisher={IEEE},
  year={2014}
}

@article{louis_2014,
	Author = {Steorts, Rebecca and Louis, T.A.},
	Date-Added = {2010-04-22 16:04:05 -0400},
	Date-Modified = {2010-04-22 16:04:05 -0400},
	Journal = {In Preparation},
	Title = {Constrained {B}ayesian Benchmarking},
	Year = {2014}}

@artile{pfeffermann_2014,
title={SINGLE AND TWO-STAGE CROSS-SECTIONAL AND TIME SERIES BENCHMARKING PROCEDURES FOR SMALL AREA ESTIMATION},
author= {Pfeffermann, Danny and Sikov, Anna and Tiller, Richard},
journal={TEST},
year= {2014}
}

@article{hall2011_random,
  title={Random differential privacy},
  author={Hall, Rob and Rinaldo, Alessandro and Wasserman, Larry},
  journal={arXiv e-prints},
  year={2011},
  note={{arxiv:1112.2680}}
}

@article{hall_2011,
  title={Secure multiple linear regression based on homomorphic encryption},
  author={Hall, Rob and Fienberg, Stephen E and Nardi, Yuval},
  journal={Journal of Official Statistics},
  volume={27},
  number={4},
  pages={669},
  year={2011}
}

@book{Davison-Hinkley-bootstrap,
	author = {A. C. Davison and D. V. Hinkley},
	title = {Bootstrap Methods and their Applications},
	address = {Cambridge, England},
	publisher = {Cambridge University Press},
	year = 1997}

@article{price_2013,
  title={Full updated statistical analysis of documentation of killing in the {S}yrian {A}rab {R}epulic},
  author={Price, Megan and Klingner, Jeff and Qtiesh, Anas and Ball, Patrick},
  journal={Report by the Human Rights Data Analysis Group to the United Nations Office of the High Commissioner for Human Rights (OHCHR)},
  year={2013}
}



@phdthesis{durham_2012,
  title={A framework for accurate, efficient private record linkage},
  author={Durham, Elizabeth Ashley},
  year={2012},
  school={Vanderbilt University}
}

@article{hall_2011,
  title={Privacy-preserving record linkage},
  author={Hall, Rob and Fienberg, Stephen E},
  journal={Privacy in Statistical Databases},
  pages={269--283},
  year={2011},
  organization={Springer}
}

@article{pauleve_2010,
  title={Locality sensitive hashing: A comparison of hash function types and querying mechanisms},
  author={Paulev{\'e}, Lo{\"\i}c and J{\'e}gou, Herv{\'e} and Amsaleg, Laurent},
  journal={Pattern Recognition Letters},
  volume={31},
  number={11},
  pages={1348--1358},
  year={2010}
}


@article{steorts_2014_spatial,
title={Spatial Smoothing and Clustering for Small Area Estimation},
author={Steorts, R. and Shalizi, C.},
journal={In preparation},
year={2014}
}

@article{wehbe_2014,
title={Regularized Brain Reading with
Shrinkage and Smoothing},
author={Wehbe, L. and Ramdas, A. and Steorts, R. and Shalizi, C.},
journal={Submitted},
year={2014}
}





@article{kass_1996,
  title={The selection of prior distributions by formal rules},
  author={Kass, Robert E and Wasserman, Larry},
  journal={Journal of the American Statistical Association},
  volume={91},
  number={435},
  pages={1343--1370},
  year={1996},
  publisher={Taylor \& Francis Group}
}

@article{lai_2011,
  title={Disambiguation and Co-Authorship Networks of the {US} Patent Inventor Database},
  author={Lai, Ronald and D’Amour, Alexander and Yu, Amy and Sun, Ye and Torvik, Vetle and Fleming, Lee},
  journal={Harvard Institute for Quantitative Social Science, Cambridge, MA},
  volume={2138},
  year={2011}
}

@article{carayol_2009,
  title={Who’s Who in Patents. A {B}ayesian approach},
  author={Carayol, Nicolas and Cassi, Lorenzo},
  journal={Cahiers du GREThA},
  volume={7},
  pages={2009--07},
  year={2009},
  publisher={Groupe de Recherche en Economie Th{\'e}orique et Appliqu{\'e}e}
}

@inbook{christen_2014,
title = {Noise-Tolerant Approximate Blocking for Dynamic Real-time Entity Resolution },
author = {Liang, Huizhi and Wang, Yanzhe and Christen, Peter and Gayler, Ross},
booktitle = {18th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD14)},
pages = {forthcoming},
year={2014},
editor = {Zhou, Zhi-Hua and Chen, Arbee L. P. and Tseng, Vincent S. and Tu, Bao Ho},
publisher = {Springer}
}


@article{clauset_2004,
  title={Finding community structure in very large networks},
  author={Clauset, Aaron and Newman, Mark EJ and Moore, Cristopher},
  journal={Physical Review E},
  volume={70},
  number={6},
  pages={066111},
  year={2004} 
} 

@article{fortunato_2010,
  title={Community detection in graphs},
  author={Fortunato, Santo},
  journal={Physics Reports},
  volume={486},
  number={3},
  pages={75--174},
  year={2010} 
}

@inbook{winkler_2006,
  title={Overview of Record Linkage and Current Research Directions},
  author={Winkler, William E},
  booktitle={Bureau of the Census},
  year={2006},
  organization={Citeseer}
}

@Manual{R_2013,
    title = {R: A Language and Environment for Statistical Computing},
    author = {{R Core Team}},
    organization = {R Foundation for Statistical Computing},
    address = {Vienna, Austria},
    year = {2013},
    url = {http://www.R-project.org/},
  }

 @Manual{borg_2012,
    title = {RecordLinkage: Record Linkage in R},
    author = {Andreas Borg and Murat Sariyar},
    year = {2012},
    note = {R package version 0.4-1},
    url = {http://CRAN.R-project.org/package=RecordLinkage},
  }


@article{kleiner_2011,
  title={A scalable bootstrap for massive data},
  author={Kleiner, Ariel and Talwalkar, Ameet and Sarkar, Purnamrita and Jordan, Michael I},
  journal={arXiv e-prints},
  year={2011},
  note={{arxiv:1112.5016}}
}


@inbook{al_2005,
  title={Blocking-aware private record linkage},
  author={Al-Lawati, Ali and Lee, Dongwon and McDaniel, Patrick},
  booktitle={Proceedings of the 2nd international workshop on Information quality in information systems},
  pages={59--68},
  year={2005} 
}
@article{sarma_2011,
  title={CBLOCK: An Automatic Blocking Mechanism for Large-Scale De-duplication Tasks},
  author={Sarma, Anish Das and Jain, Ankur and Machanavajjhala, Ashwin and Bohannon, Philip},
  journal={arXiv e-prints},
  year={2011},
  note={{arxiv:1111.3689}}
}

@article{breiman_2001,
  title={Random forests},
  author={Breiman, Leo},
  journal={Machine Learning},
  volume={45},
  number={1},
  pages={5--32},
  year={2001},
  publisher={Springer}
}

@article{christen_2012b,
  title={A survey of indexing techniques for scalable record linkage and deduplication},
  author={Christen, Peter},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  volume={24},
  number={9},
  pages={1537--1555},
  year={2012}
}


@inbook{gan_2012,
  title={Locality-sensitive hashing scheme based on dynamic collision counting},
  author={Gan, Junhao and Feng, Jianlin and Fang, Qiong and Ng, Wilfred},
  booktitle={Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data},
  pages={541--552},
  year={2012} 
}


@inbook{das_2012,
  title={An automatic blocking mechanism for large-scale de-duplication tasks},
  author={Das Sarma, Anish and Jain, Ankur and Machanavajjhala, Ashwin and Bohannon, Philip},
  booktitle={Proceedings of the 21st ACM international conference on Information and knowledge management},
  pages={1055--1064},
  year={2012} 
}


@book{rajaraman_2012,
  title={Mining of Massive Datasets},
  author={Rajaraman, Anand and Ullman, Jeffrey David},
  year={2012},
  publisher={Cambridge University Press}
}

@article{tantrum_2004,
  title={Hierarchical model-based clustering of large datasets through fractionation and refractionation},
  author={Tantrum, Jeremy and Murua, Alejandro and Stuetzle, Werner},
  journal={Information Systems},
  volume={29},
  number={4},
  pages={315--326},
  year={2004} 
}

@inbook{cutting_1992,
  title={Scatter/gather: A cluster-based approach to browsing large document collections},
  author={Cutting, Douglass R and Karger, David R and Pedersen, Jan O and Tukey, John W},
  booktitle={Proceedings of the 15th annual international ACM SIGIR conference on Research and development in information retrieval},
  pages={318--329},
  year={1992},
  organization={ACM}
}

@phdthesis{ventura_2013,
AUTHOR = "Ventura, Sam",
TITLE = "Large-Scale Clustering Methods with Applications to
Record Linkage",
SCHOOL = "CMU",
YEAR = "2013",
type = "PhD Thesis Proposal",
address = "Pittsburgh, PA",
}

@article{pfeffermann_2013,
  title={New important developments in small area estimation},
  author={Pfeffermann, Danny},
  journal={Statistical Science},
  volume={28},
  number={1},
  pages={40--68},
  year={2013},
  publisher={Institute of Mathematical Statistics}
}

@article{wainwright_2008,
  title={Graphical models, exponential families, and variational inference},
  author={Wainwright, Martin J and Jordan, Michael I},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={1},
  number={1-2},
  pages={1--305},
  year={2008},
  publisher={Now Publishers Inc.}
}

@article{broderick_2012,
  title={MAD-Bayes: MAP-based asymptotic derivations from Bayes},
  author={Broderick, Tamara and Kulis, Brian and Jordan, Michael I},
  journal={arXiv e-prints},
  year={2012},
  note={{arxiv:1212.2126}}
}

@article{broderick_2013,
  title={Streaming Variational Bayes},
  author={Broderick, Tamara and Boyd, Nicholas and Wibisono, Andre and Wilson, Ashia C and Jordan, Michael I},
  journal={arXiv e-prints},
  year={2013},
  note={{arxiv:1307.6769}}
}

@article{quantin_1998,
  title={Automatic record hash coding and linkage for epidemiological follow-up data confidentiality},
  author={Quantin, C and Bouzelat, H and Allaert, FA and Benhamiche, AM and Faivre, J and Dusserre, L},
  journal={Methods of information in medicine},
  volume={37},
  number={3},
  pages={271--277},
  year={1998},
  publisher={Schattauer}
}

@inbook{kim_2010,
  title={HARRA: fast iterative hashed record linkage for large-scale data collections},
  author={Kim, Hung-sik and Lee, Dongwon},
  booktitle={Proceedings of the 13th International Conference on Extending Database Technology},
  pages={525--536},
  year={2010},
  organization={ACM}
}



@inbook{inan_2010,
  title={Private Record Matching Using Differential Privacy},
  author={Inan, Ali and Kantarcioglu, Murat and Ghinita, Gabriel and Bertino, Elisa},
  booktitle={Proceedings of the 13th International Conference on Extending Database Technology},
  pages={123--134},
  year={2010} 
}

@inbook{gionis_1999,
  title={Similarity search in high dimensions via hashing},
  author={Gionis, Aristides and Indyk, Piotr and Motwani, Rajeev and others},
  booktitle={VLDB},
  volume={99},
  pages={518--529},
  year={1999}
}

@article{torvik_2009,
  title={Author Name Disambiguation in MEDLINE},
  author={Torvik, Vetle I and Smalheiser, Neil R},
  journal={ACM Transactions on Knowledge Discovery from Data},
  volume={3},
  number={3},
  pages={11},
  year={2009} 
}

@inbook{giles_2009,
  title={Disambiguating authors in academic publications using random forests},
  author={Treeratpituk, Pucktada and Giles, C Lee},
  booktitle={Proceedings of the 9th ACM/IEEE-CS joint conference on Digital libraries},
  pages={39--48},
  year={2009} 
}

@inbook{han_2004,
  title={Two Supervised Learning Approaches for Name Disambiguation in Author Citations},
  author={Han, Hui and Giles, Lee and Zha, Hongyuan and Li, Cheng and Tsioutsiouliklis, Kostas},
  booktitle={Digital Libraries, 2004. Proceedings of the 2004 Joint ACM/IEEE Conference on},
  pages={296--305},
  year={2004} 
}

@techreport{winkler_2002,
  title={Methods for record linkage and {B}ayesian networks},
  author={Winkler, William E},
  year={2002},
  institution={Statistical Research Division, US Census Bureau, Washington, DC}
}


@inbook{christen_2006,
  title={Privacy-preserving data linkage and geocoding: Current approaches and research directions},
  author={Christen, Peter},
  booktitle={Data Mining Workshops, 2006. ICDM Workshops 2006. 6th IEEE International Conference on},
  pages={497--501},
  year={2006} 
}


@article{steorts_2013b,
  title={A {B}ayesian Approach to Graphical Record Linkage and De-duplication},
  author={Steorts, R. C. and Hall, Rob and Fienberg, S.E.},
  journal={Submitted},
  year={2013}
}

@article{ventura2015seeing,
  title={Seeing the Non-Stars: ({S}ome) Sources of Bias in Past Disambiguation Approaches and a New Public Tool Leveraging Labeled Records},
  author={Ventura, Samuel L and Nugent, Rebecca and Fuchs, Erica RH},
  journal={Research Policy},
  volume={44},
  number={9},
  pages={1672--1701},
  year={2015},
  publisher={Elsevier}
}

@inbook{treeratpituk2009disambiguating,
  title={Disambiguating Authors in Academic Publications Using Random Forests},
  author={Treeratpituk, Pucktada and Giles, C Lee},
  booktitle={Proceedings of the 9th ACM/IEEE-CS joint conference on Digital libraries},
  pages={39--48},
  year={2009}
}

@misc{west2008pseudocode,
  title={Pseudocode for Calculating Eigenfactor TM Score and Article Influence TM Score Using Data From Thomson-Reuters Journal Citations Reports},
  author={West, Jevin and Bergstrom, Carl T},
  year={2008},
  publisher={mimeo, University of Washington}
}

@article{ventura_2012,
  title={Methods matter: Revamping inventor disambiguation algorithms with classification models and labeled inventor records},
  author={Ventura, Samuel L and Nugent, Rebecca and Fuchs, Erica},
  journal={SSRN eLibrary},
  year={2012}
}

@article{reiter_2007,
  title={The multiple adaptations of multiple imputation},
  author={Reiter, Jerome P and Raghunathan, Trivellore E},
  journal={Journal of the American Statistical Association},
  volume={102},
  number={480},
  pages={1462--1471},
  year={2007},
  publisher={Taylor \& Francis}
}

@article{ashburner2008spm8,
 title={SPM8 manual},
 author={Ashburner, J. and Chen, CC and Flandin, G. and Henson, R. and Kiebel, S. and Kilner, J. and Litvak, V. and Moran, R. and Penny, W. and Stephan, K. and others},
 journal={Functional Imaging Laboratory, Institute of Neurology},
 year={2008}
}

@book{gelman_2003,
	author = "Andrew Gelman and John B. Carlin and Hal S. Stern and Donald B. Rubin",
	title = "{Bayesian} Data Analysis",
	edition = "Second",
	address = "London",
	publisher = "CRC Press",
	year = 2003}


@book{hastie_2001,
 title={The Elements of Statistical Learning: Data Mining, Inference, and Prediction},
 author={Trevor Hastie and Robert Tibshirani and Jerome Friedman},
 year={2001},
 publisher={Springer},
 address ={New York}
}

@article{norman_2006,
  title = "Beyond mind-reading: multi-voxel pattern analysis of {fMRI} data",
  author = "Kenneth A. Norman and Sean M. Polyn and Greg J. Detre and James V. Haxby",
  journal = "Trends in Cognitive Sciences",
  volume = 10,
  year = 2006,
  pages = "424--430",
  doi = "10.1016/j.tics.2006.07.005"}

@article{pereira_2009,
  author = "Francisco Pereira and Tom Mitchell and Matthew Botvinick",
  title = "Machine learning classifiers and {fMRI}: {A} tutorial overview",
  journal = "NeuroImage",
  volume = 45,
  year = 2009,
  pages = "S199--S209",
  doi = "10.1016/j.neuroimage.2008.11.007"}

@article{yarkoni_2011,
  author = "Tal Yarkoni and Russell A. Poldrack and Thomas E. Nichols and Van Essen, David C. and Tor D. Wager",
  title = "Large-scale automated synthesis of human functional neuroimaging data",
  journal = "Nature Methods",
  volume = 8,
  year = 2011,
  pages = "665--670",
  doi = "10.1038/nmeth.1635"}

@article{poldrack_2008,
  author="Russell A. Poldrack",
  title = "The role of {fMRI} in Cognitive Neuroscience: where do we stand?",
  journal = "Current Opinion in Neurobiology",
  volume = 18,
  year = 2008,
  pages = "223--227",
  doi = "10.1016/j.conb.2008.07.006"}


@book{bilenko_2006,
  title={Learnable similarity functions and their application to record linkage and clustering},
  author={Bilenko, Mikhail Yuryevich},
  volume={67},
  number={12},
  year={2006}
}

@book{ashby_2011,
  author={F. Gregory Ashby},
  title ={Statistical Analysis of {fMRI} Data},
  address = {Cambridge, Massachusetts},
  publisher ={MIT Press},
  year={2011}}

@book{gigerenzer_1989,
  title={The Empire of Chance: How Probability Changed Science and Everyday Life},
  author = {Gerd Gigerenzer and Zeno Swijtink and Theodore Porter and Lorraine Daston and John Beatty and Lorenz Kruger},
  address = {Cambridge, England},
  publisher = {Cambridge University Press},
  year = {1989}}

@misc{lee_2011,
  title={Spatial {B}ayesian Variable Selection Models on Functional Magnetic Resonance Imaging Time-Series Data},
  author={Lee, Kuo-Jung and Jones, Galin L. and Caffo, Brian S. and Bassett, Susan Spear},
  howpublishedl={Preprint},
  year={2011}
}

@incollection{pillow_2013,
  title={Bayesian Structure Learning for Functional Neuroimaging},
 author={Park, Mijung and Koyejo, Oluwasanmi and Ghosh, Joydeep and Poldrack, Russell A and Pillow, Jonathan W},
  booktitle={16th International Conference on Artificial Intelligence and Statistics},
  year={2013},
  editor = {Carlos M. Carlvaho and Pradeep Ravikumar},
  pages = {489--497},
}

@article{genovese_2000,
 title={A {Bayesian} time-course model for functional magnetic resonance imaging data},
 author={Genovese, Christopher R},
 journal={JASA},
 volume={95},
 pages={691--703},
 year={2000},
 publisher={Taylor \& Francis Group}
}

@misc{lee_2013,
  title={Spatial {B}ayesian selection models on functional magnetic resonance imaging time series data},
  author={Lee, K.-J. and Jones, G. L. and  Caffo, B. S. and Bassett, S.},
  journal={Bayesian Analysis},
  year={2013},
  publisher={International Society for Bayesian Analysis}
}




@article{kyung_2010,
  title={Penalized regression, standard errors, and {B}ayesian lassos},
  author={Kyung, Minjung and Gill, Jeff and Ghosh, Malay and Casella, George},
  journal={Bayesian Analysis},
  volume={5},
  pages={369--411},
  year={2010},
  publisher={International Society for Bayesian Analysis}
}

@article{hoerl_1970,
  title={Ridge regression: Biased estimation for nonorthogonal problems},
  author={Hoerl, Arthur E and Kennard, Robert W},
  journal={Technometrics},
  volume={12},
  pages={55--67},
  year={1970},
  publisher={Taylor \& Francis Group}
}

@article{tibshirani_1996,
  title={Regression shrinkage and selection via the lasso},
  author={Tibshirani, Robert},
  journal={Journal of the Royal Statistical Society. Series B (Methodological)},
  volume = {58},
  pages={267--288},
  year={1996},
}

@article{zou_2005,
  title={Regularization and variable selection via the elastic net},
  author={Zou, Hui and Hastie, Trevor},
  journal={JRSSB (Statistical Methodology)},
  volume={67},
  pages={301--320},
  year={2005},
  publisher={Wiley Online Library}
}

@book{shepherd_1994,
  title={Neurobiology},
  author={Shepherd, Gordon M},
  edition ={3},
  year={1994},
  publisher={Oxford University Press}
}

@article{copas_1990,
	Author = {Copas, J. and Hilton, {F.J.}},
	Journal = {Journal of the Royal Statistical Society, Series A},
	Title = {Record Linkage: Statistical Models for Matching Computer Records},
	Volume = {153},
	Number = {3},
	pages =	 {287-320},
	Year = {1990}}	
	
@article{everson_2000,
	Author = {Everson, P. and Morris, C.},
	Journal = {Journal of the Royal Statistical Society, Series B},
	Title = {Inference of multivariate normal hierarchical models},
	Volume = {62},
	pages =	 {399-412},
	Year = {2000}}	

@article{cowles_1996,
	Author = {Cowles, M. and Carlin, B.},
	Journal = {Journal of the American Statistical Association},
	Title = {Markov chain {M}onte {C}arlo Convergence Diagnostics: A Comparative Review},
	Volume = {91},
	Number= {434},
	Pages = {883-904},
	Year = {1996}
	}

@article{datta_1991,
	Author = {Datta, G. and Ghosh, M.},
	Journal = {The Annal of Statistics},
	Title = {Bayesian Prediction in Linear Models: Applications to Small Area Estimation},
	Volume = {19},
	Number= {4},
	Pages = {1748-1770},
	Year = {1991}
	}

@article{gates_2011,
	Author = {Gates, W.},
	Journal = {Journal of Privacy and Confidentiality},
	Pages = {3-40},
	Title = {How Uncertainty about Privacy and Confidentiality Is Hampering Efforts to More Effectively Use Administrative Records in Producing {U.S.} National Statistics},
	Volume = {10},
	Number= {905},
	Year = {2011}
	}
	
@article{wheaton_2009,
	Author = {Wheaton, W. and Cajka, J. and Chasteen, B. and Wagener, D. and Cooley, P. and Ganapathi, L. and Roberts, D. and Allpress, J.},
	Journal = {Methods Rep RTI Press},
	Title = {Synthesized Population Databases: A U.S. Geospatial Database for Agent-Based Models},
	Volume = {3},
	Number= {2},
	Year = {2009},
	url = {doi:  10.3768/rtipress.2009.mr.0010.0905}
	}
	
@article{beckman_1996,
	Author = {Beckman, R. and Baggerly, K. and Mc{K}ay, D.},
	Journal = {Transportation Research Part A: Policy and Practice},
	Title = {Creating synthetic baseline populations},
	Volume = {30},
	Number= {6},
	Year = {1996},
	Pages = {415-429}
	}	
	
	

@book{acs_2007,
	Address = {Using the American Community Survey, National Research Council},
	Author = {Using the American Community Survey, National Research Council},
	Date-Added = {2013-05-30 03:49:33 +0000},
	Date-Modified = {2013-05-30 03:51:42 +0000},
	Publisher = {Springer},
	Title = {Using the American Community Survey Ð Benefits and Challenges, Panel on the Functionality and Usability of Data from the American Community Survey},
	Year = {2007}}	
	
@misc{midas_2012,
	Author = {MIDAS},
	Title = {Models of Infectious Disease Agent Study},
	Date-Modified = {2013-05-30 04:51:43 +0000},
	Url = {https://www.epimodels.org/midas/Rpubsyntdata1.do},
	Year = 2012,
	Bdsk-Url-1 = {https://www.epimodels.org/midas/Rpubsyntdata1.do}	}
	

@article{battese_1988,
	Author = {Battese, G. and Harter, R. and Fuller, W.},
	Journal = {Journal of the American Statistical Association},
	Pages = {28-36},
	Title = {An Error-Components Model for Prediction of County Crop Area Using Survey and Satellite Data},
	Volume = {83},
	Year = {1988}}
	
@article{ghosh_2009,
	Author = {Ghosh, M. and Kim, D. and Sinha, K. and Maiti,T. and Katzoff, M. and Parsons, V.},
	Date-Added = {2010-04-22 16:04:05 -0400},
	Date-Modified = {2010-04-22 16:04:05 -0400},
	Journal = {Survey Methodology},
	Pages = {53-66},
	Title = {Hierarchical and empirical {B}ayes small domain estimation of the proportion
of persons without health insurance
or minority subpopulations},
	Volume = {35},
	Number = {1},
	Year = {2009}}	
	
@article{ghosh_1998,
	Author = {Ghosh, M. and Natarajan, K. and Stroud, T. and Carlin, B.},
	Date-Added = {2010-04-22 16:04:05 -0400},
	Date-Modified = {2010-04-22 16:04:05 -0400},
	Journal = {Journal of the American Statistical Association},
	Pages = {53-66},
	Title = {Generalized Linear Models for Small Area-Estimation},
	Volume = {93},
	Number = {441},
	Year = {1998}}			
	
	
@article{isaki_2004,
	Author = {Isaki, C.T. and Tsay, J.H and Fuller, W.A.},
	Date-Added = {2010-04-22 16:04:05 -0400},
	Date-Modified = {2010-04-22 16:04:05 -0400},
	Journal = {Survey Methodology},
	Pages = {35-44},
	Title = {Weighting sample data subject 
to independent controls},
	Volume = {20},
	Year = {2004}}			

@article{liseo_jos_2011,
	Author = {Liseo, B. and Tancredi, A.},
	Date-Added = {2013-05-30 03:56:51 +0000},
	Date-Modified = {2013-05-30 03:58:16 +0000},
	Journal = {Journal of Official Statistics},
	Number = {3},
	Pages = {491--505},
	Title = {Bayesian estimation of population size via linkage of multivariate Normal data sets},
	Volume = {27},
	Year = {2011}}
	
@article{christen_2011,
 author =  {Peter Christen},
 title    =   {A Survey of Indexing Techniques for Scalable Record
            Linkage and Deduplication},
 journal = {IEEE Transactions on Knowledge and Data Engineering},
 volume =  24,
 number =  9,
 year =    2012
}
	

@techreport{Winkler_1999,
	Institution = {Statistical Research Division, U.S. Bureau of the Census},
	Author = {W.E. Winkler},
	Date-Added = {2013-05-30 03:43:45 +0000},
	Date-Modified = {2013-05-31 02:21:07 +0000},
	Title = {The state of record linkage and current research problems},
	Type = {Technical Report},
	Year = {1999}}

@article{sadinle_multi_1,
	Author = {Sadinle, M. and Fienberg, S.E.},
	Date-Modified = {2013-05-31 02:24:32 +0000},
	Journal = {Journal of the American Statistical Association},
	Title = {A Generalized {F}ellegi-{S}unter Framework for Multiple Record Linkage with Application to Homicide Record-Systems},
	Volume = {108},
	Number = {502},
	pages = {385-397},
	Year = {2013}}

@misc{sadinle_multi_2,
	Author = {Sadinle, M. and Hall, R. and Fienberg, S.E.},
	Date-Modified = {2013-05-31 02:24:22 +0000},
	Howpublished = {ISI World Congress, Dublin},
	Note = {Invited Paper},
	Title = {Approaches to Multiple Record Linkage},
	Year = {2011}}

@inbook{hall12,
	Address = {Berlin},
	Author = {Hall, R. and Fienberg, S.E.},
	Booktitle = {Privacy in Statistical Databases 2012},
	Date-Modified = {2013-05-31 02:32:24 +0000},
	Editor = {J. Domingo-Ferrer and I. Tinnirello},
	Pages = {131--142},
	Publisher = {Springer},
	Series = {Lecture Notes in Computer Science},
	Title = {Valid Statistical Inference on Automatically Matched Files},
	Volume = {7556},
	Year = {2012}}
	

@article{smmcmc,
	Author = {Jain, S. and Neal, R.},
	Journal = {Journal of Computational and Graphical Statistics},
	Pages = {158--182},
	Title = {A Split-Merge Markov Chain Monte Carlo Procedure for the Dirichlet Process Mixture Model},
	Volume = {13},
	Year = {2004}}

@article{zhang_2011,
	Author = {Zhang, S. and Midthune, D. and Guenther, P.M. and Krebs-Smith, S.M. and Kipnis, V. and Dodd, K.W. and Buckman, D.W. and Tooze, J.A. and Freedman, L. and Carroll, R.J.},
	Journal = {Annals of Applied Statistics},
	Number = {2B},
	Pages = {1456-87},
	Title = {A new multivariate measurement error model with zero-inflated dietary data, and its application to dietary assessment},
	Volume = {5},
	Year = {2011}}

@article{carroll_2013,
	Author = {Carroll, R.J.},
	Journal = {Statistical Science},
	Number = {?},
	Pages = {?},
	Title = {Estimating the Distribution of Dietary Consumption Patterns},
	Volume = {?},
	Year = {2013}}

@article{little_1991,
	Author = {Little, R.},
	Journal = {Journal of Official Statistics},
	Number = {4},
	Pages = {405-424},
	Title = {Inference with survey weights},
	Volume = {7},
	Year = {1991}}

@article{fienberg_2009,
	Author = {Fienberg, S.},
	Journal = {Journal of Privacy and Confidentiality},
	Number = {2},
	Title = {The Relevance or Irrelevance of Weights for Confidentiality and Statistical Analyses},
	Volume = {1},
	Year = {2009}}

@article{chaud_2008,
	Author = {Chaudhuri, S. and Handock, M. and Rendall, M.},
	Journal = {Journal of the Royal Statistical Society, B,},
	Number = {2},
	Pages = {311-328},
	Title = {A Conditional empirical likelihood approach for combining sampling design and population level information},
	Volume = {70},
	Year = {2008}}

@article{elliot_2000,
	Author = {Elliot, M. and Little, R.},
	Journal = {Journal of Privacy and Confidentiality},
	Number = {3},
	Pages = {191-209},
	Title = {Model-Based Alternatives to Trimming Survey Weights},
	Volume = {16},
	Year = {2000}}

@article{pfeffermann_1993,
	Author = {Pfeffermann, D.},
	Journal = {International Statistical Review},
	Number = {1},
	Pages = {317-337},
	Title = {The Role of Sampling Weights When Modeling Survey Data},
	Volume = {61},
	Year = {1993}}
	
@article{pfeffermann_2013,
	Author = {Pfeffermann, D.},
	Journal = {Statistical Science},
	Number = {1},
	Pages = {40--68},
	Title = {New Important Developments in Small Area Estimation},
	Volume = {28},
	Year = {2013}}	
	
	

@article{gelman_2007,
	Author = {Gelman, A.},
	Journal = {Statistical Science},
	Number = {2},
	Pages = {153-164},
	Title = {Struggles with survey weighting and regression modeling},
	Volume = {22},
	Year = {2007}}

@article{little_2007,
	Author = {Little, R.},
	Journal = {Statistical Science},
	Number = {2},
	Pages = {171-174},
	Title = {Comment: struggles with survey weighting and regression modeling},
	Volume = {22},
	Year = {2007}}

@article{ugarte_2009,
	Author = {Ugarte, {M. D.} and Goicoa, T. and Militino, {A. F.}},
	Journal = {TEST},
	Pages = {342-364},
	Title = {Benchmarked estimates in small areas using linear mixed models with restrictions.},
	Volume = {18},
	Year = {2009}}

@misc{liseo_2013,
	Author = {B. Liseo and A. Tancredi},
	Date-Modified = {2013-05-30 04:51:43 +0000},
	Title = {Some advances on {B}ayesian record linkage and inference for linked data},
	Url = {http://www.ine.es/e/essnetdi_ws2011/ppts/Liseo_Tancredi.pdf},
	Year = 2013,
	Bdsk-Url-1 = {http://www.ine.es/e/essnetdi_ws2011/ppts/Liseo_Tancredi.pdf}}

@article{winkler_2000,
  Title = {Machine Learning, Information Retrieval, and Record Linkage},
  author={Winkler, William E},
  journal={Proceedings of the Section on Survey Research Methods},
  publisher = {American Statistical Association},
  pages={20--29},
  year={2000}
}

@article{butar_2003,
	Author = {Butar, F. and Lahiri, P.},
	Journal = {J. Statist. Plann. Inference},
	Pages = {63-76},
	Title = {On measures of uncertainty of empirical Bayes small area estimators.},
	Volume = {112},
	Year = {2003}}

@article{jain_2004,
	Author = {S. Jain and R. Neal},
	Date-Modified = {2013-05-31 02:41:39 +0000},
	Journal = {Journal of Computational and Graphical Statistics},
	Pages = {158--182},
	Title = {A Split-Merge {M}arkov Chain {M}onte {C}arlo Procedure for the {D}irichlet Process Mixture Model},
	Volume = {13},
	Year = {2004}}

@article{bell_2013,
	Author = {Bell, W.R. and Datta, {G.S.} and Ghosh, M.},
	Date-Added = {2010-04-22 16:04:05 -0400},
	Date-Modified = {2010-04-22 16:04:05 -0400},
	Journal = {Biometrika},
	Title = {Benchmarked Small Area Estimators},
	Volume = {100},
	Number={1},
	Pages = {189-202},
	Year = {2013}}
	

@article{ghosh_2008,
	Author = {Ghosh, M. and Mergel, V. and Datta, G.},
	Date-Added = {2010-04-22 16:04:05 -0400},
	Date-Modified = {2010-04-22 16:04:05 -0400},
	Journal = {Journal of Multivariate Analysis},
	Pages = {1941-1961},
	Title = {Estimation, Prediction and the Stein Phenomenon under Divergence Loss},
	Volume = {99},
	Year = {2008}}

@article{bell_1999,
	Author = {Bell, W.R.},
	Date-Added = {2010-04-22 16:04:05 -0400},
	Date-Modified = {2010-04-22 16:04:05 -0400},
	Journal = {Bulletin of the International Statistical Institute, 52nd Session, Helsinki},
	Title = {Accounting for uncertainty about variances in small area estimation},
	Year = {1999}}

@article{bell_2010,
	Author = {Bell, W.R. and Datta, G.S. and Ghosh, M.},
	Date-Added = {2010-04-22 16:04:05 -0400},
	Date-Modified = {2010-04-22 16:04:05 -0400},
	Journal = {Preprint},
	Title = {Benchmarked Small Area Estimators},
	Year = {2010}}

@book{berger_1985,
	Author = {Berger, J.O.},
	Date-Added = {2010-04-22 16:04:05 -0400},
	Date-Modified = {2010-04-22 16:04:05 -0400},
	Publisher = {Springer-Verlag, New York},
	Title = {Statistical Decision Theory and {B}ayesian Analysis, 2nd Edition},
	Year = {1985}}

@article{datta_2000,
	Author = {Datta, G.S. and Lahiri, P.},
	Date-Added = {2010-04-22 16:04:05 -0400},
	Date-Modified = {2010-04-22 16:04:05 -0400},
	Journal = {Statistica Sinica},
	Pages = {613-627},
	Title = {A unified measure of uncertainty of estimated best linear unbiased predictors in small area estimation problems.},
	Volume = {10},
	Year = {2000}}

@article{datta_2005,
	Author = {Datta, G.S. and Rao, J.N.K. and Smith, D.D.},
	Date-Added = {2010-04-22 16:04:05 -0400},
	Date-Modified = {2010-04-22 16:04:05 -0400},
	Journal = {Biometrika},
	Pages = {183-196},
	Title = {On measuring the variability of small area estimators under a basic area level model},
	Volume = {92},
	Year = {2005}}


@article{datta_2011,
  title={Bayesian benchmarking with applications to small area estimation},
  author={Datta, GS and Ghosh, M and Steorts, R and Maples, J},
  journal={Test},
  volume={20},
  number={3},
  pages={574--588},
  year={2011},
  publisher={Springer}
}

@article{deville_1992,
	Author = {Deville, J.C. and Sarndal, C.E.},
	Date-Added = {2010-04-22 16:04:05 -0400},
	Date-Modified = {2010-04-22 16:04:05 -0400},
	Journal = {Journal of the American Statistical Assocation},
	Number = {418},
	Title = {Calibration Estimators in Survey Sampling},
	Volume = {87},
	Year = {1992}}

@article{ghosh_1992,
	Author = {Ghosh, M.},
	Date-Added = {2010-04-22 16:04:05 -0400},
	Date-Modified = {2010-04-22 16:04:05 -0400},
	Journal = {Journal of the American Stastical Association},
	Pages = {533-540},
	Title = {Constrained Bayes estimation with applications},
	Volume = {87},
	Year = {1992}}

@article{ghosh_2011,
	Author = {Ghosh, M.},
	Journal = {Statistical Science},
	Pages = {187-202},
	Title = {Objective Priors: An Introduction for Frequentists},
	Volume = {26},
	Year = {2011}}

@article{ghosh_2013,
	Author = {Ghosh, M. and Steorts, R.},
	Journal = {TEST},
	Volume = {22},
        Pages = {670-687},
	Title = {Two-Stage {B}ayesian Benchmarking as Applied to Small Area Estimation},
	Year = {2013}}

@article{steorts_2011,
	Author = {Steorts, R. and Ghosh, M.},
	Journal = {Statistica Sinica},
	Title = {On Estimation of Mean Squared Errors of Benchmarked Empirical Bayes Estimators},
	Volume = {2},
	Year = {2013}}

@article{steorts_2013,
	Author = {Steorts, R.},
	Journal = {Working Paper},
	Title = {Divergence losses under benchmarking for small area estimation},
	Year = {2013}}

@article{isaki_2000,
	Author = {Isaki, C.T. and Tsay, J.H and Fuller, W.A.},
	Date-Added = {2010-04-22 16:04:05 -0400},
	Date-Modified = {2010-04-22 16:04:05 -0400},
	Journal = {Suvery Methodology},
	Pages = {31-42},
	Title = {Estimation of census adjustment factors},
	Volume = {26},
	Year = {2000}}

@article{little_2004,
	Author = {Little, R.J.},
	Journal = {Journal of the American Stastical Association},
	Number = {466},
	Pages = {546-556},
	Title = {To Model or Not to Model? {C}ompeting Modes of Inference for Finite Population Sampling},
	Volume = {99},
	Year = {2004}}

@article{louis_1984,
	Author = {Louis, T.A.},
	Date-Added = {2010-04-22 16:04:05 -0400},
	Date-Modified = {2010-04-22 16:04:05 -0400},
	Journal = {Journal of the American Stastical Association},
	Number = {393-398},
	Title = {Estimating a population of parameter values using Bayes and empirical Bayes methods},
	Volume = {79},
	Year = {1984}}

@article{nandram_2007,
	Author = {Nandram, B. and Toto, Ma. C.S. and Choi, J.W.},
	Date-Added = {2010-04-22 16:04:05 -0400},
	Date-Modified = {2010-04-22 16:04:05 -0400},
	Journal = {Preprint},
	Title = {A {B}ayesian benchmarking for small areas},
	Year = {2007}}

@article{fuller_2007,
	Author = {Fuller, W.A.},
	Date-Added = {2010-04-22 16:04:05 -0400},
	Date-Modified = {2010-04-22 16:04:05 -0400},
	Journal = {Preprint},
	Title = {Small area prediction subject to restrection},
	Year = {2007}}

@article{fay_1979,
	Author = {Fay, R.E. and Herriot, R.A.},
	Date-Added = {2010-04-22 16:04:05 -0400},
	Date-Modified = {2010-04-22 16:04:05 -0400},
	Journal = {Journal of the American Stastical Association},
	Pages = {269-277},
	Title = {Estimates of income from small places: an application of {James-Stein} procedures to census data},
	Volume = {74},
	Year = {1979}}

@article{pfeffermann_1981,
	Author = {Pfeffermann, D. and Nathan, G.},
	Date-Added = {2010-04-22 16:04:05 -0400},
	Date-Modified = {2010-04-22 16:04:05 -0400},
	Journal = {Journal of the American Stastical Association},
	Pages = {681-689},
	Title = {Regression analysis of data from a cluster sample},
	Volume = {76},
	Year = {1981}}

@article{pfeffermann_1991,
	Author = {Pfeffermann, D. and Barnard, C.H.},
	Date-Added = {2010-04-22 16:04:05 -0400},
	Date-Modified = {2010-04-22 16:04:05 -0400},
	Journal = {Journal of Business and Economic Statistics},
	Pages = {31-42},
	Title = {Some new estimators for small area means with application to the assessment of farmland values},
	Volume = {9},
	Year = {1991}}

@article{pfeffermann_2006,
	Author = {Pfeffermann, D. and Tiller, R.},
	Date-Added = {2010-04-22 16:04:05 -0400},
	Date-Modified = {2010-04-22 16:04:05 -0400},
	Journal = {Journal of the American Stastical Association},
	Pages = {1387-1397},
	Title = {Small area estimation with state-space models subject to benchmark constraints},
	Volume = {101},
	Year = {2006}}

@article{prasad_1990,
	Author = {Prasad, N.G.N. and Rao, J.N.K.},
	Date-Added = {2010-04-22 16:04:05 -0400},
	Date-Modified = {2010-04-22 16:04:05 -0400},
	Journal = {Journal of the American Stastical Association},
	Pages = {163-171},
	Title = {The estimation of the mean squared error of small-area estimators},
	Volume = {85},
	Year = {1990}}

@book{rao_2003,
	Author = {Rao, J.N.K.},
	Date-Added = {2010-04-22 16:04:05 -0400},
	Date-Modified = {2010-04-22 16:04:05 -0400},
	Publisher = {Wiley, New York},
	Title = {Small Area Estimation},
	Year = {2003}}

@article{srivastava_1992,
	Author = {Srivastava, J. and Ouyang, Z.},
	Journal = {Journal of Planning and Statistics},
	Pages = {199-218},
	Title = {Studies on a general estimator in sampling utilizing extraneous information through a sample weight function},
	Volume = {31},
	Year = {1992}}

@article{sweeting_2006,
	Author = {Sweeting, T. and Datta, G.S. and Ghosh, M.},
	Journal = {Annals of Statistics},
	Pages = {441-468},
	Title = {Nonsubjective priors via predictive relative entropy regret},
	Volume = {34},
	Year = {2006}}

@article{you_2004,
	Author = {You, Y. and Rao, J.N.K},
	Date-Added = {2010-04-22 16:04:05 -0400},
	Date-Modified = {2010-04-22 16:04:05 -0400},
	Journal = {Statistics in Transition},
	Pages = {631-640},
	Title = {Benchmarking hierarchical{B}ayes small area estimators in the {C}anadian census undercoverage estimation},
	Volume = {6},
	Year = {2004}}

@article{you_2003,
	Author = {You, Y. and Rao, J.N.K},
	Date-Added = {2010-04-22 16:04:05 -0400},
	Date-Modified = {2010-04-22 16:04:05 -0400},
	Journal = {Journal of Statistical Planning and Inference},
	Pages = {197-208},
	Title = {Pseudo hierarchical Bayes small area estimation combining unit level models and survey weights},
	Volume = {111},
	Year = {2003}}

@article{you_2002,
	Author = {You, Y. and {Rao, J.N.K}},
	Date-Added = {2010-04-22 16:04:05 -0400},
	Date-Modified = {2010-04-22 16:04:05 -0400},
	Journal = {The Canadian Journal of Statistics},
	Pages = {431-439},
	Title = {A pseudo-empirical best linear unbiased prediction approach to small area estimation using survey weights.},
	Volume = {30},
	Year = {2002}}

@article{wang_2008,
	Author = {Wang, J. and Fuller, W.A. and Qu, Y.},
	Date-Added = {2010-04-22 16:04:05 -0400},
	Date-Modified = {2010-04-22 16:04:05 -0400},
	Journal = {Survey Methodology},
	Pages = {29-36},
	Title = {Small area estimation under a restriction},
	Volume = {34},
	Year = {2008}}

@article{zellner_1986,
	Author = {Zellner, A.},
	Date-Added = {2010-04-22 16:04:05 -0400},
	Date-Modified = {2010-04-22 16:04:05 -0400},
	Journal = {Advances in Econometrics},
	Pages = {171-182},
	Title = {Further results on {B}ayesian minimum expected loss (MELO) estimates and posterior distributions for structural coefficients.},
	Year = {1986}}

@article{zellner_1988,
	Author = {Zellner, A.},
	Date-Added = {2010-04-22 16:04:05 -0400},
	Date-Modified = {2010-04-22 16:04:05 -0400},
	Journal = {Journal of Econometrics},
	Pages = {27-50},
	Title = {{B}ayesian analysis in econometrics},
	Volume = {37},
	Year = {1988}}

@book{zellner_1994,
	Author = {Zellner, A.},
	Date-Added = {2010-04-22 16:04:05 -0400},
	Date-Modified = {2010-04-22 16:04:05 -0400},
	Publisher = {Springer-Verlag, New York},
	Series = {{B}ayesian and non-{B}ayesian estimation using balanced loss functions},
	Title = {Statistical Decision Theory and Related Topics},
	Year = {1994}}
	
@incollection{lehtonen_2009,
	Author = {Lehtonen, R. and Veijanen, A.},
	Date-Added = {2010-04-22 16:04:05 -0400},
	Date-Modified = {2010-04-22 16:04:05 -0400},
	Publisher = {North-Holland, Amsterdam},
	Editor = {D. Pfeffermann and C. R. Rao}, 
	Series = {Handbook of Statistics},
	Booktitle = {Sample Surveys: Inference and Analysis},
	Title = {Design-based methods of estimation for domains and small areas.},
	Volume = {29B},
	Pages = {219--249},
	Year = {2009}}	
	

@article{mitchell2008predicting,
  title={Predicting human brain activity associated with the meanings of nouns},
  author={Mitchell, Tom M. and Shinkareva, Svetlana V. and Carlson, Andrew and Chang, Kai-Min and Malave, Vicente L. and Mason, Robert A. and Just, Marcel Adam},
  journal={Science},
  volume={320},
  pages={1191--1195},
  year={2008},
  publisher={American Association for the Advancement of Science}
}

@article{sudre2012tracking,
  title={Tracking neural coding of perceptual and semantic features of concrete nouns},
  author={Sudre, Gustavo and Pomerleau, Dean and Palatucci, Mark and Wehbe, Leila and Fyshe, Alona and Salmelin, Riitta and Mitchell, Tom},
  journal={NeuroImage},
  volume={62},
  pages={451--463},
  year={2012},
  publisher={Elsevier}
}

@article{tzourio2002automated,
  title={Automated anatomical labeling of activations in {SPM} using a macroscopic anatomical parcellation of the {MNI} {MRI} single-subject brain},
  author={Tzourio-Mazoyer, N and Landeau, B and Papathanassiou, D and Crivello, F and Etard, O and Delcroix, N and Mazoyer, Bernard and Joliot, M},
  journal={Neuroimage},
  volume={15},
  pages={273--289},
  year={2002},
  publisher={Elsevier}
}

@inbook{palatucci2009zero,
  title={Zero-shot learning with semantic output codes},
  author={Palatucci, Mark and Pomerleau, Dean and Hinton, Geoffrey E and Mitchell, Tom M},
  booktitle={Advances in neural information processing systems},
  pages={1410--1418},
  year={2009}
}

@article{smith2004overview,
  title={Overview of {fMRI} analysis},
  author={Smith, Stephen M},
  journal={British journal of radiology},
  volume={77},
  number={suppl 2},
  pages={S167--S175},
  year={2004},
  publisher={Br Inst Radiology}
}

@article{naselaris2011encoding,
  title={Encoding and decoding in fMRI},
  author={Naselaris, Thomas and Kay, Kendrick N and Nishimoto, Shinji and Gallant, Jack L},
  journal={NeuroImage},
  volume={56},
  pages={400--410},
  year={2011},
  publisher={Elsevier}
}


@misc{friedmanglmnet,
  title={Glmnet for Matlab},
  year = 2010,
  author={Friedman, J and Hastie, T and Tibshirani, R and Jiang, H}
}

@article{sadinle2,
	author = {Sadinle, Mauricio},
	title = {A {B}ayesian Framework for Duplicate Detection, Record Linkage, and Subsequent Inference with Linked Files},
	year = {2013}
}


@article{larsen,
	author = {Larsen, M. D. and Rubin, D. B.},
	title = {Iterative Automated Record Linkage Using Mixture Models},
	journal = {Journal of the American Statistical Association},
	volume = {96},
	number = {453},
	year = {2001}
}


@article{evt,
	author = {Murat Sariyar and Andreas Borg and Klaus Pommerening},
	title = {Controlling false match rates in record linkage using extreme value theory},
	journal = {Journal of Biomedical Informatics},
	volume = {in press},
	year = {2011}
}


@article{hartigan,
	author = {Hartigan, J.A.},
	title = {Clustering Algorithms},
	journal = {John Wiley \& Sons, New York},
	year = {1975}
}


@article{fellegi,
	author = {Ivan P. Fellegi and Alan B. Sunter},
	title = {A theory for record linkage},
	journal = {Journal of the American Statistical Association},
	volume = {64},
	year = {1969},
	Number = {328},
	Pages = {1183--1210}
}

@article{rand,
	author = {William B. Rand},
	title = {Objective criteria for the evaluation of clustering methods},
	journal = {Journal of the American Statistical Association},
	volume = {66},
	year = {1971},
	Number = {336},
	Pages = {846--850}
}


@misc{winkler-conv,
	author = {Winkler, W.E.},
	title = {Personal communication},
	year = {2013},
}



@misc{christen-conv,
	author = {Christen, Peter},
	title = {Personal communication},
	year = {2011},
}


@article{beka,
	Title = {Parametric {B}ayesian Inference for High Dimensional Multiple Record Linkage},
	Author = {Steorts, Rebecca C. and Hall, Robert and Fienberg, Stephen},
	Year = {2013}
}


@article{iris,
	Title = {The use of multiple measurements in taxonomic problems},
	Author = {Fisher, R. A.},
	Pages = {179–-188},
	Year = {1936},
	Volume = {7},
	Journal = {Annals of Eugenics}
}


@article{minimax,
	Title = {Hierarchical Clustering With Prototypes via Minimax Linkage},
	Author = {Jacob Bien and Robert Tibshirani},
	Pages = {1075--1084},
	Year = {2012},
	Journal = {Annals of Eugenics},
	URL = {http://www-stat.stanford.edu/~jbien/jasa2011minimax.pdf}
}


@article{tantrum,
	Title = {Hierarchical model-based clustering of large datasets through fractionation and refractionation},
	Author = {Jeremy Tantrum and Alejandro Murua and Werner Stuetzle},
	Pages = {315–-326},
	Year = {2004},
	Journal = {Information Systems},
	Volume = {29},
	URL = {http://www.dms.umontreal.ca/~murua/research/hierarchicalMBC.pdf}
}



@article{cutting,
	Title = {Scatter/gather: a cluster-based approach to browsing large document collections},
	Author = {D. Cutting and D. Karger and J. Pedersen and J. Tukey},
	Year = {1992},
	Journal = {Proceedings of  15th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
	Pages = {318--329}
}



@article{blb,
	Title = {{A Scalable Bootstrap for Massive Data}},
	Author = {Ariel Kleiner and Ameet Talwalkar and Purnamrita Sarkar and Michael I. Jordan},
	Year = {2012},
	URL = {http://arxiv.org/abs/1112.5016},
}

@article{strings,
	Title = {{Approximate string matching}},
	Author = {Wikipedia},
	Year = {2013},
	URL = {http://en.wikipedia.org/wiki/Approximate_string_matching},
}

@article{nltcs,
	Title = {{The National Long-Term Care Survey}},
	Author = {Kenneth G. Manton},
	Institution = {Duke University},
	Year = {2013},
	URL = {http://www.nltcs.aas.duke.edu/data.htm},
}


@article{jw,
	Title = {{String Comparator Metrics and Enhanced Decision Rules in the Fellegi-Sunter Model of Record Linkage}},
	Author = {Winkler, W.E.},
	Pages = {354--359},
	Year = {1990},
	Journal = {Proceedings of the Section on Survey Research Methods (American Statistical Association)},
}



@article{treeratpituk,
	Title = {{Disambiguating Authors in Academic Publications using Random Forests}},
	Author = {P. Treeratpituk and C.L. Giles},
	Journal = {Joint Conference on Digital Libaries},
	Year = {2009}
}


@article{torvik,
	Title = {Author Name Disambiguation in MEDLINE},
	Author = {V. Torvik and N. Smalheiser},
	Journal = {ACM Transactions on Knowledge Discovery from Data},
	Year = {2009},
	Volume = {3}, 
	Number = {3},
	Article = {11}
}



@article{uspto,
	Title = {USPTO Assignee Harmonization},
	Author = {USPTO},
	Year = {2006},
	URL = {http://www.uspto.gov/web/offices/ac/ido/oeip/taf/data/misc/data_cd.doc/assignee_harmonization/_read_me_assignees_69_10Nov05.txt}
}



@article{carayol,
	Title = {Who's Who in Patents: A {B}ayesian approach},
	Author = {N. Carayol and L. Cassi},
	Year = {2009}
}






@unpublished{wunmi,
	Title = {{Economic Downturns, Technology Trajectories, and the Careers of Scientists}},
	Author = {E. Akinsanmi and R. Reagans and E. Fuchs},
	Year = {2012},
	Journal = {Carnegie Mellon University working paper},
}



@unpublished{sam-epp,
	Title = {{Methods Matter:  Rethinking Inventor Disambiguation Algorithms with Classification Models and Labeled Inventor Records}},
	Author = {S. L. Ventura and R. Nugent and E.R.H. Fuchs},
	Year = {2013},
	Journal = {Currently Under Review},
}


@book{hastie,
	Title = {{The Elements of Statistical Learning:  Data Mining, Inference, and Prediction, Second Edition}},
	Author = {Hastie, T. and Tibshirani, R. and Friedman, J.},
	Year = {2009},
	Publisher = {Springer-Verlag},
}


@article{breiman,
	Title = {{Random Forests}},
	Author = {Breiman, L.},
	Volume = {45},
	Number = {1},
	Pages = {5-32},
	Year = {2001},
	Journal = {Machine Learning},
}







@article{martins,
	Title = {A Supervised Machine Learning Approach for Duplicate Detection for {G}azetteer Records},
	Author = {B. Martins},
	Year = {2011}, 
	Journal = {Lecture Notes in Computer Science},
	Volume = {6631},
	Pages = {34--51}
}


@article{cox1972rmald,
	Title = {{Regression Models and Life-Tables (with discussion)}},
	Author = {Cox, D.R},
	Volume = {34},
	Pages = {187-220},
	Year = {1972},
	Journal = {Journal of the Royal Statistical Society, Series B},
}

@article{hirotsu2002umpmafmdotsatd,
	Title = {{Using a Markov Process Model of an Association Football Match to Determine the Optimal Timing of Substitution and Tactical Decisions}},
	Author = {Hirotsu, Nobuyoshi and Wright, Michael},
	Volume = {53},
	Number = {1},
	Year = {2002},
	Journal = {Journal of the Operational Research Society},
}


@article{rosenbaum2004mhnphttw,
	Title = {{Measuring How NBA Players Help Their Teams Win}},
	Author = {Dan T. Rosenbaum},
	Year = {2004},
	URL = {http://www.82games.com/comm30.htm},
}


@inbook{lock2009b+rscnp,
	Title = {{Beyond +/-: A Rating System to Compare NHL Players}},
	Author = {Dennis Lock and MIchael Schuckers},
	Year = {2009},
	Journal = {Joint Statistical Meetings},
	Note = {Presentation at Joint Statistical Meetings},
}



@article{tibshirani1996rsasvl,
	Title = {{Regression Shrinkage and Selection via the Lasso}},
	Author = {Tibshirani, Robert},
	Volume = {58},
	Number = {1},
	Pages = {267–288},
	Year = {1996},
	Journal = {Journal of the Royal Statistical Society, Series B (Methodology)},
}

@article{tibshirani1997lmfvscm,
	Title = {{The Lasso Method for Variable Selection in the Cox Model}},
	Author = {Robert Tibshirani},
	Volume = {16},
	Pages = {385-395},
	Year = {1997},
	Journal = {Statistics in Medicine},
	Local-URL = {%UD%/T/Tibshirani (1997) The Lasso Method for Variable Selection in the Cox Model.pdf},
}


@article{zou2005regularization,
	Title = {{Regularization and variable selection via the elastic net}},
	Author = {Zou, H. and Hastie, T.},
	Volume = {67},
	Number = {2},
	Pages = {301--320},
	Year = {2005},
	Journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
	Local-URL = {%UD%/Z/Zou (2005) Regularization and variable selection via the elastic net.pdf},
}




@article{wikipedia2012p,
	Title = {{Plus-Minus}},
	Author = {Wikipedia},
	Year = {2012},
	URL = {http://en.wikipedia.org/wiki/Plus-minus},
}





@article{macdonald2011rapsfnp,
	Title = {{A Regression-based Adjusted Plus-Minus Statistic for NHL Players}},
	Author = {Brian Macdonald},
	Volume = {7},
	Number = {3},
	Year = {2011},
	Journal = {Journal of Quantitative Analysis in Sports},
}


@inbook{macdonald2012egmfentap,
	Title = {{An Expected Goals Model for Evaluating NHL Teams and Players}},
	Author = {Brian Macdonald},
	Year = {2012},
	Local-URL = {%UD%/M/Macdonald (2012) An Expected Goals Model for Evaluating NHL Teams and Players.pdf},
booktitle = {MIT Sloan Sports Analytics Conference 2012},}



@article{macdonald2012apfnpurr,
	Title = {{Adjusted Plus-Minus for NHL Players using Ridge Regression}},
	Author = {Brian Macdonald},
	Year = {2012},
	URL = {http://arxiv.org/abs/1201.0317v1},
	Local-URL = {%UD%/M/Macdonald (2012) Adjusted Plus-Minus for NHL Players using Ridge Regression.pdf},
}





@unpublished{schuckers2011nhlsrbuaoeampaa,
	Title = {{National Hockey League Skater Ratings Based upon All On-Ice Events: An Adjusted Minus/Plus Probability (AMPP) Approach}},
	Author = {Michael E. Schuckers and Dennis F. Lock and Chris Wells and C. J. Knickerbocker and Robin H. Lock},
	Year = {2011},
	Local-URL = {%UD%/S/Schuckers (2011) National Hockey League Skater Ratings Based upon All On-Ice Events An Adjusted Minus-Plus Probability (AMPP) Approach.pdf},
}



@article{sill2010ina+uraot,
	Title = {{Improved NBA Adjusted +/- Using Regularization and Out-of-Sample Testing}},
	Author = {Joseph Sill},
	Year = {2010},
	Journal = {MIT Sloan Sports Analytics Conference},
	Local-URL = {%UD%/S/Sill (2010) Improved NBA Adjusted +-- Using Regularization and Out-of-Sample Testing.pdf},
}




@article{thomas2006ippalihs,
	Title = {{The Impact of Puck Possession and Location on Ice Hockey Strategy}},
	Author = {A.C. Thomas},
	Volume = {2},
	Number = {1},
	Year = {2006},
	Comment = {Paper number 1!},
	Journal = {Journal for Quantitative Analysis in Sports},
	Tag = {sports, },
	Local-URL = {%UD%/T/Thomas - 2006 - The Impact of Puck Possession and Location on Ice Hockey Strategy.pdf},
}

@article{thomas2007itgih,
	Title = {{Inter-Arrival Times of Goals in Ice Hockey}},
	Author = {A.C. Thomas},
	Volume = {3},
	Number = {3},
	Year = {2007},
	Journal = {Journal of Quantitative Analysis in Sports},
	Tag = {sports, },
	Local-URL = {%UD%/T/Thomas - 2007 - Inter-Arrival Times of Goals in Ice Hockey.pdf},
}



@article{hoerl1970rrbefnp,
	Title = {{Ridge regression: Biased estimation for nonorthogonal problems}},
	Author = {Hoerl, A. E. and R. W. Kennard},
	Volume = {12},
	Pages = {55–67},
	Year = {1970},
	Journal = {Technometrics},
}



@article{brown2008ipbaftebabm,
	Title = {{In-season Prediction of Batting Averages -- A Field Test of Empirical Bayes and Bayes Methodologies}},
	Author = {Lawrence D. Brown},
	Volume = {2},
	Number = {1},
	Pages = {113–152},
	Year = {2008},
	Journal = {The Annals of Applied Statistics},
	Local-URL = {%UD%/B/Brown - 2008 - In-season Prediction of Batting Averages -- A Field Test of Empirical Bayes and Bayes Methodologies.pdf},
}


@article{james1961eql,
	Title = {{Estimation with quadratic loss}},
	Author = {James, W. and Stein, C},
	Volume = {1},
	Pages = {367--379},
	Year = {1961},
	Journal = {Proc. 4th Berkeley Symp. Probab. Statist},
}



@article{beaudoin2010sfpgh,
	Title = {{Strategies for Pulling the Goalie in Hockey}},
	Author = {David Beaudoin and Tim B. Swartz},
	Volume = {64},
	Number = {3},
	Year = {2010},
	Journal = {The American Statistician},
	Local-URL = {%UD%/B/Beaudoin - 2010 - Strategies for Pulling the Goalie in Hockey.pdf},
}


@incollection{morrison1976otpgpmacsuih,
	Title = {{On the Optimal Time to Pull the Goalie: A Poisson Model Applied to a Common Strategy Used in Ice Hockey}},
	Author = {Morrison, D.G.},
	Volume = {4},
	Year = {1976},
	Booktitle = {TIMS Studies in Management Science},
}


@article{ilardi2008aprnaif2,
	Title = {{Adjusted Plus-Minus Ratings: New and Improved for 2007-2008}},
	Author = {Ilardi, S. and A. Barzilai},
	Year = {2008},
	URL = {http://www.82games.com/ilardi2.htm},
}


@article{cook2006vsb,
	Title = {Validation of Software for {B}ayesian Models Using Posterior Quantiles},
	Author = {Samantha R. Cook and Andrew Gelman and Donald B. Rubin},
	Volume = {15},
	Number = {3},
	Pages = {675--692},
	Year = {2006},
	Journal = {Journal of Computational and Graphical Statistics},
	Local-URL = {%UD%/C/Cook - 2006 - Validation of Software for Bayesian Models Using Posterior Quantiles.pdf},
}


@article{gramacy2013epchrlr,
	Title = {{Estimating Player Contribution in Hockey with Regularized Logistic Regression}},
	Author = {Robert B. Gramacy and Shane T. Jensen and Matt Taddy},
	Year = {2013},
	URL = {http://arxiv.org/abs/1209.5026},
	Local-URL = {%UD%/G/Gramacy (2013) Estimating Player Contribution in Hockey with Regularized Logistic Regression.pdf},
}

@article{berry1999bdes,
	Title = {{Bridging Different Eras in Sports}},
	Author = {Scott M. Berry and C. Shane Reese and Patrick D. Larkey},
	Volume = {94},
	Number = {447},
	Pages = {661-676},
	Year = {1999},
	Journal = {Journal of the American Statistical Association},
	Local-URL = {%UD%/B/Berry - 1999 - Bridging Different Eras in Sports.pdf},
}



@article{dawid1994spbi,
	Title = {Selection Paradoxes of {B}ayesian Inference},
	Author = {A. P. Dawid},
	Pages = {211-220},
	Year = {1994},
	Journal = {Lecture Notes-Monograph Series, Vol. 24, Multivariate Analysis and Its Applications},
	Local-URL = {%UD%/D/Dawid (1994) Selection Paradoxes of Bayesian Inference.pdf},
}

@book{klein-reif,
  Title = {{The Hockey Compendium: NHL Facts, Stats and Stories}},
  Author = {Jeff Z. Klein and Karl-Eric Reif},
  Year = {2001},
}


@article{hans2011enrmonp,
	Title = {{Elastic Net Regression Modeling With the Orthant Normal Prior}},
	Author = {Chris Hans},
	Volume = {106},
	Number = {496},
	Pages = {1383-1393},
	Year = {2011},
	Journal = {Journal of the American Statistical Association},
	Local-URL = {%UD%/H/Hans (2011) Elastic Net Regression Modeling With the Orthant Normal Prior.pdf},
}


@article{li2010ben,
	Title = {The {B}ayesian Elastic Net},
	Author = {Qing Li and Nan Lin},
	Volume = {5},
	Number = {1},
	Pages = {151–170},
	Year = {2010},
	Journal = {Bayesian Analysis},
	Local-URL = {%UD%/L/Li (2010) The Bayesian Elastic Net.pdf},
}


@article{park2008bl,
	Title = {The {B}ayesian Lasso},
	Author = {Trevor Park and George Casella},
	Volume = {103},
	Number = {482},
	Year = {2008},
	Journal = {Journal of the American Statistical Association},
	Local-URL = {%UD%/P/Park (2008) The Bayesian Lasso.pdf},
}


@ARTICLE{Minnotte93themode,
    author = {Michael C. Minnotte and David W. Scott},
    title = {The Mode Tree: A Tool for Visualization of Nonparametric Density Features},
    journal = {Journal of Computational and Graphical Statistics},
    year = {1993},
    volume = {2},
    pages = {51--68}
}


@article{hartigan1981,
     jstor_articletype = {research-article},
     title = {Consistency of Single Linkage for High-Density Clusters},
     author = {Hartigan, J. A.},
     journal = {Journal of the American Statistical Association},
     jstor_issuetitle = {},
     volume = {76},
     number = {374},
     jstor_formatteddate = {Jun., 1981},
     pages = {pp. 388-394},
     url = {http://www.jstor.org/stable/2287840},
     ISSN = {01621459},
     language = {English},
     year = {1981},
}


@article{Dunn1946,
  author = {Dunn, Halbert L},
  year = {1946},
  title = {Record Linkage},
  journal={American Journal of Public Health and the Nation's Health},
  volume = {36},
  number = {12},
  pages = {1412--1416}
}

@article{Tepping1968,
    author = {Tepping, Benjamin J.},
    journal = {Journal of the American Statistical Association},
    mendeley-groups = {Entity Resolution/Classical sources},
    number = {324},
    pages = {1321--1332},
    title = {A Model for Optimum Linkage of Records},
    volume = {63},
    year = {1968}
}

@article{Newcombe1962,
    author = {Newcombe, H. B. and Kennedy, James M},
    journal = {Communications of the ACM},
    number = {11},
    pages = {563--566},
    title = {Record Linkage: Making Maximum Use of the Discriminating Power of Identifying Information},
    volume = {5},
    year = {1962}
}

@article{Newcombe1969,
    author = {Newcombe, Howard B.},
    journal = {Population (French Edition)},
    number = {4},
    pages = {653},
    title = {Couplage de donn{\'{e}}es pour les {\'{e}}tudes d{\'{e}}mographiques},
    volume = {24},
    year = {1969}
}

@article{Newcombe1962b,
    author = {Newcombe, Howard B and Rhynas, Philip O W},
    journal = {Eugenics Quarterly},
    number = {1},
    pages = {25--35},
    publisher = {Routledge},
    title = {Child Spacing Following Stillbirth and Infant Death},
    volume = {9},
    year = {1962}
}

@article{Newcombe1965,
    author = {Newcombe, Howard B},
    journal = {The Eugenics Review},
    number = {3},
    pages = {109--125},
    title = {The Study of Mutation and Selection in Human Populations},
    volume = {57},
    year = {1965}
}

@article{Newcombe1963,
    author = {Newcombe, Howard B.},
    journal = {Annals of Human Genetics},
    number = {4},
    pages = {367--382},
    title = {Screening for effects of maternal age and birth order in a register of handicapped children},
    volume = {27},
    year = {1963}
}

@article{Newcombe1965b,
    author = {Newcombe, Howard B. and Tavendale, Olwyn G.},
    journal = {Obstetrical and Gynecological Survey},
    number = {4},
    pages = {655--656},
    title = {Effects of Father's Age on the Risk of Child Handicap or Death},
    volume = {20},
    year = {1965}
}

@article{Jaro1989,
    author = {Jaro, Matthew A.},
    journal = {Journal of the American Statistical Association},
    number = {406},
    pages = {414--420},
    title = {Advances in Record-Linkage Methodology as Applied to Matching the 1985 Census of {T}ampa, {F}lorida},
    volume = {84},
    year = {1989}
}

@article{Winkler1988,
    author = {Winkler, William E.},
    journal = {Proceedings of the Section on Survey Research Methods},
    publisher={American Statistical Association},
    pages = {667--671},
    title = {Using the EM Algorithm for Weight Computation in the {F}ellegi-{S}unter Model of Record Linkage},
    year = {1988}
}

@incollection{Winkler1985,
    address = {Arlington, Virginia},
    author = {Winkler, William E.},
    booktitle = {Record Linkage Techniques},
    editor = {Kilss, Beth and Alvey, Wendy},
    pages = {438--443},
    publisher = {U.S. Internal Revenue Services, Publication 1299},
    title = {Exact Matching Lists of Businesses: Blocking, Subfield Identification, Information Theory},
    year = {1985}
}

@techreport{Kelley1984,
    author = {Kelley, Robert Patrick},
    booktitle = {Statistical research division report series},
    publisher = {Bureau of the Census},
    title = {Blocking considerations for record linkage under conditions of uncertainty},
    year = {1984}
}

@article{Thibaudeau1993,
    author = {Thibaudeau, Yves},
    journal = {Survey Methodology},
    number = {1},
    title = {The Discrimination Power of Dependency Structures in Record Linkage},
    volume = {19},
    year = {1993}
}

@article{Winkler1993,
    author = {Winkler, William E.},
    journal = {Proceedings of the Section on Survey Research Methods},
    publisher={American Statistical Association},
    pages = {274--279},
    title = {Improved Decision Rules In The {F}ellegi-{S}unter Model Of Record Linkage},
    year = {1993}
}

@article{DuBois1969,
    author = {{Du Bois}, N. S.D.Andrea},
    journal = {Journal of the American Statistical Association},
    number = {325},
    pages = {163--174},
    title = {A Solution to the Problem of Linking Multivariate Documents},
    volume = {64},
    year = {1969}
}


@article{Verykios2003,
    author = {Verykios, Vassilios S. and Moustakides, George V. and Elfeky, Mohamed G.},
    journal = {VLDB Journal},
    number = {1},
    pages = {28--40},
    title = {A {B}ayesian Decision Model for Cost Optimal Record Matching},
    volume = {12},
    year = {2003}
}


@article{Armstrong1992,
    author = {Armstrong, J.B. and Mayda, J.E.},
    journal = {Proceedings of the Section on Survey Research Methodology},
    pages = {853 -- 858},
    publisher = {American Statistical Association},
    title = {Estimation of Record Linkage Models Using Dependent Data},
    year = {1992}
}

@incollection{belin1990proposed,
    address = {Washington, DC},
    author = {Belin, Thomas R.},
    booktitle = {Statistics of Income and Related Administrative Record Research},
    pages = {167--172},
    publisher = {International Revenue Service},
    title = {A Proposed Improvement in Computer Matching Techniques},
    year = {1990}
}


@article{Winkler1992,
    author = {Winkler, William E.},
    journal = {Proceedings of the Section on Survey Research Methods},
    publisher={American Statistical Association},
    pages = {829--834},
    title = {Comparative Analysis of Record Linkage Decision Rules},
    year = {1992}
}

@article{Daggy2014,
    author = {Daggy, Joanne and Xu, Huiping and Hui, Siu and Grannis, Shaun},
    title = {Evaluating Latent Class Models With Conditional Dependence in Record Linkage},
    journal = {Statistics in Medicine},
    volume = {33},
    number = {24},
    pages = {4250-4265},
    keywords = {latent class, record linkage, loglinear model, random effects},
    doi = {10.1002/sim.6230},
    year = {2014}
}


@article{Xu2019,
    author = {Xu, Huiping and Li, Xiaochun and Shen, Changyu and Hui, Siu L. and Grannis, Shaun},
    journal = {Annals of Applied Statistics},
    number = {3},
    pages = {1753--1790},
    title = {Incorporating Conditional Dependence in Latent Class Models for Probabilistic Record Linkage: Does it Matter?},
    volume = {13},
    year = {2019}
}


@article{Sadinle2013,
    author = {Sadinle, Mauricio and Fienberg, Stephen E.},
    journal = {Journal of the American Statistical Association},
    number = {502},
    pages = {385--397},
    title = {A Generalized {F}ellegi-{S}unter Framework for Multiple Record Linkage With Application to Homicide Record Systems},
    volume = {108},
    year = {2013}
}

@article{Nigam2000,
    author = {Nigam, Kamal and McCallum, Andrew Kachites and Thrun, Sebastian and Mitchell, Tom},
    journal = {Machine Learning},
    title = {Text Classification From Labeled and Unlabeled Documents Using {EM}},
    year = {2000}
}

@article{Criminisi2011,
    author = {Criminisi, Antonio and Shotton, Jamie and Konukoglu, Ender},
    journal = {Foundations and Trends in Computer Graphics and Vision},
    number = {2-3},
    pages = {81--227},
    title = {Decision forests: A unified framework for classification, regression, density estimation, manifold learning and semi-supervised learning},
    volume = {7},
    year = {2011}
}

@article{Szummer2002,
    author = {Szummer, Martin and Jaakkola, Tommi},
    journal = {Advances in Neural Information Processing Systems},
    title = {Partially labeled classification with markov random walks},
    year = {2002}
}

@book{Chapelle2006,
    address = {Cambridge, Massachusetts},
    author = {Chapelle, Olivier and Bernhard, Sc{\"{o}}lkopf and Zien, Alexander},
    booktitle = {Adaptive Computation and Machine Learning Thomas},
    editor = {Dietterich, Thomas},
    pages = {508},
    publisher = {The MIT Press},
    title = {Semi-Supervised Learning},
    year = {2006}
}


@misc{Goldberg2009,
    author = {Goldberg, Xiaojin},
    booktitle = {Synthesis Lectures on Artificial Intelligence and Machine Learning},
    isbn = {9781598295481},
    issn = {19394608},
    pages = {1--116},
    title = {Introduction to semi-supervised learning},
    volume = {6},
    year = {2009}
}

@article{fleming2007small,
  title={Small worlds and regional innovation},
  author={Fleming, Lee and King III, Charles and Juda, Adam I},
  journal={Organization Science},
  volume={18},
  number={6},
  pages={938--954},
  year={2007},
  publisher={Informs}
}


@article{tang2010bibliometric,
  title={Bibliometric fingerprints: name disambiguation based on approximate structure equivalence of cognitive maps},
  author={Tang, Li and Walsh, John},
  journal={Scientometrics},
  volume={84},
  number={3},
  pages={763--784},
  year={2010},
  publisher={Akad{\'e}miai Kiad{\'o}, co-published with Springer Science+ Business Media BV~…}
}


@article{enamorado2019active,
    author = {Enamorado, Ted},
    title = {Active Learning for Probabilistic Record Linkage},
    year = {2019},
    note={Available at SSRN: \url{https://ssrn.com/abstract=3257638}}
}

@article{Bellare2012,
    author = {Bellare, Kedar and Iyengar, Suresh and Parameswaran, Aditya G. and Rastogi, Vibhor},
    title = {Active Sampling for Entity Matching},
    year = {2012},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    journal = {Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
    pages = {1131–1139},
    numpages = {9},
    location = {Beijing, China}
}

@article{balcan2009agnostic,
  title={Agnostic active learning},
  author={Balcan, Maria-Florina and Beygelzimer, Alina and Langford, John},
  journal={Journal of Computer and System Sciences},
  volume={75},
  number={1},
  pages={78--89},
  year={2009},
  publisher={Elsevier}
}

@article{bellare2013active,
  title={Active sampling for entity matching with guarantees},
  author={Bellare, Kedar and Iyengar, Suresh and Parameswaran, Aditya and Rastogi, Vibhor},
  journal={ACM Transactions on Knowledge Discovery from Data (TKDD)},
  volume={7},
  number={3},
  pages={1--24},
  year={2013},
  publisher={ACM New York, NY, USA}
}

@article{Smith1975,
    author = {Smith, M. E. and Newcombe, H. B.},
    journal = {Methods of Information in Medicine},
    number = {3},
    pages = {118--125},
    pmid = {1196137},
    title = {Methods for Computer Linkage of Hospital Admission Separation Records Into Cumulative Health Histories},
    volume = {14},
    year = {1975}
}


@article{Hernandez1998,
    author = {Hern{\'{a}}ndez, Mauricio A. and Stolfo, Salvatore J.},
    doi = {10.1023/A:1009761603038},
    issn = {13845810},
    journal = {Data Mining and Knowledge Discovery},
    number = {1},
    pages = {9--37},
    title = {Real-World Data is Dirty: Data Cleansing and the Merge/Purge Problem},
    volume = {2},
    year = {1998}
}

@article{Gruenheid2014,
    author = {Gruenheid, Anja and Dong, Xin Luna and Srivastava, Divesh},
    doi = {10.14778/2732939.2732943},
    isbn = {4159862349},
    issn = {21508097},
    journal = {Proceedings of the VLDB Endowment},
    number = {9},
    pages = {697--708},
    title = {Incremental record linkage},
    volume = {7},
    year = {2014}
}


@article{Li2014,
    author = {Li, Guan Cheng and Lai, Ronald and D'Amour, Alexander and Doolin, David M. and Sun, Ye and Torvik, Vetle I. and Yu, Amy Z. and Lee, Fleming},
    doi = {10.1016/j.respol.2014.01.012},
    issn = {00487333},
    journal = {Research Policy},
    number = {6},
    pages = {941--955},
    publisher = {Elsevier B.V.},
    title = {Disambiguation and Co-Authorship Networks of the {U.S.} Patent Inventor Database (1975-2010)},
    volume = {43},
    year = {2014}
}




@article{Kejriwal2015,
    author = {Kejriwal, Mayank and Miranker, Daniel P.},
    doi = {10.1007/978-3-319-18818-8_24},
    isbn = {9783319188171},
    issn = {16113349},
    journal = {European semantic web conference},
    pages = {388--402},
    title = {Semi-supervised Instance Matching Using Boosted Classifiers},
    year = {2015}
}

@article{Wang2015,
    address = {Cham},
    author = {Wang, Qing and Vatsalan, Dinusha and Christen, Peter},
    journal = {Advances in Knowledge Discovery and Data Mining},
    editor = {Cao, Tru and Lim, Ee-Peng and Zhou, Zhi-Hua and Ho, Tu-Bao and Cheung, David and Motoda, Hiroshi},
    isbn = {978-3-319-18032-8},
    pages = {562--573},
    publisher = {Springer International Publishing},
    title = {Efficient Interactive Training Selection for Large-Scale Entity Resolution},
    year = {2015}
}

@article{Christen2016,
  author={P. {Christen} and D. {Vatsalan} and Q. {Wang}},
  journal={IEEE International Conference on Data Mining}, 
  title={Efficient Entity Resolution with Adaptive and Interactive Training Data Selection}, 
  year={2015},
  volume={},
  number={},
  pages={727-732},}



@article{Vesdapunt2014,
    author = {Vesdapunt, Norases and Bellare, Kedar and Dalvi, Nilesh},
    title = {Crowdsourcing Algorithms for Entity Resolution},
    year = {2014},
    issue_date = {August 2014},
    publisher = {VLDB Endowment},
    volume = {7},
    number = {12},
    issn = {2150-8097},
    doi = {10.14778/2732977.2732982},
    journal = {Proceedings of the VLDB Endowment},
    pages = {1071–1082},
    numpages = {12}
}

@article{Wang2012,
    author = {Wang, Jiannan and Kraska, Tim and Franklin, Michael J. and Feng, Jianhua},
    eprint = {1208.1927},
    issn = {21508097},
    journal = {Proceedings of the VLDB Endowment},
    number = {11},
    pages = {1483--1494},
    title = {CrowdER: Crowdsourcing Entity Resolution},
    volume = {5},
    year = {2012}
}

@article{Sarawagi2002,
    author = {Sarawagi, Sunita and Bhamidipaty, Anuradha},
    doi = {10.1145/775085.775087},
    file = {:home/olivier/Downloads/SarawagiKDD2002.pdf:pdf},
    isbn = {158113567X},
    journal = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
    mendeley-groups = {Entity Resolution/Active Learning,Entity Resolution/Crowdsourcing},
    pages = {269--278},
    title = {Interactive Deduplication Using Active Learning},
    year = {2002}
}

  
@techreport{Trajtenberg2008,
  title={Identification and mobility of {I}sraeli patenting inventors},
  author={Trajtenberg, Manuel and Shiff, Gil},
  year={2008},
  institution={Pinhas Sapir Center for Development}
}

@article{Kopcke2010,
    author = {K{\"{o}}pcke, Hanna and Rahm, Erhard},
    doi = {10.1016/j.datak.2009.10.003},
    issn = {0169023X},
    journal = {Data and Knowledge Engineering},
    keywords = {Entity matching,Entity resolution,Match optimization,Matcher combination,Training selection},
    mendeley-groups = {Entity Resolution/Software},
    number = {2},
    pages = {197--210},
    publisher = {Elsevier B.V.},
    title = {Frameworks for Entity Matching: A Comparison},
    volume = {69},
    year = {2010}
}


@article{Kooli2018,
    author="Kooli, Nihel
    and Allesiardo, Robin
    and Pigneul, Erwan",
    editor="Nguyen, Ngoc Thanh
    and Hoang, Duong Hung
    and Hong, Tzung-Pei
    and Pham, Hoang
    and Trawi{\'{n}}ski, Bogdan",
    title="Deep Learning Based Approach for Entity Resolution in Databases",
    journal="Intelligent Information and Database Systems",
    year="2018",
    publisher="Springer International Publishing",
    address="Cham",
    pages="3--12",
    isbn="978-3-319-75420-8"
}

@article{Kasai2020,
    author = {Kasai, Jungo and Qian, Kun and Gurajada, Sairam and Li, Yunyao and Popa, Lucian},
    doi = {10.18653/v1/p19-1586},
    eprint = {1906.08042},
    isbn = {9781950737482},
    journal = {57th Annual Meeting of the Association for Computational Linguistics},
    pages = {5851--5861},
    title = {Low-Resource Deep Entity Resolution with Transfer and Active Learning},
    year = {2020}
}

@article{Ebraheem2017,
    author = {Ebraheem, Muhammad and Thirumuruganathan, Saravanan and Joty, Shafiq and Ouzzani, Mourad and Tang, Nan},
    title={{DeepER} -- {Deep} Entity Resolution},
    journal={arXiv e-prints},
    note = {{arxiv:1710.00597}},
    year = {2017}
}


@article{Gottapu2016,
    author = {Gottapu, Ram Deepak and Dagli, Cihan and Ali, Bharami},
    doi = {10.1016/j.procs.2016.09.306},
    journal = {Procedia Computer Science},
    keywords = {convolutional neural network,crowdsourcing,hybrid machine-human model,word embedding,word stemming},
    pages = {153--158},
    publisher = {Elsevier Masson SAS},
    title = {Entity Resolution Using Convolutional Neural Network},
    volume = {95},
    year = {2016}
}

@article{Cochinwala2001,
    author = {Cochinwala, Munir and Kurien, Verghese and Lalk, Gail and Shasha, Dennis},
    doi = {10.1016/S0020-0255(00)00070-0},
    issn = {00200255},
    journal = {Information Sciences},
    mendeley-groups = {Entity Resolution/ML methods,Entity Resolution/Supervised},
    number = {1-4},
    pages = {1--15},
    title = {Efficient data reconciliation},
    volume = {137},
    year = {2001}
}

@article{Verykios2000,
    author = {Verykios, Vassilios S. and Elmagarmid, Ahmed K. and Houstis, Elias N.},
    doi = {10.1016/S0020-0255(00)00013-X},
    issn = {00200255},
    journal = {Information sciences},
    number = {1},
    pages = {83--98},
    title = {Automating the approximate record-matching process},
    volume = {126},
    year = {2000}
}

@article{Elfeky2002,
    author = {Elfeky, Mohamed G. and Verykios, Vassilios S. and Elmagarmid, Ahmed K.},
    doi = {10.1109/icde.2002.994694},
    file = {:Users/olivierbinette/Documents/Mendeley/Elfeky, Verykios, Elmagarmid - 2002 - TAILOR A record linkage toolbox.pdf:pdf},
    journal = {Proceedings - International Conference on Data Engineering},
    mendeley-groups = {Entity Resolution/Supervised},
    pages = {17--28},
    title = {TAILOR: A record linkage toolbox},
    year = {2002}
}

@article{Christen2007,
    author = {Christen, Peter},
    title = {A Two-Step Classification Approach to Unsupervised Record Linkage},
    year = {2007},
    publisher = {Australian Computer Society, Inc.},
    journal = {Proceedings of the Sixth Australasian Conference on Data Mining and Analytics},
    pages = {111–119},
    numpages = {9},
    location = {Gold Coast, Australia}
}


@article{Torvik2005,
    author = {Torvik, Vetle I. and Weeber, Marc and Swanson, Don R. and Smalheiser, Neil R.},
    doi = {10.1002/asi.20105},
    issn = {15322882},
    journal = {Journal of the American Society for Information Science and Technology},
    number = {2},
    pages = {140--158},
    title = {A Probabilistic Similarity Metric for MEDLINE Records: A Model for Author Name Disambiguation},
    volume = {56},
    year = {2005}
}

@article{Christen2008,
    author = {Christen, Peter},
    title = {Automatic Record Linkage Using Seeded Nearest Neighbour and Support Vector Machine Classification},
    year = {2008},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    journal = {Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
    pages = {151–159},
    numpages = {9},
    location = {Las Vegas, Nevada, USA},
}
  

@article{Azoulay2007,
    author = {Azoulay, Pierre and Michigan, Ryan and Sampat, Bhaven N.},
    title = {The Anatomy of Medical School Patenting},
    journal = {New England Journal of Medicine},
    volume = {357},
    number = {20},
    pages = {2049-2056},
    year = {2007},
}


@incollection{Azoulay2011,
  title={The Diffusion of Scientific Knowledge Across Time and Space: Evidence from Professional Transitions for the Superstars of Medicine},
  author={Azoulay, Pierre and Zivin, Joshua S Graff and Sampat, Bhaven N},
  year={2012},
  booktitle={The Rate and Direction of Inventive Activity Revisited},
  editor={Lerner, Josh and Stern, Scott},
  publisher={University of Chicago Press}
}

@article{Ventura2014,
    address = {Cham},
    author = {Ventura, Samuel L and Nugent, Rebecca and Erica R.H. Fuchs},
    journal = {Privacy in Statistical Databases},
    editor = {Domingo-Ferrer, J.},
    isbn = {978-3-319-11257-2},
    pages = {283--298},
    publisher = {Springer International Publishing},
    title = {Hierarchical Linkage Clustering with Distributions of Distances for Large-Scale Record Linkage},
    year = {2014}
}

@article{Bhattacharya2006,
    author = {Bhattacharya, Indrajit and Getoor, Lise},
    doi = {10.1137/1.9781611972764.5},
    isbn = {089871611X},
    journal = {Proceedings of the Sixth SIAM International Conference on Data Mining},
    pages = {47--58},
    title = {A Latent Dirichlet Model for Unsupervised Entity Resolution},
    year = {2006}
}

@article{Potosky1993,
    abstract = {The National Cancer Institute and the Health Care Financing Administration share a strong research interest in cancer costs, access to cancer prevention and treatment services, and cancer patient outcomes. To develop a database for such research, the two agencies have undertaken a collaborative effort to link Medicare Program data with the Surveillance, Epidemiology, and End Results (SEER) Program database. The SEER Program is a system of 9 population-based tumor registries that collect standardized clinical information on cases diagnosed in separate, geographically defined areas covering approximately 10{\%} of the US population. Using a deterministic matching algorithm, the records of 94{\%} of SEER registry cases diagnosed at age 65 or older between 1973 to 1989, or more than 610,000 persons, were successfully linked with Medicare claims files. The resulting database, combining clinical characteristics with information on utilization and costs, will permit the investigation of the contribution of various patient and health care setting factors to treatment patterns, costs, and medical outcomes. {\textcopyright} 1993, J. B. Lippincott Company.},
    author = {Potosky, Arnold L. and Riley, Gerald F. and Lubitz, James D. and Mentnech, Renee M. and Kessler, Larry G.},
    doi = {10.1097/00005650-199308000-00006},
    file = {:home/olivier/Downloads/3765984.pdf:pdf},
    issn = {15371948},
    journal = {Medical Care},
    keywords = {Cancer,Costs of cancer,Medicare,Prevention of cancer,Tumor registry},
    mendeley-groups = {Entity Resolution/Deterministic},
    number = {8},
    pages = {732--748},
    pmid = {8336512},
    title = {Potential for Cancer Related Health Services Research Using a Linked Medicare-Tumor Registry Database},
    volume = {31},
    year = {1993}
}

@article{Gomatam2002,
    abstract = {We consider the problem of record linkage in the situation where we have only non-unique identifiers, like names, sex, race etc., as common identifiers in databases to be linked. For such situations much work on probabilistic methods of record linkage can be found in the statistical literature. However, although many groups undoubtedly still use deterministic procedures, not much literature is available on deterministic strategies. Furthermore, there appears to exist almost no documentation on the comparison of results for the two strategies. In this work we compare a stepwise deterministic linkage strategy with a probabilistic strategy, as implemented in AUTOMATCH, for a situation in which the truth is known. The comparison was carried out on a linkage between medical records from the Regional Perinatal Intensive Care Centers database and educational records from the Florida Department of Education. Social security numbers, available in both databases, were used to decide the true status of each record pair after matching. Match rates and error rates for the two strategies are compared and a discussion of their similarities and differences, strengths and weaknesses is presented. Copyright {\textcopyright} 2002 John Wiley {\&} Sons, Ltd.},
    author = {Gomatam, Shanti and Carter, Randy and Ariet, Mario and Mitchell, Glenn},
    doi = {10.1002/sim.1147},
    file = {:home/olivier/Downloads/10.1.1.455.5537.pdf:pdf},
    issn = {02776715},
    journal = {Statistics in Medicine},
    keywords = {AUTOMATCH,Document linkage,Exact matching,Hierarchical linkage strategies,Probabilistic matching,Stepwise deterministic linkage},
    mendeley-groups = {Entity Resolution/Deterministic},
    number = {10},
    pages = {1485--1496},
    title = {An Empirical Comparison of Record Linkage Procedures},
    volume = {21},
    year = {2002}
}

@article{Tromp2011,
    abstract = {Objective: To gain insight into the performance of deterministic record linkage (DRL) vs. probabilistic record linkage (PRL) strategies under different conditions by varying the frequency of registration errors and the amount of discriminating power. Study Design and Setting: A simulation study in which data characteristics were varied to create a range of realistic linkage scenarios. For each scenario, we compared the number of misclassifications (number of false nonlinks and false links) made by the different linking strategies: deterministic full, deterministic N-1, and probabilistic. Results: The full deterministic strategy produced the lowest number of false positive links but at the expense of missing considerable numbers of matches dependent on the error rate of the linking variables. The probabilistic strategy outperformed the deterministic strategy (full or N-1) across all scenarios. A deterministic strategy can match the performance of a probabilistic approach providing that the decision about which disagreements should be tolerated is made correctly. This requires a priori knowledge about the quality of all linking variables, whereas this information is inherently generated by a probabilistic strategy. Conclusion: PRL is more flexible and provides data about the quality of the linkage process that in turn can minimize the degree of linking errors, given the data provided. {\textcopyright} 2011 Elsevier Inc. All rights reserved.},
    author = {Tromp, Miranda and Ravelli, Anita C. and Bonsel, Gouke J. and Hasman, Arie and Reitsma, Johannes B.},
    doi = {10.1016/j.jclinepi.2010.05.008},
    file = {:home/olivier/Downloads/1-s2.0-S0895435610002258-main.pdf:pdf},
    issn = {08954356},
    journal = {Journal of Clinical Epidemiology},
    keywords = {Data quality,Deterministic linkage,Medical record linkage,Probabilistic linkage,Registries,Simulation study},
    mendeley-groups = {Entity Resolution/Deterministic},
    number = {5},
    pages = {565--572},
    publisher = {Elsevier Inc},
    title = {Results From Simulated Data Sets: Probabilistic Record Linkage Outperforms Deterministic Record Linkage},
    volume = {64},
    year = {2011}
}

@article{Campbell2008,
    author = {Campbell, Kevin M. and Deck, Dennis and Krupski, Antoinette},
    journal = {Health Informatics Journal},
    number = {1},
    pages = {5--15},
    title = {Record Linkage Software in the Public Domain: A Comparison of {L}ink Plus, The {L}ink {K}ing, and a 'Basic' Deterministic Algorithm},
    volume = {14},
    year = {2008}
}

@article{Hassanzadeh2009,
    author = {Hassanzadeh, Oktie and Chiang, Fei and Lee, Hyun Chul and Miller, Ren\'{e}e J.},
    title = {Framework for Evaluating Clustering Algorithms in Duplicate Detection},
    year = {2009},
    issue_date = {August 2009},
    publisher = {VLDB Endowment},
    volume = {2},
    number = {1},
    doi = {10.14778/1687627.1687771},
    journal = {Proceedings of the VLDB Endowment},
    pages = {1282–1293},
    numpages = {12}
}
  


@article{Monge1997,
    author = {Monge, Alvaro E. and Elkan, Charles P.},
    doi = {10.1.1.28.8405},
    journal = {Proceedings of the SIGMOD 1997 Workshop on Research Issues on Sata Mining and Knowledge Discovery},
    pages = {23--29},
    title = {An Efficient Domain-Independent Algorithm for Detecting Approximately Duplicate Database Records},
    year = {1997}
}

@article{Rahm2016,
    abstract = {Current data integration approaches are mostly limited to few data sources, partly due to the use of binary match approaches between pairs of sources. We thus advocate for the development of more holistic, clustering-based data integration approaches that scale to many data sources. We outline different use cases and provide an overview of initial approaches for holistic schema/ontology integration and entity clustering. The discussion also considers open data repositories and so-called knowledge graphs.},
    address = {Cham},
    author = {Rahm, Erhard},
    journal = {Advances in Databases and Information Systems},
    editor = {Pokorn{\'{y}}, Jaroslav and Ivanovi{\'{c}}, Mirjana and Thalheim, Bernhard and {\v{S}}aloun, Petr},
    isbn = {978-3-319-44039-2},
    pages = {11--27},
    publisher = {Springer International Publishing},
    title = {The Case for Holistic Data Integration},
    year = {2016}
}


@article{Bansal2004,
    author = {Bansal, Nikhil and Blum, Avrim and Chawla, Shuchi},
    journal = {Machine Learning},
    number = {1-3},
    pages = {89--113},
    title = {Correlation Clustering},
    volume = {56},
    year = {2004}
}

@article{Cohen2002,
    author = {Cohen, William W. and Richman, Jacob},
    title = {Learning to Match and Cluster Large High-Dimensional Data Sets for Data Integration},
    year = {2002},
    isbn = {158113567X},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    journal = {Proceedings of the Eighth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
    pages = {475–480},
    numpages = {6},
    location = {Edmonton, Alberta, Canada},
}
  


@article{Ailon2008,
    author = {Ailon, Nir and Charikar, Moses and Newman, Alantha},
    journal = {Journal of the ACM},
    number = {5},
    pages = {1--27},
    title = {Aggregating Inconsistent Information: Ranking and Clustering},
    volume = {55},
    year = {2008}
}

@article{Gionis2007,
    author = {Gionis, Aristides and Mannila, Heikki and Tsaparas, Panayiotis},
    title = {Clustering Aggregation},
    year = {2007},
    issue_date = {March 2007},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {1},
    number = {1},
    journal = {ACM Transactions on Knowledge Discovevery from Data},
    pages = {4–es},
    numpages = {30},
}
  

@article{Filkov2003,
    author = {Filkov, Vladimir and Skiena, Steven},
    journal = {Proceedings of the International Conference on Tools with Artificial Intelligence},
    doi = {10.1109/tai.2003.1250220},
    issn = {10636730},
    pages = {418--426},
    title = {Integrating Microarray Data by Consensus Clustering},
    year = {2003}
}

@article{Charikar2003,
    title = "Clustering With Qualitative Information",
    journal = "Journal of Computer and System Sciences",
    volume = "71",
    number = "3",
    pages = "360 - 383",
    year = "2005",
    author = "Charikar, Moses and Guruswami, Venkatesan and Wirth, Anthony",
}

@book{Hartigan1975,
    author = {Hartigan, John A},
    mendeley-groups = {Entity Resolution/Clustering},
    title = {{Clustering Algorithms}},
    year = {1975}
}

@article{Johnson1967,
    author = {Johnson, Stephen C.},
    doi = {10.1007/BF02289588},
    issn = {00333123},
    journal = {Psychometrika},
    number = {3},
    pages = {241--254},
    title = {Hierarchical Clustering Schemes},
    volume = {32},
    year = {1967}
}

@book{Naumann2010,
    author = {Naumann, Felix and Herschel, Melanie},
    booktitle = {Synthesis Lectures on Data Management},
    pages = {1--87},
    title = {An Introduction to Duplicate Detection},
    year = {2010},
    publisher={Morgan \& Claypool Publishers}
}

@book{Han2011,
  author    = {Han, Jiawei and Kamber, Micheline and Pei, Jian},
  title     = {Data Mining: Concepts and Techniques},
  publisher = {Morgan Kaufmann Publishers},
  year      = {2011},
  address   = {Waltham, MA}
}


@article{Bien2011,
    author = {Bien, Jacob and Tibshirani, Robert},
    doi = {10.1198/jasa.2011.tm10183},
    issn = {0162-1459},
    journal = {Journal of the American Statistical Association},
    keywords = {Agglomerative,Dendrogram,Unsupervised learning},
    language = {eng},
    number = {495},
    pages = {1075--1084},
    title = {Hierarchical Clustering With Prototypes via Minimax Linkage},
    url = {https://pubmed.ncbi.nlm.nih.gov/26257451 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4527350/},
    volume = {106},
    year = {2011}
}

@MISC{APgeorgia,
   author =       {Ben Nadler},
   title =        {Voting Rights Become a Flashpoint in Georgia Governor’s Race},
   editor =       {Associated Press},
   month =        {October},
   year =         {2018},
   url = {https://apnews.com/fb011f39af3b40518b572c8cce6e906c},
   note =         {Online; posted October 9, 2018; retrieved July 17, 2020},
 }

@misc{ReutersGeorgia,
    author =       {Ax, Joseph},
    title =        {Georgia Lawsuit is Latest Blow in {U.S.} Fight Over Voting Rights},
    editor =       {Reuters},
    month =        {October},
    year =         {2018},
    url = {https://www.reuters.com/article/usa-election-registrations/georgia-lawsuit-is-latest-blow-in-u-s-fight-over-voting-rights-idUSKCN1ML333},
    note = {Online; posted October 12, 2018; retrieved July 17, 2020}
}

 @MISC{NCSL,
   author =       {National Conference on State Legislatures},
   title =        {Voter List Accuracy},
   editor =       {},
   month =        {March},
   year =         {2020},
   url = {https://www.ncsl.org/research/elections-and-campaigns/voter-list-accuracy.aspx},
   note =         {Online; posted March 20, 2020; retrieved July 17, 2020},
 }

@misc{PeoplevKemp,
author={{Georgia Coalition For the Peoples' Agenda, Inc. et al v. Kemp}},
title = {Complaint for Injunctive and Declaratory Relief},
year = {2018},
note={}
}

@misc{TedGeorgia,
    title = {Georgia’s ‘Exact Match’ Law Could Potentially Harm Many Eligible Voters},
    author = {Ted Enamorado},
    url = {https://www.washingtonpost.com/news/monkey-cage/wp/2018/10/20/georgias-exact-match-law-could-disenfranchise-3031802-eligible-voters-my-research-finds/},
    year={2018},
    month={October},
    note={Online; posted October 20, 2018; retrieved July 17, 2020}
}


@article{Matsakis2010,
    author = {Matsakis, Nicholas Elias},
    pages = {137},
    title = {Active Duplicate Detection with {B}ayesian Nonparametric Models},
    year = {2010},
    note = {PhD Thesis}
}

@misc{Gregg2015,
    author={Gregg, Forest and Derek Eder},
    year={2015},
    title={Dedupe},
    note = {Online; retrieved July 29, 2020; \url{https://github.com/dedupeio/dedupe}},
    url={https://github.com/dedupeio/dedupe}
}

@misc{deBruin2016,
    author={de Bruin, Jonathan},
    title = {recordlinkage 0.14},
    year = {2019},
    note = {Online; released December 1, 2019; retrieved July 29, 2020; \url{https://pypi.org/project/recordlinkage/}},
    url={https://pypi.org/project/recordlinkage/}
}

@article{Christen08febrl,
    author = {Peter Christen},
    title = {Febrl – An Open Source Data Cleaning, Deduplication and Record Linkage System With a Graphical User Interface},
    journal = {In ACM International Conference on Knowledge Discovery and Data Mining},
    year = {2008},
    pages = {1065--1068}
}

@article{Yash2019,
    author = {Govind, Yash and Konda, Pradap and Suganthan G.C., Paul and Martinkus, Philip and Nagarajan, Palaniappan and Li, Han and Soundararajan, Aravind and Mudgal, Sidharth and Ballard, Jeff R. and Zhang, Haojun and Ardalan, Adel and Das, Sanjib and Paulsen, Derek and Singh Saini, Amanpreet and Paulson, Erik and Park, Youngchoon and Carter, Marshall and Sun, Mingju and Fung, Glenn M. and Doan, AnHai},
    title = {Entity Matching Meets Data Science: A Progress Report from the Magellan Project},
    year = {2019},
    isbn = {9781450356435},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    doi = {10.1145/3299869.3314042},
    journal = {Proceedings of the 2019 International Conference on Management of Data},
    pages = {389–403},
    numpages = {15},
    location = {Amsterdam, Netherlands},
}

@article{sariyar2010recordlinkage,
  title={The RecordLinkage Package: Detecting Errors in Data},
  author={Sariyar, Murat and Borg, Andreas},
  journal={The R Journal},
  volume={2},
  number={2},
  pages={61--67},
  year={2010}
}

@data{Lai2011_data,
    author = {Ronald Lai and Alexander D'Amour and Amy Yu and Ye Sun and Lee Fleming},
    publisher = {Harvard Dataverse},
    title = {Disambiguation and Co-Authorship Networks of the U.S. Patent Inventor Database (1975 - 2010)},
    UNF = {UNF:5:RqsI3LsQEYLHkkg5jG/jRg==},
    year = {2011},
    version = {V5},
    doi = {10.7910/DVN/5F1RRI},
    url = {https://doi.org/10.7910/DVN/5F1RRI}
}

@article{Sadosky2015,
    archivePrefix = {arXiv},
    arxivId = {1510.07714},
    author = {Sadosky, Peter and Shrivastava, Anshumali and Price, Megan and Steorts, Rebecca C.},
    pages = {1--25},
    title = {Blocking Methods Applied to Casualty Records from the {S}yrian Conflict},
    year = {2015},
    journal={arXiv e-prints},
    note={{arxiv:1510.07714}}
}

@article{Bilenko2006,
    abstract = {Many data mining tasks require computing similarity between pairs of objects. Pairwise similarity computations are particularly important in record linkage systems, as well as in clustering and schema mapping algorithms. Because the number of object pairs grows quadratically with the size of the dataset, computing similarity between all pairs is impractical and becomes prohibitive for large dataseis and complex similarity functions. Blocking methods alleviate this problem by efficiently selecting approximately similar object pairs for subsequent distance computations, leaving out the remaining pairs as dissimilar. Previously proposed blocking methods require manually constructing an indexbased similarity function or selecting a set of predicates, followed by hand-tuning of parameters. In this paper, we introduce an adaptive framework for automatically learning blocking functions that are efficient and accurate. We describe two predicate-based formulations of leamable blocking functions and provide learning algorithms for training them. The effectiveness of the proposed techniques is demonstrated on real and simulated dataseis, on which they prove to be more accurate than non-adaptive blocking methods. {\textcopyright} 2006 IEEE.},
    author = {Bilenko, Mikhail and Kamath, Beena and Mooney, Raymond J.},
    doi = {10.1109/ICDM.2006.13},
    isbn = {0769527019},
    issn = {15504786},
    journal = {Proceedings - IEEE International Conference on Data Mining, ICDM},
    number = {December},
    pages = {87--96},
    title = {Adaptive blocking: Learning to scale up record linkage},
    year = {2006}
}

@article{Evangelista2010,
    author = {Evangelista, Luiz Osvaldo and Cortez, Eli and da Silva, Altigran S and {Meira Jr.}, Wagner},
    file = {:home/olivier/Downloads/blocking-jidm.pdf:pdf},
    issn = {21787107},
    journal = {Journal of Information and Data Management},
    keywords = {blocking,genetic algorithms,record linkage},
    mendeley-groups = {Entity Resolution/Blocking},
    number = {2},
    pages = {167},
    title = {Adaptive and Flexible Blocking for Record Linkage Tasks},
    url = {http://seer.lcc.ufmg.br/index.php/jidm/article/view/50},
    volume = {1},
    year = {2010}
}

@misc{Ball2016,
    author = {Patrick Ball},
    year = {2016},
    title = {A geeky deep-dive: database deduplication to identify victims of human rights violations},
    url = {https://hrdag.org/2016/01/08/a-geeky-deep-dive-database-deduplication-to-identify-victims-of-human-rights-violations/},
    note={Online; posted January 8, 2016; retrieved July 29, 2020}
}

@TECHREPORT{Gu2003,
    author = {Lifang Gu and Rohan Baxter and Deanne Vickers and Chris Rainsford},
    title = {Record Linkage: Current Practice and Future Directions},
    institution = {CSIRO Mathematical and Information Sciences},
    year = {2003}
}

@inbook{Jurek2019,
  title={Semi-supervised and unsupervised approaches to record pairs classification in multi-source data linkage},
  author={Jurek-Loughrey, Anna and Deepak, P},
  booktitle={Linking and Mining Heterogeneous and Multi-view Data},
  pages={55--78},
  year={2019},
  publisher={Springer}
}



@inbook{OHare2019,
    address = {Cham},
    author = {O'Hare, Kevin and Jurek-Loughrey, Anna and de Campos, Cassio},
    booktitle = {Linking and Mining Heterogeneous and Multi-view Data},
    doi = {10.1007/978-3-030-01872-6_4},
    editor = {P, Deepak and Jurek-Loughrey, Anna},
    isbn = {978-3-030-01872-6},
    pages = {79--105},
    publisher = {Springer International Publishing},
    title = {A Review of Unsupervised and Semi-supervised Blocking Methods for Record Linkage},
    year = {2019}
}



@article{Winkler2014,
    abstract = {This overview gives background on a number of statistical methods that have been proven effective for record linkage. To prepare data for the main computational algorithms, we need parsing/standardization that allows us to structure the free-form names, addresses, and other fields into corresponding components. The main parameter-estimation methods are unsupervised methods that yield 'optimal' record linkage parameters. Extended methods provide estimates of false match rates in both unsupervised and, with greater accuracy, in semi-supervised situations. Finally, the paper describes ongoing research for adjusting standard statistical analyses for linkage error. {\textcopyright} 2014 Wiley Periodicals, Inc. 6 5 September/October 2014 10.1002/wics.1317 Overview Overview Published 2014. This article is a U.S. Government work and is in the public domain in the USA.},
    author = {Winkler, William E.},
    doi = {10.1002/wics.1317},
    file = {:home/olivier/Downloads/wics.1317.pdf:pdf},
    issn = {19390068},
    journal = {Wiley Interdisciplinary Reviews: Computational Statistics},
    keywords = {Classification rules,Entity resolution,False match and nonmatch rates,String comparison,Unsupervised learning},
    mendeley-groups = {Entity Resolution,Entity Resolution/Surveys},
    number = {5},
    pages = {313--325},
    title = {Matching and Record Linkage},
    volume = {6},
    year = {2014}
}

@article{Brizan2006,
    abstract = {A great deal of research is focused on formation of a data warehouse. This is an important area of research as it could save many computation cycles and thus allow accurate information provided to the right people at the right time. Two considerations when forming a data warehouse are data cleansing (including entity resolution) and with schema integration (including record linkage). Uncleansed and fragmented data requires time to decipher and may lead to increased costs for an organization, so data cleansing and schema integration can save a great many (human) computation cycles and can lead to higher organizational efficiency. In this study we survey the literature for the methodologies proposed or developed for entity resolution and record linkage. This survey provides a foundation for solving many problems in data warehousing. For instance, little or no research has been directed at the problem of maintenance of cleansed and linked relations.},
    author = {Brizan, David Guy and Tansel, Abdullah Uz},
    file = {:home/olivier/Downloads/A. Survey of Entity Resolution and Record Linkage Methodologies.pdf:pdf},
    isbn = {1941-6687},
    issn = {1941-6687},
    journal = {Communications of the IIMA},
    mendeley-groups = {Entity Resolution/Surveys},
    number = {3},
    pages = {41--50},
    title = {A Survey of Entity Resolution and Record Linkage Methodologies},
    volume = {6},
    year = {2006}
}

@inbook{Vidhya2019,
  author={K. A. {Vidhya} and T. V. {Geetha}},
  booktitle={2019 IEEE 9th International Conference on Advanced Computing (IACC)}, 
  title={Entity Resolution and Blocking: A Review}, 
  year={2019},
  volume={},
  number={},
  pages={133-140},
 }

@article{Sayers2016,
    abstract = {Studies involving the use of probabilistic record linkage are becoming increasingly common. However, the methods underpinning probabilistic record linkage are not widely taught or understood, and therefore these studies can appear to be a ‘black box' research tool. In this article, we aim to describe the process of probabilistic record linkage through a simple exemplar. We first introduce the concept of deterministic linkage and contrast this with probabilistic linkage. We illustrate each step of the process using a simple exemplar and describe the data structure required to perform a probabilistic linkage. We describe the process of calculating and interpreting matched weights and how to convert matched weights into posterior probabilities of a match using Bayes theorem. We conclude this article with a brief discussion of some of the computational demands of record linkage, how you might assess the quality of your linkage algorithm, and how epidemiologists can maximize the value of their record-linked research using robust record linkage methods.},
    author = {Sayers, Adrian and Ben-Shlomo, Yoav and Blom, Ashley W. and Steele, Fiona},
    doi = {10.1093/ije/dyv322},
    file = {:home/olivier/Downloads/dyv322(1).pdf:pdf},
    issn = {14643685},
    journal = {International Journal of Epidemiology},
    keywords = {Bias,Data linkage,Epidemiological methods,Medical record linkage,Record linkage},
    mendeley-groups = {Entity Resolution/Surveys},
    number = {3},
    pages = {954--964},
    pmid = {26686842},
    title = {Probabilistic Record Linkage},
    volume = {45},
    year = {2016}
}

@article{Bailey2017,
  title={How well do automated linking methods perform? Lessons from {US} historical data},
  author={Bailey, Martha J and Cole, Connor and Henderson, Morgan and Massey, Catherine},
  journal={Journal of Economic Literature},
  volume={58},
  number={4},
  pages={997--1044},
  year={2020}
}


@article{Avoundjian2020,
    author = {Avoundjian, Tigran and Dombrowski, Julia C and Golden, Matthew R and Hughes, James P and Guthrie, Brandon L and Baseman, Janet and Sadinle, Mauricio},
    doi = {10.2196/15917},
    issn = {2369-2960},
    journal = {JMIR Public Health and Surveillance},
    month = {apr},
    number = {2},
    pages = {e15917},
    title = {Comparing Methods for Record Linkage for Public Health Action: Matching Algorithm Validation Study},
    volume = {6},
    year = {2020}
}

@article{Tran2013,
    author = {Tran, Khoi-Nguyen and Vatsalan, Dinusha and Christen, Peter},
    title = {GeCo: An Online Personal Data Generator and Corruptor},
    year = {2013},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    journal = {Proceedings of the 22nd ACM International Conference on Information \& Knowledge Management},
    pages = {2473–2476},
    numpages = {4},
    keywords = {synthetic data, online demo, duplicates, data generation},
    location = {San Francisco, California, USA}
}
  
@article{Narayanan2008,
    author = {Narayanan, Arvind and Shmatikov, Vitaly},
    doi = {10.1109/SP.2008.33},
    isbn = {9780769531687},
    issn = {10816011},
    journal = {Proceedings - IEEE Symposium on Security and Privacy},
    mendeley-groups = {Entity Resolution/Linkage attacks},
    pages = {111--125},
    title = {Robust De-Anonymization of Large Sparse Datasets},
    year = {2008}
}

@article{Sweeney2002,
    author = {Sweeney, Latanya},
    title = {K-Anonymity: A Model for Protecting Privacy},
    year = {2002},
    issue_date = {October 2002},
    publisher = {World Scientific Publishing Co., Inc.},
    address = {USA},
    volume = {10},
    number = {5},
    doi = {10.1142/S0218488502001648},
    journal = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
    pages = {557–570},
    numpages = {14},
}
  
@article{Mohammed2011,
    abstract = {Data integration methods enable different data providers to flexibly integrate their expertise and deliver highly customizable services to their customers. Nonetheless, combining data from different sources could potentially reveal person-specific sensitive information. In VLDBJ 2006, Jiang and Clifton (Very Large Data Bases J (VLDBJ) 15(4):316-333, 2006) propose a secure Distributed k-Anonymity (DkA) framework for integrating two private data tables to a k-anonymous table in which each private table is a vertical partition on the same set of records. Their proposed DkA framework is not scalable to large data sets. Moreover, DkA is limited to a two-party scenario and the parties are assumed to be semi-honest. In this paper, we propose two algorithms to securely integrate private data from multiple parties (data providers). Our first algorithm achieves the k-anonymity privacy model in a semi-honest adversary model. Our second algorithm employs a game-theoretic approach to thwart malicious participants and to ensure fair and honest participation of multiple data providers in the data integration process. Moreover, we study and resolve a real-life privacy problem in data sharing for the financial industry in Sweden. Experiments on the real-life data demonstrate that our proposed algorithms can effectively retain the essential information in anonymous data for data analysis and are scalable for anonymizing large data sets. {\textcopyright} 2010 Springer-Verlag.},
    author = {Mohammed, Noman and Fung, Benjamin C.M. and Debbabi, Mourad},
    doi = {10.1007/s00778-010-0214-6},
    issn = {10668888},
    journal = {VLDB Journal},
    keywords = {Classification,Privacy,Secure data integration,k-anonymity},
    mendeley-groups = {Entity Resolution/PPRL},
    number = {4},
    pages = {567--588},
    title = {Anonymity Meets Game Theory: Secure Data Integration With Malicious Participants},
    volume = {20},
    year = {2011}
}

@article{Vatsalan2013,
    author = {Vatsalan, Dinusha and Christen, Peter and Verykios, Vassilios S.},
    journal = {Information Systems},
    number = {6},
    pages = {946--969},
    title = {A Taxonomy of Privacy-Preserving Record Linkage Techniques},
    volume = {38},
    year = {2013}
}

@article{Mohammed2014,
    abstract = {Privacy-preserving data publishing addresses the problem of disclosing sensitive data when mining for useful information. Among the existing privacy models, (E)-differential privacy provides one of the strongest privacy guarantees. In this paper, we address the problem of private data publishing, where different attributes for the same set of individuals are held by two parties. In particular, we present an algorithm for differentially private data release for vertically partitioned data between two parties in the semihonest adversary model. To achieve this, we first present a two-party protocol for the exponential mechanism. This protocol can be used as a subprotocol by any other algorithm that requires the exponential mechanism in a distributed setting. Furthermore, we propose a two-party algorithm that releases differentially private data in a secure way according to the definition of secure multiparty computation. Experimental results on real-life data suggest that the proposed algorithm can effectively preserve information for a data mining task. {\textcopyright} 2013 IEEE.},
    author = {Mohammed, Noman and Alhadidi, Dima and Fung, Benjamin C.M. and Debbabi, Mourad},
    doi = {10.1109/TDSC.2013.22},
    file = {:home/olivier/Downloads/06517175.pdf:pdf},
    issn = {15455971},
    journal = {IEEE Transactions on Dependable and Secure Computing},
    keywords = {Differential privacy,classification analysis,secure data integration},
    mendeley-groups = {Entity Resolution/PPRL},
    number = {1},
    pages = {59--71},
    publisher = {IEEE},
    title = {Secure Two-Party Differentially Private Data Release for Vertically Partitioned Data},
    volume = {11},
    year = {2014}
}

@article{Jiang2006,
    abstract = {k-anonymity provides a measure of privacy protection by preventing re-identification of data to fewer than a group of k data items. While algorithms exist for producing k-anonymous data, the model has been that of a single source wanting to publish data. Due to privacy issues, it is common that data from different sites cannot be shared directly. Therefore, this paper presents a two-party framework along with an application that generates k-anonymous data from two vertically partitioned sources without disclosing data from one site to the other. The framework is privacy preserving in the sense that it satisfies the secure definition commonly defined in the literature of Secure Multiparty Computation. {\textcopyright} 2006 Springer-Verlag.},
    author = {Jiang, Wei and Clifton, Chris},
    doi = {10.1007/s00778-006-0008-z},
    issn = {10668888},
    journal = {VLDB Journal},
    number = {4},
    pages = {316--333},
    title = {A Secure Distributed Framework for Achieving k-Anonymity},
    volume = {15},
    year = {2006}
}

@article{Cheng2020,
    abstract = {In this paper, we study the problem of publishing high-dimensional data in a distributed multi-party environment under differential privacy. In particular, with the assistance of a semi-trusted curator, the parties (i.e., local data owners) collectively generate a synthetic integrated dataset while satisfying $\backslash$varepsilonϵ-differential privacy. To solve this problem, we present a differentially private sequential update of Bayesian network (DP-SUBN) approach. In DP-SUBN, the parties and the curator collaboratively identify the Bayesian network $\backslash$mathbb {\{}N{\}}N that best fits the integrated dataset in a sequential manner, from which a synthetic dataset can then be generated. The fundamental advantage of adopting the sequential update manner is that the parties can treat the intermediate results provided by previous parties as their prior knowledge to direct how to learn $\backslash$mathbb {\{}N{\}}N. The core of DP-SUBN is the construction of the search frontier, which can be seen as a priori knowledge to guide the parties to update $\backslash$mathbb {\{}N{\}}N. By exploiting the correlations of attribute pairs, we propose exact and heuristic methods to construct the search frontier. In particular, to privately quantify the correlations of attribute pairs without introducing too much noise, we first put forward a non-overlapping covering design (NOCD) method, and then devise a dynamic programming method for determining the optimal parameters used in NOCD. Through privacy analysis, we show that DP-SUBN satisfies $\backslash$varepsilonϵ-differential privacy. Extensive experiments on real datasets demonstrate that DP-SUBN offers desirable data utility with low communication cost.},
    author = {Cheng, Xiang and Tang, Peng and Su, Sen and Chen, Rui and Wu, Zequn and Zhu, Binyuan},
    doi = {10.1109/TKDE.2019.2906610},
    file = {:home/olivier/Downloads/08673599.pdf:pdf},
    issn = {15582191},
    journal = {IEEE Transactions on Knowledge and Data Engineering},
    keywords = {Differential privacy,data publishing,high-dimensional data,multiple parties},
    mendeley-groups = {Entity Resolution/PPRL},
    number = {8},
    pages = {1557--1571},
    publisher = {IEEE},
    title = {Multi-Party High-Dimensional Data Publishing under Differential Privacy},
    volume = {32},
    year = {2020}
}

@article{Hall2010,
    abstract = {Record linkage has a long tradition in both the statistical and the computer science literature. We survey current approaches to the record linkage problem in a privacy-aware setting and contrast these with the more traditional literature. We also identify several important open questions that pertain to private record linkage from different perspectives.},
    address = {Berlin, Heidelberg},
    author = {Hall, Rob and Fienberg, Stephen E},
    journal = {Privacy in Statistical Databases},
    editor = {Domingo-Ferrer, Josep and Magkos, Emmanouil},
    isbn = {978-3-642-15838-4},
    pages = {269--283},
    publisher = {Springer Berlin Heidelberg},
    title = {Privacy-Preserving Record Linkage},
    year = {2010}
}


@incollection{Vatsalan2017,
    address = {Cham},
    author = {Vatsalan, Dinusha and Sehili, Ziad and Christen, Peter and Rahm, Erhard},
    booktitle = {Handbook of Big Data Technologies},
    editor = {Zomaya, Albert Y and Sakr, Sherif},
    isbn = {978-3-319-49340-4},
    pages = {851--895},
    publisher = {Springer International Publishing},
    title = {Privacy-Preserving Record Linkage for Big Data: Current Approaches and Research Challenges},
    year = {2017}
}

@article{Price2014big_data,
    author = {Price, Megan and Ball, Patrick},
    journal = {SAIS Review of International Affairs},
    number = {1},
    pages = {9--20},
    title = {Big Data, Selection Bias, and the Statistical Patterns of Mortality in Conflict},
    volume = {34},
    year = {2014}
}



@book{national2013nonresponse,
  title={Nonresponse in social science surveys: A research agenda},
  author={{National Research Council}},
  editors={Roger Tourangeau and Thomas J. Plewes},
  year={2013},
  publisher={National Academies Press}
}

@article{Sanmartin2016,
    author = {Sanmartin, Claudia and Decady, Yves and Trudeau, Richard and Dasylva, Abel and Tjepkema, Michael and Fin{\`{e}}s, Philippe and Burnett, Rick and Ross, Nancy and Manuel, Douglas G.},
    journal = {Health Reports},
    number = {12},
    pages = {10--18},
    pmid = {28002578},
    title = {Linking the Canadian community health survey and the canadian mortality database: An enhanced data source for the study of mortality},
    volume = {27},
    year = {2016}
}

@article{Dasylva2018,
    author = {Dasylva, A},
    journal = {Proceedings of Statistics Canada Symposium},
    keywords = {data matching,linkage errors,record linkage},
    mendeley-groups = {Entity Resolution/STATCAN},
    title = {Pairwise Estimating Equations for the Primary Analysis of Linked Data},
    year = {2018}
}

@incollection{Dasylva2014,
    title = {Overcoverage in the 2011 {C}anadian Census},
    author = {Dasylva, Abel and Titus, Robert-Charles and Thibault, Christian},
    booktitle = {Proceedings of Statistics Canada Symposium},
    year = {2014}
}


@article{AbelDasylva2016,
    author = {{Abel Dasylva} and {Melanie Abeysundera} and {Blache Akpou{\'{e}}} and Sa{\"{i}}di, Abdelnasser},
    journal = {Statistics Canada Symposium 201},
    title = {Measuring the Quality of a Probabilistic Linkage through Clerical-Reviews},
    year = {2016}
}

@techreport{Chevrette2011GLINKA,
  title={G-LINK : A Probabilistic Record Linkage System},
  author={Antoine Chevrette},
  year={2011},
  institution={Statistics Canada}
}

@article{Thompson2018,
author = {Thompson, Mary E.},
issn = {1708-945X},
journal = {Canadian Journal of Statistics},
number = {1},
pages = {10--23},
title = {Dynamic data science and official statistics},
volume = {46},
year = {2018}
}

@article{Winkler1990,
    author = {{William E Winkler} and Thibaudeau, Yves},
    file = {:home/olivier/.var/app/com.elsevier.MendeleyDesktop/data/data/Mendeley Ltd./Mendeley Desktop/Downloaded/William E Winkler, Thibaudeau - 1990 - An application of the Fellegi-Sunter model of record linkage to the 1990 {US} decennial census.pdf:pdf},
    journal = {Research Report},
    keywords = {Decision Rule,EM Algorithm,Error Rate.,LP Algorithm,String Comparator Metric},
    mendeley-groups = {Entity Resolution,Entity Resolution/Applications,Entity Resolution/FS-type},
    number = {April 2015},
    pages = {1--22},
    title = {An application of the {F}ellegi-{S}unter model of record linkage to the 1990 {US} decennial census},
    year = {1990}
}


@article{Rogot1986,
    author = {Rogot, Eugene and Sorlie, Paul and Johnson, Norman J.},
    journal = {Journal of Chronic Diseases},
    number = {9},
    pages = {719--734},
    title = {Probabilistic Methods in Matching Census},
    volume = {39},
    year = {1986}
}

@book{Dusetzina2014,
    address = {Rockville, MD},
    author = {Dusetzina, Stacie B and Tyree, Seth and Meyer, Anne-Marie and Meyer, Adrian and Green, Laura and Carpenter, William R},
    doi = {AHRQ No.14-EHC033},
    pmid = {25392892},
    publisher = {Agency for Healthcare Research and Quality},
    title = {Linking Data for Health Services Research: A Framework and Instructional Guide},
    year = {2014}
}

@article{lum2013applications,
  title={Applications of multiple systems estimation in human rights research},
  author={Lum, Kristian and Price, Megan Emily and Banks, David},
  journal={The American Statistician},
  volume={67},
  number={4},
  pages={191--200},
  year={2013},
  publisher={Taylor \& Francis}
}

@article{meray2007probabilistic,
  title={Probabilistic record linkage is a valid and transparent tool to combine databases without a patient identification number},
  author={M{\'e}ray, Nora and Reitsma, Johannes B and Ravelli, Anita CJ and Bonsel, Gouke J},
  journal={Journal of Clinical Epidemiology},
  volume={60},
  number={9},
  pages={883 - 891},
  year={2007},
  publisher={Elsevier}
}

@article{bell1994urge,
  title={The urge to merge: linking vital statistics records and Medicaid claims},
  author={Bell, Robert M and Keesey, Joan and Richards, Toni},
  journal={Medical care},
  pages={1004--1018},
  year={1994},
  publisher={JSTOR}
}

@article{Jaro1995,
    author = {Jaro, Matthew A.},
    doi = {10.1002/sim.4780140510},
    journal = {Statistics in Medicine},
    number = {5-7},
    pages = {491--498},
    pmid = {7792443},
    title = {Probabilistic linkage of large public health data files},
    volume = {14},
    year = {1995}
}

@article{Hand2018,
    author = {Hand, David J.},
    doi = {10.1111/rssa.12315},
    file = {:home/olivier/Downloads/rssa.12315.pdf:pdf},
    issn = {1467985X},
    journal = {Journal of the Royal Statistical Society. Series A: Statistics in Society},
    keywords = {Data quality,Management data,Operational data,Repurposed data,‘Big data'},
    mendeley-groups = {Entity Resolution},
    number = {3},
    pages = {555--605},
    title = {Statistical challenges of administrative and transaction data},
    volume = {181},
    year = {2018}
}

@article{Stedman2019,
    author = {Stedman, Richard C. and Connelly, Nancy A. and Heberlein, Thomas A. and Decker, Daniel J. and Allred, Shorna B.},
    doi = {10.1080/08941920.2019.1587127},
    issn = {15210723},
    journal = {Society and Natural Resources},
    keywords = {Alternative methods,mail survey,response rate},
    number = {10},
    pages = {1139--1154},
    publisher = {Routledge},
    title = {The End of the (Research) World As We Know It? Understanding and Coping With Declining Response Rates to Mail Surveys},
    url = {https://doi.org/10.1080/08941920.2019.1587127},
    volume = {32},
    year = {2019}
}


@article{Gutman2013,
    author = {Gutman, Roee and Afendulis, Christopher C. and Zaslavsky, Alan M.},
    doi = {10.1080/01621459.2012.726889},
    issn = {01621459},
    journal = {Journal of the American Statistical Association},
    keywords = {Administrative data,Bayesian analysis,Missing data,Record linkage,Statistical matching},
    mendeley-groups = {Entity Resolution},
    number = {501},
    pages = {34--47},
    title = {A {B}ayesian procedure for file linking to analyze end-of-life medical costs},
    volume = {108},
    year = {2013}
}

@article{Winkler2010,
abstract = {2010 JSM Proceedings - Papers presented at Joint Statistical Meetings - Vancouver, British Columbia, July 31 – August 5, 2010 and other ASA-sponsored conferences},
author = {Winkler, William E and Yancey, William E and Porter, Edward H},
file = {:home/olivier/Downloads/307067_57754.pdf:pdf},
journal = {Proceedings of the Section on Survey Research Methods},
keywords = {administrative,fast record linkage of,jsm 2010,methods,support of decennial and,tion on survey research,very large files in},
mendeley-groups = {Entity Resolution},
pages = {2120--2130},
title = {Fast Record Linkage of Very Large Files in Support of Decennial and Administrative Records Projects},
year = {2010}
}

@article{Ball2019,
    author = {Ball, Patrick and Price, Megan},
    doi = {10.1146/annurev-statistics-030718-105222},
    journal = {Annual Review of Statistics and Its Application},
    number = {1},
    pages = {63--84},
    title = {Using Statistics to Assess Lethal Violence in Civil and Inter-State War},
    url = {https://doi.org/10.1146/annurev-statistics-030718-105222},
    volume = {6},
    year = {2019}
}

@article{Monath2019,
    abstract = {We introduce Grinch, a new algorithm for large-scale, non-greedy hierarchical clustering with general linkage functions that compute arbitrary similarity between two point sets. The key components of Grinch are its rotate and graft subroutines that efciently reconfgure the hierarchy as new points arrive, supporting discovery of clusters with complex structure. Grinch is motivated by a new notion of separability for clustering with linkage functions: we prove that when the linkage function is consistent with a ground-truth clustering, Grinch is guaranteed to produce a cluster tree containing the ground-truth, independent of data arrival order. Our empirical results on benchmark and author coreference datasets (with standard and learned linkage functions) show that Grinch is more accurate than other scalable methods, and orders of magnitude faster than hierarchical agglomerative clustering.},
    archivePrefix = {arXiv},
    arxivId = {2001.00076},
    author = {Monath, Nicholas and Kobren, Ari and Krishnamurthy, Akshay and Glass, Michael R. and McCallum, Andrew},
    doi = {10.1145/3292500.3330929},
    eprint = {2001.00076},
    file = {:Users/olivierbinette/Documents/Mendeley/Monath, Kobren, Krishnamurthy - 2020 - Scalable Hierarchical Clustering with Tree Grafting.pdf:pdf},
    isbn = {9781450362016},
    journal = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
    keywords = {Clustering,Hierarchical Clustering},
    pages = {1438--1448},
    title = {Scalable hierarchical clustering with tree grafing},
    year = {2019}
}

@article{Monath2021,
    author = {Monath, Nicholas and Ahmed, Amr and Mccallum, Andrew},
    title = {DAG-Structured Clustering by Nearest Neighbors},
    volume = {130},
    year = {2021}
}

@article{Sauleau2005,
    author = {Sauleau, Erik A. and Paumier, Jean Philippe and Buemi, Antoine},
    doi = {10.1186/1472-6947-5-32},
    file = {:Users/olivierbinette/Documents/Mendeley/Sauleau, Paumier, Buemi - 2005 - BMC Medical Informatics and Medical record linkage in health information systems by approximate string.pdf:pdf},
    issn = {14726947},
    journal = {BMC Medical Informatics and Decision Making},
    mendeley-groups = {Entity Resolution},
    pages = {1--13},
    pmid = {16219102},
    volume = {5},
    year = {2005}
}

@article{wu2020zeroer,
  title={{ZeroER}: Entity resolution using zero labeled examples},
  author={Wu, Renzhi and Chaba, Sanya and Sawlani, Saurabh and Chu, Xu and Thirumuruganathan, Saravanan},
  journal={Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data},
  pages={1149--1164},
  year={2020}
}

@article{Wang2011,
    author = {Wang, Jiannan and Li, Guoliang and Yu, Jeffrey Xu and Feng, Jianhua},
    doi = {10.14778/2021017.2021020},
    journal = {Proceedings of the VLDB Endowment},
    number = {10},
    pages = {622--633},
    title = {Entity matching: {H}ow similar is similar},
    volume = {4},
    year = {2011}
}

@article{Rivero2020,
    author = {Rivero, Carlos R and Ruiz, David},
    journal = {Proceedings of the ACM Symposium on Applied Computing},
    pages = {907--914},
    title = {Selecting suitable configurations for automated link discovery},
    year = {2020}
}

@article{Heidari2020,
author = {Heidari, Alireza and Michalopoulos, George and Kushagra, Shrinu and Ilyas, Ihab F. and Rekatsinas, Theodoros},
title = {Record fusion: {A} learning approach},
year = {2020},
journal = {arXiv e-prints},
note={{arxiv:2006.10208}}
}

@article{Fan2009,
    title = {Reasoning about record matching rules},
    author = {Fan, Wenfei and Jia, Xibei and Li, Jianzhong and Ma, Shuai},
    journal = {Proceedings of the VLDB Endowment},
    number = {1},
    pages = {407--418},
    volume = {2},
    year = {2009}
}

@article{Wang2010,
    author = {Wang, Jiannan and Feng, Jianhua and Li, Guoliang},
    doi = {10.14778/1920841.1920992},
    file = {:home/olivier/Downloads/1920841.1920992.pdf:pdf},
    issn = {21508097},
    journal = {Proceedings of the VLDB Endowment},
    mendeley-groups = {Entity Resolution/CS / Data management},
    number = {1},
    pages = {1219--1230},
    title = {Trie-join: {E}fficient triebased string similarity joins with edit distance constraints},
    volume = {3},
    year = {2010}
}

@article{Papadakis2020,
    author = {Papadakis, George and Skoutas, Dimitrios and Thanos, Emmanouil and Palpanas, Themis},
    title = {Blocking and Filtering Techniques for Entity Resolution: A Survey},
    year = {2020},
    issue_date = {June 2020},
    publisher = {Association for Computing Machinery},
    address = {New York, NY},
    volume = {53},
    number = {2},
    journal = {ACM Computing Surveys},
    month = mar,
    articleno = {31},
    numpages = {42},
    keywords = {filtering, entity resolution, Blocking}
}

@article{Zhang2017,
    archivePrefix = {arXiv},
    arxivId = {1702.00093},
    author = {Zhang, Haoyu and Zhang, Qin},
    journal = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
    pages = {585--594},
    title = {EmbedJoin: {E}fficient edit similarity joins via embeddings},
    year = {2017}
}

@article{Yu2017,
    author = {Yu, Minghe and Wang, Jin and Li, Guoliang and Zhang, Yong and Deng, Dong and Feng, Jianhua},
    issn = {0949877X},
    journal = {VLDB Journal},
    number = {2},
    pages = {249--274},
    publisher = {Springer Berlin Heidelberg},
    title = {{A unified framework for string similarity search with edit-distance constraint}},
    volume = {26},
    year = {2017}
}

@article{Wei2018,
    author = {Wei, Hao and Yu, Jeffrey Xu and Lu, Can},
    number = {1},
    pages = {170--184},
    publisher = {IEEE},
    journal={IEEE Transactions on Knowledge and Data Engineering},
    title = {String Similarity Search : {A} Hash-Based Approach},
    volume = {30},
    year = {2018}
}

@article{Soru2013,
author = {Soru, Tommaso and Ngomo, Axel Cyrille Ngonga},
journal = {Proceedings of the Ontology
Matching Workshop},
title = {Rapid execution of weighted edit distances},
year = {2013}
}

@article{Nentwig2017,
    author = {Nentwig, Markus and Hartung, Michael and {Ngonga Ngomo}, Axel Cyrille and Rahm, Erhard},
    doi = {10.3233/SW-150210},
    file = {:home/olivier/Downloads/swj-nentwig2017.pdf:pdf},
    issn = {22104968},
    journal = {Semantic Web},
    mendeley-groups = {Entity Resolution/CS / Data management},
    number = {3},
    pages = {419--436},
    title = {A survey of current Link Discovery frameworks},
    volume = {8},
    year = {2017}
}

@inbook{Saeedi2017,
    address = {Cham},
    author = {Saeedi, Alieh and Peukert, Eric and Rahm, Erhard},
    booktitle = {Advances in Databases and Information Systems},
    editor = {Kirikova, M. and N{\o}rv{\aa}g, Kjetil and Papadopoulos, George A},
    isbn = {978-3-319-66917-5},
    pages = {278--293},
    publisher = {Springer International Publishing},
    title = {Comparative Evaluation of Distributed Clustering Schemes for Multi-source Entity Resolution},
    year = {2017}
}

@article{Benjelloun2009,
    author = {Benjelloun, Omar and Garcia-Molina, Hector and Menestrina, David and Su, Qi and Whang, Steven Euijong and Widom, Jennifer},
    doi = {10.1007/s00778-008-0098-x},
    issn = {10668888},
    journal = {VLDB Journal},
    keywords = {Data cleaning,Entity resolution,Generic entity resolution},
    mendeley-groups = {Entity Resolution/CS / Data management},
    number = {1},
    pages = {255--276},
    title = {Swoosh: {A} generic approach to entity resolution},
    volume = {18},
    year = {2009}
}

@phdthesis{galhardas2001declarative,
  title={Declarative data cleaning: Language, model, and algorithms},
  author={Galhardas, Helena and Florescu, Daniela and Shasha, Dennis and Simon, Eric and Saita, Cristian},
  year={2001},
  school={INRIA}
}

@article{Cohen2000,
    author = {Cohen, William W.},
    doi = {10.1145/352595.352598},
    file = {:home/olivier/Downloads/352595.352598.pdf:pdf},
    issn = {10468188},
    journal = {ACM Transactions on Information Systems},
    keywords = {H.2.3 [Information Systems]: Database Management - data manipulation languages,H.2.5 [Information Systems]: Database Management - heterogeneous databases,Query languages},
    mendeley-groups = {Entity Resolution/CS / Data management},
    number = {3},
    pages = {288--321},
    title = {Data integration using similarity joins and a word-based information representation language},
    volume = {18},
    year = {2000}
}

@article{yujian2007normalized,
  title={A normalized Levenshtein distance metric},
  author={Yujian, Li and Bo, Liu},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={29},
  number={6},
  pages={1091--1095},
  year={2007},
  publisher={IEEE}
}

@article{levenshtein1966binary,
  title={Binary codes capable of correcting deletions, insertions, and reversals},
  author={Levenshtein, Vladimir I },
  journal={Soviet physics doklady},
  volume={10},
  number={8},
  pages={707--710},
  year={1966}
}

@article{navarro2001guided,
  title={A guided tour to approximate string matching},
  author={Navarro, Gonzalo},
  journal={ACM computing surveys},
  volume={33},
  number={1},
  pages={31--88},
  year={2001},
  publisher={ACM New York, NY, USA}
}

@article{Tai2019,
    author = {Tai, Xiao Hui},
    doi = {10.1109/ICDMW.2018.00081},
    file = {:home/olivier/Downloads/Record_Linkage_and_Matching_Problems_in_Forensics.pdf:pdf},
    isbn = {9781538692882},
    issn = {23759259},
    journal = {IEEE International Conference on Data Mining Workshops},
    keywords = {forensic matching,record linkage,unstructured data},
    mendeley-groups = {Entity Resolution},
    pages = {510--517},
    publisher = {IEEE},
    title = {Record linkage and matching problems in forensics},
    year = {2018}
}

@article{Li2020,
    archivePrefix = {arXiv},
    arxivId = {2004.00584},
    author = {Li, Yuliang and Li, Jinfeng and Suhara, Yoshihiko and Doan, Anhai and Tan, Wang Chiew},
    doi = {10.14778/3421424.3421431},
    eprint = {2004.00584},
    file = {:home/olivier/Downloads/3421424.3421431.pdf:pdf},
    issn = {21508097},
    journal = {Proceedings of the VLDB Endowment},
    mendeley-groups = {Entity Resolution,Entity Resolution/Deep},
    number = {1},
    pages = {50--60},
    title = {{Deep entity matching with pre-trained language models}},
    volume = {14},
    year = {2020}
}

@article{Firmani2016,
    author = {Firmani, Donatella and Saha, Barna and Srivastava, Divesh},
    title = {Online Entity Resolution Using an Oracle},
    year = {2016},
    issue_date = {January 2016},
    publisher = {VLDB Endowment},
    volume = {9},
    number = {5},
    issn = {2150-8097},
    journal = {Proceedings of the VLDB Endowment},
    pages = {384–395},
    numpages = {12}
}

@article{bilenko2003adaptive,
  title={Adaptive duplicate detection using learnable string similarity measures},
  author={Bilenko, Mikhail and Mooney, Raymond J},
  journal={Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages={39--48},
  year={2003}
}

@article{mccallum2012conditional,
  title={A conditional random field for discriminatively-trained finite-state string edit distance},
  author={McCallum, Andrew and Bellare, Kedar and Pereira, Fernando},
  journal={arXiv e-prints},
  year={2012},
  note={{arXiv:1207.1406}}
}

@article{andrews2012name,
  title={Name phylogeny: A generative model of string variation},
  author={Andrews, Nicholas and Eisner, Jason and Dredze, Mark},
  journal={Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning},
  pages={344--355},
  year={2012}
}

@article{LiBing2020,
author = {Li, Bing and Wang, Wei and Sun, Yifang and Zhang, Linhan and Ali, Muhammad Asif and Wang, Yi},
doi = {10.1609/aaai.v34i05.6330},
file = {:home/olivier/Downloads/6330-Article Text-9555-1-10-20200517.pdf:pdf},
isbn = {9781577358350},
issn = {2159-5399},
journal = {34th AAAI Conference on Artificial Intelligence},
keywords = {Natural Language Processing},
mendeley-groups = {Entity Resolution/Deep},
pages = {8172--8179},
title = {{GraphER: Token-centric entity resolution with graph convolutional neural networks}},
year = {2020}
}

@article{Ebraheem2018,
    author = {Ebraheem, Muhammad and Thirumuruganathan, Saravanan and Joty, Shafiq and Ouzzani, Mourad and Tang, Nan},
    issn = {2150-8097},
    journal = {Proceedings of the VLDB Endowment},
    mendeley-groups = {Entity Resolution/Deep},
    number = {11},
    pages = {1454--1467},
    title = {{Distributed representations of tuples for entity resolution}},
    volume = {11},
    year = {2018}
}

@article{Li2021,
    author = {Li, Yuliang and Li, Jinfeng and Suhara, Yoshihiko and Wang, Jin and Hirota, Wataru and Tan, Wang Chiew},
    doi = {10.1145/3431816},
    file = {:home/olivier/.var/app/com.elsevier.MendeleyDesktop/data/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2021 - Deep Entity Matching Challenges and Opportunities.pdf:pdf},
    issn = {19361963},
    journal = {Journal of Data and Information Quality},
    keywords = {Entity matching,data integration,deep learning,entity resolution,pre-trained language models},
    mendeley-groups = {Entity Resolution/CS / Data management,Entity Resolution/Deep},
    number = {1},
    pages = {1--17},
    title = {{Deep Entity Matching: Challenges and Opportunities}},
    volume = {13},
    year = {2021}
}

@inbook{gokhale2014corleone,
  title={Corleone: {H}ands-off crowdsourcing for entity matching},
  author={Gokhale, Chaitanya and Das, Sanjib and Doan, AnHai and Naughton, Jeffrey F and Rampalli, Narasimhan and Shavlik, Jude and Zhu, Xiaojin},
  booktitle={Proceedings of the 2014 ACM SIGMOD international conference on Management of data},
  pages={601--612},
  year={2014}
}

@book{Ilyas2019,
    author = {Ilyas, Ihab F. and Chu, Xu},
    title = {Data Cleaning},
    year = {2019},
    isbn = {9781450371520},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    abstract = {Data quality is one of the most important problems in data management, since dirty
    data often leads to inaccurate data analytics results and incorrect business decisions.
    Poor data across businesses and the U.S. government are reported to cost trillions
    of dollars a year. Multiple surveys show that dirty data is the most common barrier
    faced by data scientists. Not surprisingly, developing effective and efficient data
    cleaning solutions is challenging and is rife with deep theoretical and engineering
    problems.This book is about data cleaning, which is used to refer to all kinds of
    tasks and activities to detect and repair errors in the data. Rather than focus on
    a particular data cleaning task, we give an overview of the endto- end data cleaning
    process, describing various error detection and repair methods, and attempt to anchor
    these proposals with multiple taxonomies and views. Specifically, we cover four of
    the most common and important data cleaning tasks, namely, outlier detection, data
    transformation, error repair (including imputing missing values), and data deduplication.
    Furthermore, due to the increasing popularity and applicability of machine learning
    techniques, we include a chapter that specifically explores how machine learning techniques
    are used for data cleaning, and how data cleaning is used to improve machine learning
    models.This book is intended to serve as a useful reference for researchers and practitioners
    who are interested in the area of data quality and data cleaning. It can also be used
    as a textbook for a graduate course. Although we aim at covering state-of-the-art
    algorithms and techniques, we recognize that data cleaning is still an active field
    of research and therefore provide future directions of research whenever appropriate.}
}

@book{doan2012principles,
  title={Principles of Data Integration},
  author={Doan, AnHai and Halevy, Alon and Ives, Zachary},
  year={2012},
  publisher={Morgan Kaufmann},
  address={Waltham, MA}
}

@inbook{gagliardelli2019sparker,
  title={{SparkER}: {S}caling entity resolution in spark},
  author={Gagliardelli, Luca and Simonini, Giovanni and Beneventano, Domenico and Bergamaschi, Sonia},
  booktitle={EDBT 2019: 22nd International Conference on Extending Database Technology},
  year={2019},
  organization={PRT}
}

@misc{Robin2020,
  author = {Robin Linacre and Sam Lindsay},
  title = {splink: Probabilistic record linkage and deduplication at scale},
  year = {2021},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/moj-analytical-services/splink}}
}

@Manual{cohen2018us,
title = {fedmatch: Fast, Flexible, and User-Friendly Record Linkage Methods},
author = {Melanie Friedrichs and Chris Webster and Blake Marsh and Jacob Dice and Seung Lee},
year = {2021},
note = {R package version 2.0.3},
url = {https://CRAN.R-project.org/package=fedmatch},
 }

@article{papadakis2018return,
  title={The return of {JedAI}: End-to-end entity resolution for structured and semi-structured data},
  author={Papadakis, George and Tsekouras, Leonidas and Thanos, Emmanouil and Giannakopoulos, George and Palpanas, Themis and Koubarakis, Manolis},
  journal={Proceedings of the VLDB Endowment, Vol. 11, No. 12},
  volume={11},
  number={12},
  pages={1950--1953},
  year={2018},
  publisher={VLDB Endowment}
}

@ARTICLE{Ristad1998,

  author={Ristad, E.S. and Yianilos, P.N.},

  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 

  title={Learning string-edit distance}, 

  year={1998},

  volume={20},

  number={5},

  pages={522-532},

  doi={10.1109/34.682181}
 }

@article{liu2021oag,
  title={{OAG-BERT: P}re-train Heterogeneous Entity-augmented Academic Language Models},
  author={Liu, Xiao and Yin, Da and Zhang, Xingjian and Su, Kai and Wu, Kan and Yang, Hongxia and Tang, Jie},
  journal={arXiv e-prints},
  year={2021},
  note={{arXiv:2103.02410}}
}

@article{tai2020automatically,
  title={Automatically matching topographical measurements of cartridge cases using a record linkage framework},
  author={Tai, Xiao Hui and Eddy, William F},
  journal={arXiv e-prints},
  year={2020},
  note={{arXiv:2003.00060}}
}

@article{arasu2010active,
  title={On active learning of record matching packages},
  author={Arasu, Arvind and G{\"o}tz, Michaela and Kaushik, Raghav},
  journal={Proceedings of the 2010 ACM SIGMOD International Conference on Management of data},
  pages={783--794},
  year={2010}
}

@inbook{qian2017active,
  title={Active learning for large-scale entity resolution},
  author={Qian, Kun and Popa, Lucian and Sen, Prithviraj},
  booktitle={Proceedings of the 2017 ACM on Conference on Information and Knowledge Management},
  pages={1379--1388},
  year={2017}
}


@inbook{chen2018enabling,
  title={Enabling quality control for entity resolution: A human and machine cooperation framework},
  author={Chen, Zhaoqiang and Chen, Qun and Fan, Fengfeng and Wang, Yanyan and Wang, Zhuo and Nafa, Youcef and Li, Zhanhuai and Liu, Hailong and Pan, Wei},
  booktitle={2018 IEEE 34th International Conference on Data Engineering (ICDE)},
  pages={1156--1167},
  year={2018},
  organization={IEEE}
}

@inbook{chen2017human,
  title={A human-and-machine cooperative framework for entity resolution with quality guarantees},
  author={Chen, Zhaoqiang and Chen, Qun and Li, Zhanhuai},
  booktitle={2017 IEEE 33rd International Conference on Data Engineering (ICDE)},
  pages={1405--1406},
  year={2017},
  organization={IEEE}
}

@inbook{wang2013leveraging,
  title={Leveraging transitive relations for crowdsourced joins},
  author={Wang, Jiannan and Li, Guoliang and Kraska, Tim and Franklin, Michael J and Feng, Jianhua},
  booktitle={Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data},
  pages={229--240},
  year={2013}
}

@article{mozafari2014scaling,
  title={Scaling up crowd-sourcing to very large datasets: a case for active learning},
  author={Mozafari, Barzan and Sarkar, Purna and Franklin, Michael and Jordan, Michael and Madden, Samuel},
  journal={Proceedings of the VLDB Endowment},
  volume={8},
  number={2},
  pages={125--136},
  year={2014},
  publisher={VLDB Endowment}
}

@inbook{meduri2020comprehensive,
  title={A comprehensive benchmark framework for active learning methods in entity matching},
  author={Meduri, Venkata Vamsikrishna and Popa, Lucian and Sen, Prithviraj and Sarwat, Mohamed},
  booktitle={Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data},
  pages={1133--1147},
  year={2020}
}

@inbook{gurajada2019learning,
  title={Learning-based methods with human-in-the-loop for entity resolution},
  author={Gurajada, Sairam and Popa, Lucian and Qian, Kun and Sen, Prithviraj},
  booktitle={Proceedings of the 28th ACM International Conference on Information and Knowledge Management},
  pages={2969--2970},
  year={2019}
}

@inbook{tao2018entity,
  title={Entity matching with active monotone classification},
  author={Tao, Yufei},
  booktitle={Proceedings of the 37th ACM SIGMOD-SIGACT-SIGAI Symposium on Principles of Database Systems},
  pages={49--62},
  year={2018}
}

@inbook{primpeli2020unsupervised,
  title={Unsupervised bootstrapping of active learning for entity resolution},
  author={Primpeli, Anna and Bizer, Christian and Keuper, Margret},
  booktitle={European Semantic Web Conference},
  pages={215--231},
  year={2020},
  organization={Springer}
}

@article{qian2019systemer,
  title={Systemer: A human-in-the-loop system for explainable entity resolution},
  author={Qian, Kun and Popa, Lucian and Sen, Prithviraj},
  year={2019}
}

@article{govind2018cloudmatcher,
  title={CloudMatcher: A hands-off cloud/crowd service for entity matching},
  author={Govind, Yash and Paulson, Erik and Nagarajan, Palaniappan and Paul Suganthan, GC and Doan, AnHai and Park, Youngchoon and Fung, Glenn and Conathan, Devin and Carter, Marshall and Sun, Mingju},
  year={2018}
}

@article{Wilke2021,
  title={Towards Multi-modal Entity Resolution for Product Matching},
  author={Wilke, Moritz and Rahm, Erhard},
  year={2021},
  journal={Proceedings of the 32nd GI-Workshop on Foundations of Databases (Grundlagen von Datenbanken)}
}

@article{barlaug2021neural,
  title={Neural Networks for Entity Matching: A Survey},
  author={Barlaug, Nils and Gulla, Jon Atle},
  journal={ACM Transactions on Knowledge Discovery from Data},
  volume={15},
  number={3},
  pages={1--37},
  year={2021},
  publisher={ACM New York, NY}
}

